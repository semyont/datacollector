<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at
  
      http://www.apache.org/licenses/LICENSE-2.0
      
  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_hqg_nzh_vx">
 <title>Impala Queries for the Drift Synchronization Solution for Hive</title>
 <conbody>
        <p><indexterm>Hive Query executor<indexterm>Impala queries for the Drift Synchronization
                    Solution for Hive</indexterm></indexterm><indexterm>Drift Synchronization
                Solution for Hive<indexterm>implementing Impala Invalidate Metadata
                    queries</indexterm></indexterm>The Drift Synchronization Solution for Hive
            enables a pipeline to automatically create and update Hive tables and to write files to
            the tables. </p>
        <p>When implementing the Drift Synchronization Solution for Hive with Impala, you can use
            the Hive Query executor to submit an invalidate metadata query each time you need to
            update the Impala metadata cache. For a detailed example, see <xref
                href="../Event_Handling/CaseStudy-Impala.dita#concept_szz_xwm_lx"/>.</p>
        <p>Connect a Hive Query executor to the event stream from the Hive Metastore destination and
            the Hadoop FS destination. You can use the same executor for both, or use a separate
            executor for each.<dl>
                <dlentry>
                    <dt>Processing event records from the Hive Metastore destination</dt>
                    <dd>The Hive Metastore destination generates an event record each time it
                        changes a table and places the table name in the "table" record header
                        attribute. Use the following query to update the Impala metadata cache:
                        <codeblock>invalidate metadata ${record:attribute('/table')}</codeblock></dd>
                    <dd>When the Hive Query executor receives the event record, it runs the
                        Invalidate Metadata query on the table specified in the event record. </dd>
                </dlentry>
                <dlentry>
                    <dt>Processing event records from the Hadoop FS destination</dt>
                    <dd>The Hadoop FS destination generates an event record each time it closes a
                        file. It places the file path in a "filepath" field in the event record. If
                        you use a separate Hive Query executor for each destination, use the
                        following query to update the Impala
                        cache:<codeblock>invalidate metadata `${file:pathElement(record:value('/filepath'), -3)}`.
`${file:pathElement(record:value('/filepath'), -2)}`      </codeblock></dd>
                    <dd>This expression uses the third-to-last section of the path as the database
                        name, and the second-to-last section of the path as the table name. </dd>
                    <dd>If you want to use the same Hive Query executor to process records from Hive
                        Query and Hadoop FS, add an Expression Evaluator in the Hadoop FS event
                        stream to perform this processing. For an example, see <xref
                            href="../Event_Handling/CaseStudy-Impala.dita#concept_szz_xwm_lx"
                        />.</dd>
                </dlentry>
            </dl></p>
 </conbody>
</concept>
