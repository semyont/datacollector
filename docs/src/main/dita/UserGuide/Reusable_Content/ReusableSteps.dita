<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE task PUBLIC "-//OASIS//DTD DITA General Task//EN" "generalTask.dtd">
<task id="task_kzs_5vz_sq">
    <title>Reusable Steps</title>
    <shortdesc>You can conref these steps. Don't change anything in this file without checking where
        it is used.</shortdesc>
    <taskbody>
        <context/>
        <steps id="steps_pf2_wvz_sq">
            <step>
                <cmd id="PIPE_PROPS">
                    <draft-comment author="Loretta"><uicontrol>PIPELINE
                        PROPERTIES</uicontrol></draft-comment>
                </cmd>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta">The following two step are used in Configuring a
                        Pipeline and the tutorial pipeline config topic.</draft-comment>
                </cmd>
            </step>
            <step id="CreatePipeline1">
                <cmd>From the <wintitle>Home</wintitle> page or <wintitle>Getting Started</wintitle>
                    page, click <uicontrol>Create New Pipeline</uicontrol>. </cmd>
                <info>
                    <note type="tip">To get to the <wintitle>Home</wintitle> page, click the Home
                        icon.</note>
                </info>
            </step>
            <step id="CreatePipeline2">
                <cmd>In the <wintitle>New Pipeline</wintitle> window, enter a pipeline name and
                    optional description, and click <uicontrol>Save</uicontrol>.</cmd>
                <stepresult>The pipeline canvas displays the pipeline name and an error icon. The
                    error icon indicates that you need to configure error handling for the pipeline.
                    The Properties panel displays the pipeline properties. </stepresult>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>DATA
                        PREVIEW</uicontrol></draft-comment>
                    <draft-comment author="Loretta">The steps below are for data preview. They are
                        used in "Previewing a Single Stage" and "Previewing Multiple
                        Stages."</draft-comment>
                </cmd>
            </step>
            <step id="StartPreview">
                <cmd>Above the pipeline canvas, click the <uicontrol>Preview</uicontrol> icon:
                        <image href="../Graphics/icon_Preview.png" id="image_tfg_tf4_zs" scale="70"
                    />.</cmd>
                <info>If the Preview icon is disabled, check the Issues list for unconnected stages
                    and required properties that are not defined.</info>
            </step>
            <step id="Preview-Source">
                <cmd>In the <wintitle>Preview Configuration</wintitle> dialog box, configure the
                    following properties, then click <uicontrol>Run Preview</uicontrol>.</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_mjq_mfm_cs">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Preview Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Preview Source</entry>
                                    <entry>Source data for the preview:<ul id="ul_db2_4fm_cs">
                                            <li>Configured Source - Provides data from the origin
                                                system.</li>
                                            <li>Snapshot Data - Uses available snapshot data.</li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Preview Batch Size</entry>
                                    <entry>Number of records to use in the preview. Honors values up
                                        to the <ph
                                            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                        /> preview batch size. <p>Default is 10. The <ph
                                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                            /> default is 10.</p></entry>
                                </row>
                                <row>
                                    <entry>Preview Timeout</entry>
                                    <entry>Milliseconds to wait for preview data. Use to limit the
                                        time data preview waits for data to arrive at the origin.
                                        Relevant for transient origins only. </entry>
                                </row>
                                <row>
                                    <entry>Write to Destinations and Executors</entry>
                                    <entry>Determines whether the preview passes data to
                                        destinations or executors.<p>By default, does not pass data
                                            to destination or executor stages.</p></entry>
                                </row>
                                <row>
                                    <entry>Show Record/Field Header</entry>
                                    <entry>Displays record header attributes and field attributes
                                        when in List view. Attributes do not display in Table
                                        view.</entry>
                                </row>
                                <row>
                                    <entry>Show Field Type</entry>
                                    <entry>Displays the data type for fields in List view. Field
                                        types do not display in Table view.</entry>
                                </row>
                                <row>
                                    <entry>Snapshot Data</entry>
                                    <entry>When using a snapshot for source data, select the
                                        snapshot to use. </entry>
                                </row>
                                <row>
                                    <entry>Remember the Configuration</entry>
                                    <entry>Stores the current preview configuration for use every
                                        time you request a preview for this pipeline. <p>After you
                                            run data preview, you can change this option in the
                                            Preview panel by selecting the Preview Configuration
                                            icon (<image
                                                href="../Graphics/icon_PrevPreviewConfig.png"
                                                id="image_qzd_tnf_vs" scale="80"/>) and clearing the
                                            option. The change takes effect the next time you run
                                            data preview.</p></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
                <stepresult>The Preview panel highlights the origin stage and displays preview data
                    in table view. Since this is the origin of the pipeline, no input data displays.
                        <p>To view preview data in list view, click the <uicontrol>List
                            View</uicontrol> icon: <image href="../Graphics/icon_PrevListView.png"
                            id="image_ids_rc4_xs" scale="80"/>.</p></stepresult>
            </step>
            <step id="DeletePreviewRecord">
                <cmd>To delete a record that you do not want to use, click the
                        <uicontrol>Delete</uicontrol> icon.</cmd>
            </step>
            <step id="RefreshPreview">
                <cmd>To refresh the preview, click the <uicontrol>Refresh Preview</uicontrol> icon:
                        <image href="../Graphics/icon_PrevRefresh.png" id="image_nys_3ff_vs"
                        scale="90"/>.</cmd>
                <info>Based on the origin, refreshing the preview either provides a new set of data
                    or reverts any changes to the existing data.</info>
            </step>
            <step id="RevertRefreshClose2">
                <cmd>To exit data preview and return to pipeline configuration, click
                        <uicontrol>Close Preview</uicontrol>.</cmd>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta">The following step is used in "Previewing a
                        Single Stage" and "Reviewing Snapshot Data"</draft-comment>
                </cmd>
            </step>
            <step id="NextStage">
                <cmd>To view data for the next stage, click the <uicontrol>Next Stage</uicontrol>
                    icon. Or, to view data for a different stage, select the stage in the pipeline
                    canvas.</cmd>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol id="ORIGIN_INFO"
                        >ORIGINS</uicontrol></draft-comment>
                </cmd>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>1stStepErrorHandling</uicontrol> -
                        Use this step for origins that are not cluster origins. Standalone
                        only</draft-comment>
                </cmd>
            </step>
            <step id="1stStepErrorHandling">
                <cmd>In the Properties panel, on the <wintitle>General</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_vlh_bgh_hr">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>General Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Name</entry>
                                    <entry>Stage name.</entry>
                                </row>
                                <row>
                                    <entry>Description</entry>
                                    <entry>Optional description.</entry>
                                </row>
                                <row>
                                    <entry>On Record Error <xref
                                            href="../Pipeline_Design/ErrorHandling-Stage.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_z4j_byn_lw"/></xref></entry>
                                    <entry>Error record handling for the stage: <ul
                                            id="ul_mmh_bgh_hr">
                                            <li>Discard - Discards the record.</li>
                                            <li>Send to Error - Sends the record to the pipeline for
                                                error handling.</li>
                                            <li>Stop Pipeline - Stops the pipeline. </li>
                                        </ul></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>1stStep-ClusterOrigin</uicontrol> -
                        Use for origins that ARE cluster origins - points out stop pipeline is not
                        valid.</draft-comment>
                </cmd>
            </step>
            <step id="1stStep-ClusterOrigin">
                <cmd>In the Properties panel, on the <wintitle>General</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_u44_lsn_xs">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>General Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Name</entry>
                                    <entry>Stage name.</entry>
                                </row>
                                <row>
                                    <entry>Description</entry>
                                    <entry>Optional description.</entry>
                                </row>
                                <row>
                                    <entry>Stage Library</entry>
                                    <entry>Library version that you want to use. </entry>
                                </row>
                                <row>
                                    <entry>On Record Error <xref
                                            href="../Pipeline_Design/ErrorHandling-Stage.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_gyg_4yn_lw"/></xref></entry>
                                    <entry>Error record handling for the stage: <ul
                                            id="ul_mp4_lsn_xs">
                                            <li>Discard - Discards the record.</li>
                                            <li>Send to Error - Sends the record to the pipeline for
                                                error handling.</li>
                                            <li>Stop Pipeline - Stops the pipeline. Not valid for
                                                cluster pipelines.</li>
                                        </ul></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"
                            ><uicontrol>1stStep-StageLib-EHandling</uicontrol> - Use this step for
                        non-cluster origins with stage libraries. </draft-comment>
                </cmd>
            </step>
            <step id="1stStep-StageLib-EHandling">
                <cmd>In the Properties panel, on the <wintitle>General</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_rv1_q3d_3t">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>General Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Name</entry>
                                    <entry>Stage name.</entry>
                                </row>
                                <row>
                                    <entry>Description</entry>
                                    <entry>Optional description.</entry>
                                </row>
                                <row>
                                    <entry>Stage Library</entry>
                                    <entry>Library version that you want to use. </entry>
                                </row>
                                <row>
                                    <entry>On Record Error <xref
                                            href="../Pipeline_Design/ErrorHandling-Stage.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_ur4_4yn_lw"/></xref></entry>
                                    <entry>Error record handling for the stage: <ul
                                            id="ul_kw1_q3d_3t">
                                            <li>Discard - Discards the record.</li>
                                            <li>Send to Error - Sends the record to the pipeline for
                                                error handling.</li>
                                            <li>Stop Pipeline - Stops the pipeline. Not valid for
                                                cluster pipelines.</li>
                                        </ul></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>O-AVROFILE</uicontrol> - The
                        following step is used by any file-based origin that reads from Avro and
                        includes compression – Should be S3, Directory, File Tail, Kinesis Consumer
                        origin? Origins that do not include compression conref rows from here. –
                        Hadoop FS, </draft-comment>
                </cmd>
            </step>
            <step id="O-AVRO-FILE">
                <cmd>For Avro data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_fv4_ggf_lx">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Avro Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row id="O-row-AvroSLocation">
                                    <entry>Avro Schema Location</entry>
                                    <entry>Location of the Avro schema definition to use when
                                        processing data:<ul id="ul_gv4_ggf_lx">
                                            <li>Message/Data Includes Schema - Use the schema in the
                                                file.</li>
                                            <li>In Pipeline Configuration - Use the schema provided
                                                in the stage configuration.</li>
                                            <li>Confluent Schema Registry - Retrieve the schema from
                                                the Confluent Schema Registry.</li>
                                        </ul><p>Using a schema in the stage configuration or in the
                                            Confluent Schema Registry can improve
                                        performance.</p></entry>
                                </row>
                                <row id="O-row-AvroSc">
                                    <entry>Avro Schema</entry>
                                    <entry>Avro schema definition used to process the data.
                                        Overrides any existing schema definitions associated with
                                        the data. <p>You can optionally use the runtime:loadResource
                                            function to use a schema definition stored in a runtime
                                            resource file. </p></entry>
                                </row>
                                <row id="O-row-A-SchemaRegURL">
                                    <entry>Schema Registry URLs</entry>
                                    <entry>Confluent Schema Registry URLs used to look up the
                                        schema. To add a URL, click <uicontrol>Add</uicontrol>. Use
                                        the following format to enter the
                                        URL:<codeblock>http://&lt;host name>:&lt;port number></codeblock></entry>
                                </row>
                                <row id="O-row-A-LookupSchema">
                                    <entry>Lookup Schema By</entry>
                                    <entry>Method used to look up the schema in the Confluent Schema
                                            Registry:<ul id="ul_hv4_ggf_lx">
                                            <li>Subject - Look up the specified Avro schema
                                                subject.</li>
                                            <li>Schema ID - Look up the specified Avro schema ID.
                                            </li>
                                        </ul>Overrides any existing schema definitions associated
                                        with the data. </entry>
                                </row>
                                <row id="O-row-A-SchemaSubj">
                                    <entry>Schema Subject</entry>
                                    <entry>Avro schema subject to look up in the Confluent Schema
                                            Registry.<p>If the specified subject has multiple schema
                                            versions, the origin uses the latest schema version for
                                            that subject. To use an older version, find the
                                            corresponding schema ID, and then set the
                                                <uicontrol>Look Up Schema By</uicontrol> property to
                                            Schema ID.</p></entry>
                                </row>
                                <row id="O-row-A-SchemaID">
                                    <entry>Schema ID</entry>
                                    <entry>Avro schema ID to look up in the Confluent Schema
                                        Registry.</entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>O-AVRO-Mess</uicontrol> - The
                        following step is used by origins that read Avro data from messages and have
                        compression. Kinesis Consumer. Origins without compression uses rows - JMS,
                        Kafka.</draft-comment>
                </cmd>
            </step>
            <step id="O-AVRO-Mess">
                <cmd>For Avro data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_acd_2qd_3t">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Avro Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row id="Mess-row-AvroSchemaLoc">
                                    <entry>Avro Schema Location</entry>
                                    <entry>Location of the Avro schema definition to use when
                                        processing data:<ul id="ul_k2p_vx2_lx">
                                            <li>Message/Data Includes Schema - Use the schema in the
                                                message.</li>
                                            <li>In Pipeline Configuration - Use the schema provided
                                                in the stage configuration.</li>
                                            <li>Confluent Schema Registry - Retrieve the schema from
                                                the Confluent Schema Registry.</li>
                                        </ul><p>Using a schema in the stage configuration or in the
                                            Confluent Schema Registry can improve
                                        performance.</p></entry>
                                </row>
                                <row id="Mess-row-AvroSchema">
                                    <entry>Avro Schema</entry>
                                    <entry>Avro schema definition used to process the data.
                                        Overrides any existing schema definitions associated with
                                        the data. <p>You can optionally use the runtime:loadResource
                                            function to use a schema definition stored in a runtime
                                            resource file. </p></entry>
                                </row>
                                <row id="Mess-row-SchemaReg">
                                    <entry>Schema Registry URLs</entry>
                                    <entry>Confluent Schema Registry URLs used to look up the
                                        schema. To add a URL, click <uicontrol>Add</uicontrol>. Use
                                        the following format to enter the
                                        URL:<codeblock>http://&lt;host name>:&lt;port number></codeblock></entry>
                                </row>
                                <row id="Mess-row-LookupSchema">
                                    <entry>Lookup Schema By</entry>
                                    <entry>Method used to look up the schema in the Confluent Schema
                                            Registry:<ul id="ul_pb1_5df_lx">
                                            <li>Subject - Look up the specified Avro schema
                                                subject.</li>
                                            <li>Schema ID - Look up the specified Avro schema ID. </li>
                                            <li>Embedded Schema ID - Look up the Avro schema ID
                                                embedded in each message.</li>
                                        </ul>Overrides any existing schema definitions associated
                                        with the message. </entry>
                                </row>
                                <row id="Mess-row-SchemaSub">
                                    <entry>Schema Subject</entry>
                                    <entry>Avro schema subject to look up in the Confluent Schema
                                            Registry.<p>If the specified subject has multiple schema
                                            versions, the origin uses the latest schema version for
                                            that subject. To use an older version, find the
                                            corresponding schema ID, and then set the
                                                <uicontrol>Look Up Schema By</uicontrol> property to
                                            Schema ID.</p></entry>
                                </row>
                                <row id="Mess-row-SchemaID">
                                    <entry>Schema ID</entry>
                                    <entry>Avro schema ID to look up in the Confluent Schema
                                        Registry.</entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="alisontaylor"><uicontrol>O-AVRO-KAFKA</uicontrol> used by
                        Kafka Consumer</draft-comment>
                </cmd>
            </step>
            <step id="O-AVRO-KAFKA">
                <cmd>For Avro data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_acd_9qd_4t">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Avro Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Avro Schema Location</entry>
                                    <entry>Location of the Avro schema definition to use when
                                        processing data:<ul id="ul_k6p_vx3_lx">
                                            <li>Message/Data Includes Schema - Use the schema in the
                                                message.</li>
                                            <li>In Pipeline Configuration - Use the schema provided
                                                in the stage configuration.</li>
                                            <li>Confluent Schema Registry - Retrieve the schema from
                                                the Confluent Schema Registry.</li>
                                        </ul><p>Using a schema in the stage configuration or in the
                                            Confluent Schema Registry can improve
                                        performance.</p></entry>
                                </row>
                                <row>
                                    <entry>Avro Schema</entry>
                                    <entry>Avro schema definition used to process the data.
                                        Overrides any existing schema definitions associated with
                                        the data. <p>You can optionally use the runtime:loadResource
                                            function to use a schema definition stored in a runtime
                                            resource file. </p></entry>
                                </row>
                                <row>
                                    <entry>Schema Registry URLs </entry>
                                    <entry>Confluent Schema Registry URLs used to look up the
                                        schema. To add a URL, click <uicontrol>Add</uicontrol>. Use
                                        the following format to enter the
                                        URL:<codeblock>http://&lt;host name>:&lt;port number></codeblock></entry>
                                </row>
                                <row>
                                    <entry>Lookup Schema By</entry>
                                    <entry>Method used to look up the schema in the Confluent Schema
                                            Registry:<ul id="ul_pb2_9df_lx">
                                            <li>Subject - Look up the specified Avro schema
                                                subject.</li>
                                            <li>Schema ID - Look up the specified Avro schema ID. </li>
                                            <li>Embedded Schema ID - Look up the Avro schema ID
                                                embedded in each message. You must configure the
                                                origin to use the Confluent method to deserialize
                                                the messages on the <uicontrol>Kafka</uicontrol>
                                                tab.</li>
                                        </ul>Overrides any existing schema definitions associated
                                        with the message. </entry>
                                </row>
                                <row>
                                    <entry>Schema Subject</entry>
                                    <entry>Avro schema subject to look up in the Confluent Schema
                                            Registry.<p>If the specified subject has multiple schema
                                            versions, the origin uses the latest schema version for
                                            that subject. To use an older version, find the
                                            corresponding schema ID, and then set the
                                                <uicontrol>Look Up Schema By</uicontrol> property to
                                            Schema ID.</p></entry>
                                </row>
                                <row>
                                    <entry>Schema ID</entry>
                                    <entry>Avro schema ID to look up in the Confluent Schema
                                        Registry.</entry>
                                </row>
                                <row>
                                    <entry>Key Deserializer <xref
                                            href="../Origins/KConsumer-DataFormats.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                placement="inline"/></xref></entry>
                                    <entry>Method used to deserialize the Kafka message key.<p>Set
                                            to Confluent when the Avro schema ID is embedded in each
                                            Kafka message. </p></entry>
                                </row>
                                <row>
                                    <entry>Value Deserializer</entry>
                                    <entry>Method used to deserialize the Kafka message value.<p>Set
                                            to Confluent when the Avro schema ID is embedded in each
                                            Kafka message.</p></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>O-Binary </uicontrol>. Used by
                        message reading origins that have compression - Kinesis Consumer, Redis
                        Consumer. Non-compressed origins use rows - JMS, Kafka </draft-comment>
                </cmd>
            </step>
            <step id="O-Binary">
                <cmd>For binary data, on the <wintitle>Data Format</wintitle> tab and configure the
                    following property:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_dpx_kdm_35">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Binary Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Origin-FileCompression">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Origin-FilePatternCompressed">
                                    <entry/>
                                </row>
                                <row id="O-row-Bin-MaxDataSize">
                                    <entry>Max Data Size (bytes)</entry>
                                    <entry>Maximum number of bytes in the message. Larger messages
                                        cannot be processed or written to error. </entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>O-Datagram</uicontrol> - just Kafka
                        Consumer right now.</draft-comment>
                </cmd>
            </step>
            <step id="O-Datagram">
                <cmd>For datagram data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_qrx_zqz_pw">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Datagram Properties</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Data Format <xref
                                            href="../Origins/KConsumer-DataFormats.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                placement="inline" id="image_bmy_h8q_ds"
                                        /></xref></entry>
                                    <entry>Message type: <ul
                                            conref="#task_kzs_5vz_sq/ul-UDPDataFormat"
                                            id="ul_q1q_yp4_4x">
                                            <li/>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry
                                        conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/entry-TypesDBname"/>
                                    <entry><ph
                                            conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/ph-TypesDBinfo"
                                            /><p>For collectd data only.</p></entry>
                                </row>
                                <row>
                                    <entry
                                        conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/entry-HiRestitle"/>
                                    <entry><ph
                                            conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/ph-HiResinfo"
                                            /><p>For collectd data only.</p></entry>
                                </row>
                                <row>
                                    <entry
                                        conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/entry-Exludename"/>
                                    <entry><ph
                                            conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/ph-Excludeinfo"
                                            /><p>For collectd data only.</p></entry>
                                </row>
                                <row>
                                    <entry
                                        conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/entry-Authname"/>
                                    <entry><ph
                                            conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/ph-Authinfo"
                                            /><p>For collectd data only.</p></entry>
                                </row>
                                <row conref="ReusableTables.dita#concept_wfr_rnw_yq/MessagesCharset">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/IgnoreControlChars-row">
                                    <entry/>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>DELIMITED data</uicontrol> - Step
                        used by Delimited origins using compression – S3, Directory, Other Delimited
                        origins use steps. - Hadoop FS origin, JMS Consumer, Kafka
                        Consumer</draft-comment>
                </cmd>
            </step>
            <step id="DelimFILE">
                <cmd>For delimited data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_DelimitedData">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Delimited Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Origin-FileCompression">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Origin-FilePatternCompressed">
                                    <entry/>
                                </row>
                                <row id="O-row-DelimFormatType">
                                    <entry>Delimiter Format Type</entry>
                                    <entry>Delimiter format type. Use one of the following options:
                                            <ul
                                            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/ul_delFileTypes"
                                            id="ul_s5z_b3z_3r">
                                            <li/>
                                        </ul></entry>
                                </row>
                                <row id="O-row-Del-HeaderLine">
                                    <entry>Header Line</entry>
                                    <entry>Indicates whether a file contains a header line, and
                                        whether to use the header line.</entry>
                                </row>
                                <row id="O-row-Del-MaxRecLength">
                                    <entry>Max Record Length (chars)</entry>
                                    <entry>Maximum length of a record in characters. Longer records
                                        are not read. </entry>
                                </row>
                                <row id="O-row-Del-DelChar">
                                    <entry>Delimiter Character</entry>
                                    <entry>Delimiter character for a custom delimiter format. Select
                                        one of the available options or use Other to enter a custom
                                            character.<p>You can enter a Unicode control character
                                            using the format \u<i>NNNN</i>, where ​<i>N</i> is a
                                            hexadecimal digit from the numbers 0-9 or the letters
                                            A-F. For example, enter \u0000 to use the null character
                                            as the delimiter or \u2028 to use a line separator as
                                            the delimiter.</p><p>Default is the pipe character ( |
                                            ).</p></entry>
                                </row>
                                <row id="O-row-Del-EscChar">
                                    <entry>Escape Character</entry>
                                    <entry>Escape character for a custom file type.</entry>
                                </row>
                                <row id="O-row-Del-QuoteChar">
                                    <entry>Quote Character</entry>
                                    <entry>Quote character for a custom file type.</entry>
                                </row>
                                <row id="O-row-Del-RootField">
                                    <entry>Root Field Type <xref
                                            href="../Pipeline_Design/DelimitedDataRootFieldTypes.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_exx_41q_ft"/></xref></entry>
                                    <entry>Root field type to use:<ul id="ul_izr_p1q_ft">
                                            <li>List-Map - Generates an indexed list of data.
                                                Enables you to use standard functions to process
                                                data. Use for new pipelines.</li>
                                            <li>List - Generates a record with an indexed list with
                                                a map for header and value. Requires the use of
                                                delimited data functions to process data. Use only
                                                to maintain pipelines created before 1.1.0.</li>
                                        </ul></entry>
                                </row>
                                <row id="O-row-Del-Lines2skip">
                                    <entry>Lines to Skip</entry>
                                    <entry>Lines to skip before reading data. </entry>
                                </row>
                                <row id="O-row-Del-ParseNulls">
                                    <entry>Parse NULLs</entry>
                                    <entry>Replaces the specified string constant with null
                                        values.</entry>
                                </row>
                                <row id="O-row-Del-NullConstant">
                                    <entry>NULL Constant</entry>
                                    <entry>String constant to replace with null values.</entry>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Charset">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/IgnoreControlChars-row">
                                    <entry/>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><b>JSON-2props </b> - Kafka Consumer, Kinesis
                        all use them. HTTP Client, and probably others use the 2nd row. Non
                        compression origins use rows - JMS Consumer, Kafka Consumer</draft-comment>
                </cmd>
            </step>
            <step id="JSON-2props">
                <cmd>For JSON data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_JSONdata">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>JSON Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Origin-FileCompression">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Origin-FilePatternCompressed">
                                    <entry/>
                                </row>
                                <row id="ROW-JSONContent">
                                    <entry>JSON Content</entry>
                                    <entry>Type of JSON content. Use one of the following options: <p>
                                            <ul id="ul_atw_krl_5q">
                                                <li>Array of Objects </li>
                                                <li>Multiple Objects</li>
                                            </ul>
                                        </p></entry>
                                </row>
                                <row id="ROW-MaxObject">
                                    <entry>Maximum Object Length (chars)</entry>
                                    <entry>Maximum number of characters in a JSON object. <p>Longer
                                            objects are diverted to the pipeline for error handling.
                                        </p></entry>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Charset">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/IgnoreControlChars-row">
                                    <entry/>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>LOG data </uicontrol> - Used in JMS
                        Consumer, Kafka Consumer, Hadoop FS, probably Directory. Use the following
                        for origins that use the Log data format. UL in first row is also being
                        conrefed in Log Parser. </draft-comment>
                </cmd>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta">Also - For any changes to the bullets below this
                        first table, update Log Parser as well. Everything except the Log4j
                        table/bullet point is copied from here. </draft-comment>
                </cmd>
            </step>
            <step id="LogData_Log4j">
                <cmd>For log data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_ihc_3fs_sr">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Log Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Origin-FileCompression">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Origin-FilePatternCompressed">
                                    <entry/>
                                </row>
                                <row id="O-row-LogFormat">
                                    <entry>Log Format</entry>
                                    <entry>Format of the log files. Use one of the following
                                            options:<ul id="ul-LogFormatList">
                                            <li>Common Log Format</li>
                                            <li>Combined Log Format</li>
                                            <li>Apache Error Log Format</li>
                                            <li>Apache Access Log Custom Format</li>
                                            <li>Regular Expression</li>
                                            <li>Grok Pattern</li>
                                            <li>Log4j</li>
                                        </ul></entry>
                                </row>
                                <row id="O-row-MaxLine">
                                    <entry>Max Line Length</entry>
                                    <entry>Maximum length of a log line. The origin truncates longer
                                        lines. </entry>
                                </row>
                                <row id="O-row-RetainOLine">
                                    <entry>Retain Original Line</entry>
                                    <entry>Determines how to treat the original log line. Select to
                                        include the original log line as a field in the resulting
                                            record.<p>By default, the original line is
                                            discarded.</p></entry>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Charset">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/IgnoreControlChars-row">
                                    <entry/>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                    <ul id="ul-LogDetails">
                        <li>When you select <uicontrol>Apache Access Log Custom Format</uicontrol>,
                            use Apache log format strings to define the <uicontrol>Custom Log
                                Format</uicontrol>.</li>
                        <li>When you select <uicontrol>Regular Expression</uicontrol>, enter the
                            regular expression that describes the log format, and then map the
                            fields that you want to include to each regular expression group.</li>
                        <li>When you select <uicontrol>Grok Pattern</uicontrol>, you can use the
                                <uicontrol>Grok Pattern Definition</uicontrol> field to define
                            custom grok patterns. You can define a pattern on each line. <p>In the
                                    <uicontrol>Grok Pattern</uicontrol> field, enter the pattern to
                                use to parse the log. You can use a predefined grok patterns or
                                create a custom grok pattern using patterns defined in
                                    <uicontrol>Grok Pattern Definition</uicontrol>.</p><p>For more
                                information about defining grok patterns and supported grok
                                patterns, see <xref
                                    href="../Apx-GrokPatterns/GrokPatterns.dita#concept_vdk_xjb_wr"
                                />.</p></li>
                        <li>When you select <uicontrol>Log4j</uicontrol>, define the following properties:<p>
                                <table frame="all" rowsep="1" colsep="1" id="table_pzm_rbt_sr">
                                    <tgroup cols="2">
                                        <colspec colname="c1" colnum="1" colwidth="1*"/>
                                        <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                                        <thead>
                                            <row>
                                                <entry>Log4j Property</entry>
                                                <entry>Description</entry>
                                            </row>
                                        </thead>
                                        <tbody>
                                            <row>
                                                <entry>On Parse Error</entry>
                                                <entry>Determines how to handle information that
                                                  cannot be parsed:<ul id="ul_bvm_5bt_sr">
                                                  <li>Skip and Log Error - Skips reading the line
                                                  and logs a stage error.</li>
                                                  <li>Skip, No Error - Skips reading the line and
                                                  does not log an error.</li>
                                                  <li>Include as Stack Trace - Includes information
                                                  that cannot be parsed as a stack trace to the
                                                  previously-read log line. The information is added
                                                  to the message field for the last valid log
                                                  line.</li>
                                                  </ul></entry>
                                            </row>
                                            <row>
                                                <entry>Use Custom Log Format</entry>
                                                <entry>Allows you to define a custom log
                                                  format.</entry>
                                            </row>
                                            <row>
                                                <entry>Custom Format</entry>
                                                <entry>Use log4j variables to define a custom log
                                                  format. </entry>
                                            </row>
                                        </tbody>
                                    </tgroup>
                                </table>
                            </p></li>
                    </ul>
                </info>
            </step>
            <step>
                <cmd/>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>O-PROTO-Mess</uicontrol>. Step used
                        by message-reading stages except for Kafka. Kafka conrefs the first two rows
                        of table. <p>NOTE: When making changes, make sure to update the file version
                            and destination versions, as necessary.</p></draft-comment>
                </cmd>
            </step>
            <step id="O-PROTO-Mess">
                <cmd>For protobuf data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_s3c_mz4_45">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Protobuf Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Origin-FileCompression">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Origin-FilePatternCompressed">
                                    <entry/>
                                </row>
                                <row id="Mess-ProtoDescFile">
                                    <entry>Protobuf Descriptor File </entry>
                                    <entry>Descriptor file (.desc) to use. The descriptor file must
                                        be in the <ph
                                            conref="ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                        /> resources directory,
                                            <codeph>$SDC_RESOURCES</codeph>.<p>For information about
                                            generating the descriptor file, see <xref
                                                href="../Pipeline_Design/Protobuf-Prerequisites.dita"
                                            />. For more information about environment variables,
                                            see <xref
                                                href="../Configuration/DCEnvironmentConfig.dita#concept_rng_qym_qr"
                                            />.</p></entry>
                                </row>
                                <row id="Mess-MessType">
                                    <entry>Message Type</entry>
                                    <entry>The fully-qualified name for the message type to use when
                                        reading data.<p>Use the following format:
                                                <codeph>&lt;package name>.&lt;message
                                            type></codeph>. </p>Use a message type defined in the
                                        descriptor file.</entry>
                                </row>
                                <row id="Mess-DelimMessages">
                                    <entry>Delimited Messages</entry>
                                    <entry>Indicates if a message might include more than one
                                        protobuf message.</entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>O-Proto-File</uicontrol>. Step used
                        by file-based proto. <p>NOTE: When making changes, make sure to update the
                            message version and destination versions, as
                        necessary.</p></draft-comment>
                </cmd>
            </step>
            <step id="O-PROTO-File">
                <cmd>For protobuf data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_f4r_4cp_45">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Protobuf Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Origin-FileCompression">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Origin-FilePatternCompressed">
                                    <entry/>
                                </row>
                                <row>
                                    <entry>Protobuf Descriptor File </entry>
                                    <entry>Descriptor file (.desc) to use. The descriptor file must
                                        be in the <ph
                                            conref="ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                        /> resources directory, <codeph>$SDC_RESOURCES</codeph>.
                                            <p>For more information about environment variables, see
                                                <xref
                                                href="../Configuration/DCEnvironmentConfig.dita#concept_rng_qym_qr"
                                            />. For information about generating the descriptor
                                            file, see <xref
                                                href="../Pipeline_Design/Protobuf-Prerequisites.dita"
                                            />.</p></entry>
                                </row>
                                <row>
                                    <entry>Message Type</entry>
                                    <entry>The fully-qualified name for the message type to use when
                                        reading data.<p>Use the following format:
                                                <codeph>&lt;package name>.&lt;message
                                            type></codeph>. </p>Use a message type defined in the
                                        descriptor file.</entry>
                                </row>
                                <row>
                                    <entry>Delimited Messages</entry>
                                    <entry>Indicates if a file might include more than one protobuf
                                        message.</entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>O-SDCRecord</uicontrol> - Adding to
                        origins that use it. Non-compression origins use rows.</draft-comment>
                </cmd>
            </step>
            <step id="O-SDCRecord">
                <cmd>For SDC Record data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_rtb_csl_wx">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>SDC Record Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Origin-FileCompression">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Origin-FilePatternCompressed">
                                    <entry/>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="alisontaylor"><uicontrol>TEXT_Hadoop data</uicontrol> -
                        Hadoop FS and MapR FS origins (Include Custom Delimiter is not applicable) –
                        should this go in Local FS too? </draft-comment>
                </cmd>
            </step>
            <step id="Text_Hadoop">
                <cmd>For text data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_ney_vwc_fv">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Text Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Max Line Length</entry>
                                    <entry>Maximum number of characters allowed for a line. Longer
                                        lines are truncated.<p>Adds a boolean field to the record to
                                            indicate if it was truncated. The field name is
                                            Truncated. </p></entry>
                                </row>
                                <row>
                                    <entry>Use Custom Delimiter <xref
                                            href="../Pipeline_Design/TextCDelim.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                placement="inline" id="image_f8g_d37_xv"
                                        /></xref></entry>
                                    <entry>Uses custom delimiters to define records instead of line
                                        breaks. </entry>
                                </row>
                                <row>
                                    <entry>Custom Delimiter</entry>
                                    <entry>One or more characters to use to define records. </entry>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Charset">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/IgnoreControlChars-row">
                                    <entry/>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>TEXT data</uicontrol> - Amazon S3,
                        Directory, Kafka Consumer, Kinesis Consumer, JMS Consumer. HTTP Client. Non
                        compression origins using rows - JMS</draft-comment>
                </cmd>
            </step>
            <step id="Text">
                <cmd>For text data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_ngy_vcc_fv">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Text Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Origin-FileCompression">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Origin-FilePatternCompressed">
                                    <entry/>
                                </row>
                                <row id="O-row-MaxLineLength">
                                    <entry>Max Line Length</entry>
                                    <entry>Maximum number of characters allowed for a line. Longer
                                        lines are truncated.<p>Adds a boolean field to the record to
                                            indicate if it was truncated. The field name is
                                            Truncated. </p></entry>
                                </row>
                                <row id="O-row-UseCDelim">
                                    <entry>Use Custom Delimiter <xref
                                            href="../Pipeline_Design/TextCDelim.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                placement="inline" id="image_f2g_d54_xv"
                                        /></xref></entry>
                                    <entry>Uses custom delimiters to define records instead of line
                                        breaks. </entry>
                                </row>
                                <row id="O-row-CustomDelim">
                                    <entry>Custom Delimiter</entry>
                                    <entry>One or more characters to use to define records. </entry>
                                </row>
                                <row id="O-row-IncludeCDelim">
                                    <entry>Include Custom Delimiter</entry>
                                    <entry>Includes delimiter characters in the record.</entry>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Charset">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/IgnoreControlChars-row">
                                    <entry/>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>O-WholeFile</uicontrol> -
                        Directory</draft-comment>
                </cmd>
            </step>
            <step id="O-WholeFile">
                <cmd>For whole files on the <wintitle>Data Format</wintitle> tab, configure the
                    following property:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_ff1_v3h_xw">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Whole File Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Buffer Size (bytes)</entry>
                                    <entry>Size of the buffer to use to transfer data.</entry>
                                </row>
                                <row>
                                    <entry>Rate per Second <xref
                                            href="../Pipeline_Design/WholeFile-TransferRate.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                placement="inline"/></xref></entry>
                                    <entry>Transfer rate to use. <p>Enter a number to specify a rate
                                            in bytes per second. Use an expression to specify a rate
                                            that uses a different unit of measure per second, e.g.
                                            ${5 * MB}. Use -1 to opt out of this property. </p><p>By
                                            default, the origin does not use a transfer rate.
                                        </p></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>O-WholeFile-Checksum</uicontrol> -
                        S3</draft-comment>
                </cmd>
            </step>
            <step id="O-WholeFile-Checksum">
                <cmd>For whole files, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_x5m_5xf_zw">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Whole File Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Buffer Size (bytes)</entry>
                                    <entry>Size of the buffer to use to transfer data.</entry>
                                </row>
                                <row>
                                    <entry>Rate per Second <xref
                                            href="../Pipeline_Design/WholeFile-TransferRate.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                placement="inline" id="image_ljp_wy2_py"
                                        /></xref></entry>
                                    <entry>Transfer rate to use. <p>Enter a number to specify a rate
                                            in bytes per second. Use an expression to specify a rate
                                            that uses a different unit of measure per second, e.g.
                                            ${5 * MB}. Use -1 to opt out of this property. </p><p>By
                                            default, the origin does not use a transfer rate.
                                        </p></entry>
                                </row>
                                <row>
                                    <entry>Verify Checksum</entry>
                                    <entry>Verifies the checksum during the read. </entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>XML data </uicontrol>- step used by
                        message and file based origins: Kafka Consumer, Hadoop FS, Kinesis Consumer,
                        Directory, S3, HTTP Client, maybe more. Origins without compression uses
                        rows - JMS Consumer</draft-comment>
                </cmd>
            </step>
            <step id="XMLprops">
                <cmd>For XML data, on the <wintitle>XML</wintitle> tab, configure the following
                    properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_pmz_mcj_45">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>XML Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Origin-FileCompression">
                                    <entry/>
                                </row>
                                <row id="O-row-XMLDelimElement">
                                    <entry>Delimiter Element <xref
                                            href="../Pipeline_Design/XMLDF-XPath-Syntax.dita#concept_tmc_4bc_dy">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                placement="inline" id="image_xwx_xrm_js"
                                        /></xref></entry>
                                    <entry>
                                        <p>Delimiter to use to generate records. Omit a delimiter to
                                            treat the entire XML document as one record. Use one of
                                            the following:<ul id="XML-ul-delimiterelements">
                                                <li>An XML element directly under the root element.
                                                  <p>Use the XML element name without surrounding
                                                  angle brackets ( &lt; > ) . For example, msg
                                                  instead of &lt;msg>. </p></li>
                                                <li>A simplified XPath expression that specifies the
                                                  data to use.<p>Use a simplified XPath expression
                                                  to access data deeper in the XML document or data
                                                  that requires a more complex access
                                                  method.</p><p>For more information about valid
                                                  syntax, see <xref
                                                  href="../Pipeline_Design/XMLDF-XPath-Syntax.dita#concept_tmc_4bc_dy"
                                                  />.</p></li>
                                            </ul></p>
                                    </entry>
                                </row>
                                <row id="O-row-XMLNamespaces">
                                    <entry>Namespaces </entry>
                                    <entry>Namespace prefix and URI to use when parsing the XML
                                        document. Define namespaces when the XML element being used
                                        includes a namespace prefix or when the XPath expression
                                        includes namespaces.<p>For information about using
                                            namespaces with an XML element, see <xref
                                                href="../Pipeline_Design/XMLDF-XMLelem-Namespace.dita#concept_ilc_r3g_2y"
                                            />.</p><p>For information about using namespaces with
                                            XPath expressions, see <xref
                                                href="../Pipeline_Design/XMLDF-XPath-Namespaces.dita#concept_mkk_3zj_dy"
                                            />.</p><p>Use the <uicontrol>Add</uicontrol> icon to add
                                            additional namespaces.</p></entry>
                                </row>
                                <row id="O-row-XML-MaxRecLength">
                                    <entry>Max Record Length (chars)</entry>
                                    <entry>
                                        <p>The maximum number of characters in a record. Longer
                                            records are diverted to the pipeline for error handling.
                                        </p>
                                    </entry>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Charset">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/IgnoreControlChars-row">
                                    <entry/>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>ORIGIN-MIXED REUSE - </uicontrol>The
                        following handful of steps are for origin/origin, origin/processor or
                        possibly origin/destination reuse. In alphabetical order.</draft-comment>
                    <draft-comment author="Loretta"><uicontrol>HTTPClient-Credentials</uicontrol> -
                        The following steps are used in HTTP Client origin and processor Configuring
                        topics:</draft-comment>
                </cmd>
            </step>
            <step id="HTTPClient-Credentials">
                <cmd>When using authentication, on the <wintitle>Credentials</wintitle> tab,
                    configure the following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_qfx_54h_jw">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Credentials Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Username</entry>
                                    <entry>User name for basic, digest, or universal authentication. </entry>
                                </row>
                                <row>
                                    <entry>Password</entry>
                                    <entry>Password for basic, digest, or universal authentication.
                                            <note
                                            conref="ReusablePhrases.dita#concept_vhs_5tz_xp/Tip_Usernames"
                                        /></entry>
                                </row>
                                <row>
                                    <entry>Consumer Key</entry>
                                    <entry>Consumer key for OAuth 1.0 authentication.</entry>
                                </row>
                                <row>
                                    <entry>Consumer Secret</entry>
                                    <entry>Consumer secret for OAuth 1.0 authentication.</entry>
                                </row>
                                <row>
                                    <entry>Token</entry>
                                    <entry>Consumer token for OAuth 1.0 authentication.</entry>
                                </row>
                                <row>
                                    <entry>Token Secret</entry>
                                    <entry>Token secret for OAuth 1.0 authentication.</entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>HTTPClient-Proxy</uicontrol> - - The
                        following steps are used in HTTP Client origin and processor Configuring
                        topics:</draft-comment>
                </cmd>
            </step>
            <step id="HTTPClient-Proxy">
                <cmd>To use an HTTP proxy, on the <wintitle>Proxy</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_qbv_qz2_2v">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>HTTP Proxy Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Proxy URI</entry>
                                    <entry>Proxy URI.</entry>
                                </row>
                                <row>
                                    <entry>Username</entry>
                                    <entry>Proxy user name.</entry>
                                </row>
                                <row>
                                    <entry>Password</entry>
                                    <entry>Proxy password.<note
                                            conref="ReusablePhrases.dita#concept_vhs_5tz_xp/Tip_Usernames"
                                        /></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>HTTPClient-SSLTLS</uicontrol> - same
                        as above</draft-comment>
                </cmd>
            </step>
            <step id="HTTPClient-SSLTLS">
                <cmd>Optionally, on the <uicontrol>SSL/TLS</uicontrol> tab, configure truststore and
                    keystore details:</cmd>
                <info>
                    <note conref="ReusablePhrases.dita#concept_vhs_5tz_xp/Tip_Passwords"/>
                    <table frame="all" rowsep="1" colsep="1" id="table_cpn_3rh_jw">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>SSL/TLS Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Path to Truststore</entry>
                                    <entry>Absolute path to the truststore. </entry>
                                </row>
                                <row>
                                    <entry>Password</entry>
                                    <entry>Truststore password.</entry>
                                </row>
                                <row>
                                    <entry>Path to Keystore</entry>
                                    <entry>Absolute path to the keystore. </entry>
                                </row>
                                <row>
                                    <entry>Password</entry>
                                    <entry>Keystore password.</entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta">The following steps are used in <uicontrol>JDBC
                            Consumer, JDBC Producer, JDBC Lookup, and JDBC Tee </uicontrol>config
                        topics. <uicontrol>Oracle CDC Client</uicontrol> is using some info from the
                        Credentials table, and the whole Legacy Drivers step.</draft-comment>
                </cmd>
            </step>
            <step id="JDBC-Credentials">
                <cmd>To enter JDBC credentials separately from the JDBC connection string, on the
                        <uicontrol>Credentials</uicontrol> tab, configure the following
                    properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_ybf_v1w_ht">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Credentials Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Username</entry>
                                    <entry>User name for the JDBC connection.</entry>
                                </row>
                                <row id="row-JDBCpassword">
                                    <entry>Password</entry>
                                    <entry>Password for the JDBC account.<note
                                            conref="ReusablePhrases.dita#concept_vhs_5tz_xp/Tip_Usernames"
                                        /></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step id="JDBC-Legacy">
                <cmd>When using JDBC versions older than 4.0, on the <uicontrol>Legacy
                        Drivers</uicontrol> tab, optionally configure the following
                    properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_LogData">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Legacy Driver Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>JDBC Class Driver Name</entry>
                                    <entry>Class name for the JDBC driver. Required for JDBC
                                        versions older than version 4.0.</entry>
                                </row>
                                <row>
                                    <entry>Connection Health Test Query</entry>
                                    <entry>Optional query to test the health of a connection.
                                        Recommended only when the JDBC version is older than 4.0.
                                    </entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta">Rows in this table are used by Kafka Consumer
                        and SDC RPC to Kafka origins, also UDP to Kafka.</draft-comment>
                </cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_pzz_wtr_pw">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Misc Kafka Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row id="O-KafkaBrokerURI">
                                    <entry>Broker URI</entry>
                                    <entry>Connection string for the Kafka broker. Use the following
                                        format: <codeph>&lt;host>:&lt;port></codeph>. <p>To ensure a
                                            connection, enter a comma-separated list of additional
                                            broker URIs.</p></entry>
                                </row>
                                <row id="O-KafkaTopic">
                                    <entry>Topic</entry>
                                    <entry>Kafka topic to read.</entry>
                                </row>
                                <row id="O-KafkaConfig">
                                    <entry>Kafka Configuration <xref
                                            href="../Origins/KConsumer_AdditionalKProp.dita#concept_d5f_n2g_vq">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_mwv_b52_zq"/></xref>
                                    </entry>
                                    <entry>
                                        <p id="p-KafkaConfig1">Additional Kafka configuration
                                            properties to use. To add properties, click
                                                <uicontrol>Add</uicontrol> and define the Kafka
                                            property name and value.</p>
                                        <p id="p-KafkaConfig2">Use the property names and values as
                                            expected by Kafka.</p>
                                        <p id="p-KafkaConfig3">For information about enabling secure
                                            connections to Kafka, see <xref
                                                href="../Origins/KConsumer-EnablingSecurity.dita"
                                            />.</p>
                                    </entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta">The following
                            <uicontrol>O-MongodBconfigs</uicontrol> step is used in the MongoDB
                        origin and rows/entries used by MongoDB Oplog. MongoDB destination might use
                        some too, when I get to it.</draft-comment>
                </cmd>
            </step>
            <step id="O-MongoDBconfigs">
                <cmd>On the <wintitle>MongoDB</wintitle> tab, configure the following
                    properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_mh4_bxs_ns">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3*"/>
                            <thead>
                                <row>
                                    <entry>MongoDB Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row id="row-MongoConnectString">
                                    <entry>Connection String</entry>
                                    <entry>Connection string for the MongoDB instance. Use the
                                        following
                                        format:<codeblock>mongodb://host1[:port1][,host2[:port2],...[,hostN[:portN]]][/[database][?options]]</codeblock>When
                                        connecting to a cluster, enter additional node information
                                        to ensure a connection.</entry>
                                </row>
                                <row id="row-MongoSingleMode">
                                    <entry>Enable Single Mode</entry>
                                    <entry>Select to connect to a single MongoDB server or node. If
                                        multiple nodes are defined in the connection string, the
                                        origin connects only to the first node. <p>Use this option
                                            with care. If the origin cannot connect or the
                                            connection fails, the pipeline stops. </p></entry>
                                </row>
                                <row>
                                    <entry>Database</entry>
                                    <entry>Name of the MongoDB database.</entry>
                                </row>
                                <row>
                                    <entry>Collection</entry>
                                    <entry>Name of the MongoDB collection to use.</entry>
                                </row>
                                <row>
                                    <entry>Capped Collection</entry>
                                    <entry>The collection is capped. Clear this option to read an
                                        uncapped collection.</entry>
                                </row>
                                <row>
                                    <entry>Initial Offset</entry>
                                    <entry>Initial offset to use to begin reading. When using an
                                        Object ID field as the offset field, enter a timestamp with
                                        the following format: <codeph>YYYY-MM-DD hh:mm:ss</codeph>.
                                        When using a string field, enter the string to
                                            use.<p>Default is: 2015-01-01 00:00:00</p></entry>
                                </row>
                                <row>
                                    <entry>Offset Field Type</entry>
                                    <entry>Data type of the offset field. Use Object ID for Object
                                        ID fields. Use String for string offset fields. <p>Default
                                            is Object ID.</p></entry>
                                </row>
                                <row>
                                    <entry>Offset Field <xref
                                            href="../Origins/MongoDB-OffsetField.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_k2w_rsd_3t"/></xref>
                                    </entry>
                                    <entry>Field to use to track reads. Default is the _id field.
                                            <p>You can use a nested offset field, such as o._id, or
                                            any Object ID field or any string field. Results are not
                                            guaranteed for anything but the _id field.</p></entry>
                                </row>
                                <row id="row-Mongo-BatchSize">
                                    <entry>Batch Size (records)</entry>
                                    <entry>Maximum number of records allowed in a batch.</entry>
                                </row>
                                <row>
                                    <entry>Max Batch Wait Time <xref
                                            href="../Origins/BatchSizeWaitTime.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                            /></xref>
                                    </entry>
                                    <entry id="entry-Mongo-BatchWaitTime">Amount of time the origin
                                        will wait to fill a batch before sending an empty batch.
                                    </entry>
                                </row>
                                <row>
                                    <entry>Read Preference <xref
                                            href="../Origins/MongoDB-ReadPreference.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_o23_1rd_ww"/></xref>
                                    </entry>
                                    <entry id="entry-Mongo-ReadPref">Determines how the origin reads
                                        data from different members of the MongoDB replica
                                        set.</entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>RabbitMQ</uicontrol> - Entire step
                        used by Consumer, rows used by Producer</draft-comment>
                </cmd>
            </step>
            <step id="RabbitMQ">
                <cmd>On the <wintitle>RabbitMQ</wintitle> tab, configure the following
                    properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_sdq_nzn_2v">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>RabbitMQ Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row id="Rabbit-URI">
                                    <entry>URI</entry>
                                    <entry>RabbitMQ URI. <p>Typically uses the following format:
                                                <codeph>amqp:&lt;host>:&lt;port>/&lt;virtualhost></codeph>.</p></entry>
                                </row>
                                <row>
                                    <entry>Consumer Tag</entry>
                                    <entry>RabbitMQ consumer tag. Leave empty to use an
                                        automatically generated consumer tag. </entry>
                                </row>
                                <row>
                                    <entry>One Record per Message</entry>
                                    <entry>Generates a single record for each RabbitMQ message.
                                            <p>When not selected, the origin generates a record for
                                            each object in the message. </p></entry>
                                </row>
                                <row id="Rabbit-AddConfig">
                                    <entry>Additional Client Configuration</entry>
                                    <entry>Additional RabbitMQ client configuration properties to
                                        use. To add properties, click <uicontrol>Add</uicontrol> and
                                        define the RabbitMQ client property name and value. <p>Use
                                            the property names and values as expected by RabbitMQ.
                                        </p></entry>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/MaxBatchSize">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/BatchWaitTime">
                                    <entry/>
                                </row>
                                <row id="Rabbit-UseCreds">
                                    <entry>Use Credentials</entry>
                                    <entry>Enables the use of RabbitMQ credentials.</entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step id="Rabbit-CredentialsStep">
                <cmd>On the <wintitle>Credentials</wintitle> tab, enter the RabbitMQ credentials to
                    use if you enabled credentials.</cmd>
                <info>
                    <note conref="ReusablePhrases.dita#concept_vhs_5tz_xp/Tip_Usernames"/>
                </info>
            </step>
            <step id="Rabbit-QueueStep">
                <cmd>On the <wintitle>Queue</wintitle> tab, configure the following queue
                    properties:</cmd>
                <info>These properties directly correspond to RabbitMQ properties. For more
                    information, see the RabbitMQ documentation. <table frame="all" rowsep="1"
                        colsep="1" id="table_sxy_wg4_q5">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Queue Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Name</entry>
                                    <entry>Name of the queue to use or create.</entry>
                                </row>
                                <row>
                                    <entry>Durable</entry>
                                    <entry>Creates a durable queue when selected. <p>The stage
                                            creates a durable queue by default.</p></entry>
                                </row>
                                <row>
                                    <entry>Exclusive</entry>
                                    <entry>Creates an exclusive queue when selected. When exclusive,
                                        the queue allows only the <ph
                                            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                        /> to use it.<p>The stage creates an exclusive queue by
                                            default.</p></entry>
                                </row>
                                <row>
                                    <entry>Auto-Delete</entry>
                                    <entry>Automatically deletes a queue after all consumers
                                        unsubscribe. <p>When used with an exclusive queue, the queue
                                            is automatically deleted when you stop the pipeline.
                                        </p></entry>
                                </row>
                                <row>
                                    <entry>Declaration Properties</entry>
                                    <entry>Additional queue declaration properties to use. </entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table></info>
            </step>
            <step id="Rabbit-ExchangeStep">
                <cmd>On the <wintitle>Exchange</wintitle> tab, optionally configure the following
                    binding properties for the bindings that you want to use. When no bindings are
                    configured, the default exchange is used.</cmd>
                <info>These properties directly correspond to RabbitMQ properties. For more
                    information, see the RabbitMQ documentation. <table frame="all" rowsep="1"
                        colsep="1" id="table_ufb_p34_q5">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Exchange Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Name</entry>
                                    <entry>Binding name.</entry>
                                </row>
                                <row>
                                    <entry>Type</entry>
                                    <entry>Binding type.</entry>
                                </row>
                                <row>
                                    <entry>Durable</entry>
                                    <entry>Creates a durable exchange.</entry>
                                </row>
                                <row>
                                    <entry>Auto-Delete</entry>
                                    <entry>Automatically deletes an exchange when all queues are
                                        finished using it.</entry>
                                </row>
                                <row>
                                    <entry>Routing Key</entry>
                                    <entry>Routing key. <p>Leave empty to default to the queue
                                            name.</p></entry>
                                </row>
                                <row>
                                    <entry>Declaration Properties</entry>
                                    <entry>Additional exchange properties to use.</entry>
                                </row>
                                <row>
                                    <entry>Binding Properties</entry>
                                    <entry>Additional binding properties to use. </entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table></info>
            </step>
            <step id="Rabbit-AdvancedStep">
                <cmd>Optionally configure advanced options on the <wintitle>Advanced</wintitle>
                    tab.</cmd>
                <info>These properties directly correspond to RabbitMQ properties. For more
                    information, see the RabbitMQ documentation. </info>
                <info>Generally, you should use the defaults for these properties:<table frame="all"
                        rowsep="1" colsep="1" id="table_ebg_144_q5">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Advanced Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Automatic Recovery Enabled</entry>
                                    <entry>Determines whether to attempt to reestablish a
                                        connection.</entry>
                                </row>
                                <row>
                                    <entry>Network Recovery Interval</entry>
                                    <entry>Milliseconds to wait before attempting to reestablish a
                                        network connection. <p>Default is 5000.</p></entry>
                                </row>
                                <row>
                                    <entry>Connection Timeout (ms)</entry>
                                    <entry>Milliseconds for the connection to establish. Use 0 to
                                        opt out of a connection timeout. <p>Default is
                                        0.</p></entry>
                                </row>
                                <row>
                                    <entry>Handshake Timeout (ms)</entry>
                                    <entry>Milliseconds for the handshake to complete.</entry>
                                </row>
                                <row>
                                    <entry>Shutdown Timeout (ms)</entry>
                                    <entry>Milliseconds for the shutdown to complete. </entry>
                                </row>
                                <row>
                                    <entry>Heartbeat Timeout (secs)</entry>
                                    <entry>Seconds to wait for a heartbeat to verify that RabbitMQ
                                        is up and the connection still available.<p>Use 0 to avoid
                                            requesting heartbeats. Default is 0.</p></entry>
                                </row>
                                <row>
                                    <entry>Maximum Frame Size (bytes)</entry>
                                    <entry>Maximum frame size in bytes. Use for performance tuning.
                                            <p>Setting a larger value can improve throughput.
                                            Setting a smaller value can improve latency.</p><p>Use 0
                                            for no limit. Default is 0.</p></entry>
                                </row>
                                <row>
                                    <entry>Maximum Channel Number</entry>
                                    <entry>Maximum number of channels allowed. </entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table></info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta">The following is used for SDC RPC origins. Last
                        two rows used by HTTP to Kafka origin</draft-comment>
                </cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_uq4_2rr_pw">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Misc SDC RPC Properties</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row id="row-RPCListPort">
                                    <entry>RPC Listening Port</entry>
                                    <entry id="entry-RPCListPort">Port number to listen to for data.
                                        Must match one of the port numbers associated with the SDC
                                        RPC destination that provides the data.</entry>
                                </row>
                                <row id="row-RPC-ID">
                                    <entry>RPC ID</entry>
                                    <entry id="entry-RPC-ID">User-defined ID. Must match the RPC ID
                                        defined in the SDC RPC destination.</entry>
                                </row>
                                <row id="O-RPC-TLSenabled">
                                    <entry>TLS Enabled <xref
                                            href="../RPC_Pipelines/EnablingEncryption.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                placement="inline" id="image_b2n_wrr_pw"
                                        /></xref></entry>
                                    <entry>Enables the secure transfer of data using TLS (SSL).
                                            <p>To use encryption, both the origin and SDC RPC
                                            destination must be enabled for TLS.</p></entry>
                                </row>
                                <row id="O-RPC-KeystoreFile">
                                    <entry>Keystore File</entry>
                                    <entry>Keystore file for SSL/TLS. <p>Must be stored in the <ph
                                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                            /> resources directory,
                                                <filepath>$SDC_RESOURCES</filepath>. For more
                                            information about environment variables, see <xref
                                                href="../Configuration/DCEnvironmentConfig.dita#concept_rng_qym_qr"
                                            />.</p></entry>
                                </row>
                                <row id="O-RPC-KeystorePass">
                                    <entry>Keystore Password</entry>
                                    <entry>Password for the keystore file.<note
                                            conref="ReusablePhrases.dita#concept_vhs_5tz_xp/Tip_Passwords"
                                        /></entry>
                                </row>
                                <row>
                                    <entry/>
                                    <entry/>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>O-UDPprops</uicontrol> - whole step
                        used by UDP Source. Rows in this table by UDP to Kafka. Data format
                        bulletted list is also used by Configuring the Kafka Consumer > Datagram
                        step.</draft-comment>
                </cmd>
            </step>
            <step id="O-step-UDPprops">
                <cmd>On the <wintitle>UDP</wintitle> tab, configure the following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_ovk_ndv_1s">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3*"/>
                            <thead>
                                <row>
                                    <entry>UDP Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row id="row-UDPport">
                                    <entry>Port</entry>
                                    <entry>Port to listen to for data. To list additional ports,
                                        click the<uicontrol> Add</uicontrol> icon.<note>To listen to
                                            a port below 1024, <ph
                                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                            /> must be run by a user with root privileges.
                                            Otherwise, the operating system does not allow <ph
                                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                            /> to bind to the port.</note></entry>
                                </row>
                                <row>
                                    <entry>Enable Multithreading</entry>
                                    <entry id="entry_EnableMultithreading">On 64-bit Linux,
                                        specifies whether to use multiple receiver threads for each
                                        port. Using multiple receiver threads can improve
                                        performance. <p>Because the multithreading requires native
                                            libraries, it is only available when <ph
                                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                            /> runs on 64-bit Linux.</p></entry>
                                </row>
                                <row>
                                    <entry>Number of Receiver Threads</entry>
                                    <entry id="entry_ReceiverThreads">Number of receiver threads to
                                        use for each port. For example, if you configure two threads
                                        per port and configure the origin to use three ports, the
                                        origin uses a total of six threads.<p>Set to the expected
                                            number of CPU cores of the <ph
                                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                            /> machine that are dedicated to the <ph
                                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                            />.</p><p>Default is 1.</p></entry>
                                </row>
                                <row id="row-UDPdataformat">
                                    <entry>Data Format</entry>
                                    <entry>Data format passed by UDP:<ul id="ul-UDPDataFormat">
                                            <li>collectd</li>
                                            <li>NetFlow</li>
                                            <li>syslog </li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Max Batch Size (messages)</entry>
                                    <entry>Maximum number of messages include in a batch and pass
                                        through the pipeline at one time. Honors values up to the
                                            <ph
                                            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                        /> maximum batch size. <p>Default is 1000. The <ph
                                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                            /> default is 1000.</p></entry>
                                </row>
                                <row>
                                    <entry>Batch Wait Time (ms) <xref
                                            href="../Origins/BatchSizeWaitTime.dita#concept_ypd_vgr_5q">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_mgp_2q3_br" placement="inline"
                                        /></xref></entry>
                                    <entry>Milliseconds to wait before sending a partial or empty
                                        batch.</entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>O-UDP-collectd</uicontrol> - used by
                        UDP Source and entries and ph used in Kafka Consumer.</draft-comment>
                </cmd>
            </step>
            <step id="O-UDP-collectd">
                <cmd>On the <uicontrol>collectd</uicontrol> tab, define the following collectd
                    properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3*"/>
                            <thead>
                                <row>
                                    <entry>collectd Property</entry>
                                    <entry>Properties</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry id="entry-TypesDBname">TypesDB File Path</entry>
                                    <entry><ph id="ph-TypesDBinfo">Path to a user-provided types.db
                                            file. Overrides the default types.db file.</ph>
                                    </entry>
                                </row>
                                <row>
                                    <entry id="entry-HiRestitle">Convert Hi-Res Time &amp;
                                        Interval</entry>
                                    <entry><ph id="ph-HiResinfo">Converts the collectd high
                                            resolution time format interval and timestamp to UNIX
                                            time, in milliseconds.</ph></entry>
                                </row>
                                <row>
                                    <entry id="entry-Exludename">Exclude Interval</entry>
                                    <entry><ph id="ph-Excludeinfo">Excludes the interval field from
                                            output record.</ph></entry>
                                </row>
                                <row>
                                    <entry id="entry-Authname">Auth File</entry>
                                    <entry><ph id="ph-Authinfo">Path to an optional authentication
                                            file. Use an authentication file to accept signed and
                                            encrypted data.</ph>
                                    </entry>
                                </row>
                                <row id="row-Charset">
                                    <entry>Charset</entry>
                                    <entry>Character set of the data.</entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step id="PROCESSORS">
                <cmd>
                    <draft-comment author="Loretta"
                        ><uicontrol>PROCESSORS</uicontrol></draft-comment>
                </cmd>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta">Use this step for processors that have error
                        handling - should be almost all. </draft-comment>
                </cmd>
            </step>
            <step id="1stStep-ReqField-ErrorHandling">
                <cmd>In the Properties panel, on the <wintitle>General</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_blh_n2h_hr">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>General Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Name</entry>
                                    <entry>Stage name.</entry>
                                </row>
                                <row>
                                    <entry>Description</entry>
                                    <entry>Optional description.</entry>
                                </row>
                                <row>
                                    <entry>Required Fields <xref
                                            href="../Pipeline_Design/RequiredFields.dita#concept_dnj_bkm_vq">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_h4p_p5v_yq"/></xref></entry>
                                    <entry>Fields that must include data to be passed into the
                                        stage. <note outputclass="" type="tip">You might include
                                            fields that the stage uses.</note></entry>
                                </row>
                                <row>
                                    <entry>Preconditions <xref
                                            href="../Pipeline_Design/Preconditions.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_f3b_khp_fs"/></xref></entry>
                                    <entry>Conditions that must evaluate to TRUE to allow a record
                                        to enter the stage for processing. Click
                                            <uicontrol>Add</uicontrol> to create additional
                                        preconditions. </entry>
                                </row>
                                <row>
                                    <entry>On Record Error <xref
                                            href="../Pipeline_Design/ErrorHandling-Stage.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_w55_4yn_lw"/></xref></entry>
                                    <entry>Error record handling for the stage: <ul
                                            id="ul_swp_lfh_hr">
                                            <li>Discard - Discards the record.</li>
                                            <li>Send to Error - Sends the record to the pipeline for
                                                error handling.</li>
                                            <li>Stop Pipeline - Stops the pipeline. Not valid for
                                                cluster pipelines.</li>
                                        </ul></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="alisontaylor">Use this step for processors that include a
                        Stage Library field - just Spark Evaluator at this point</draft-comment>
                </cmd>
            </step>
            <step id="1stStep-ReqField-StageLib">
                <cmd>In the Properties panel, on the <wintitle>General</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_blh_n5h_ur">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>General Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Name</entry>
                                    <entry>Stage name.</entry>
                                </row>
                                <row>
                                    <entry>Description</entry>
                                    <entry>Optional description.</entry>
                                </row>
                                <row>
                                    <entry>Stage Library</entry>
                                    <entry>Library version that you want to use. </entry>
                                </row>
                                <row>
                                    <entry>Required Fields <xref
                                            href="../Pipeline_Design/RequiredFields.dita#concept_dnj_bkm_vq">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_h2p_p1v_yq"/></xref></entry>
                                    <entry>Fields that must include data to be passed into the
                                        stage. <note outputclass="" type="tip">You might include
                                            fields that the stage uses.</note></entry>
                                </row>
                                <row>
                                    <entry>Preconditions <xref
                                            href="../Pipeline_Design/Preconditions.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_f6b_kjp_fs"/></xref></entry>
                                    <entry>Conditions that must evaluate to TRUE to allow a record
                                        to enter the stage for processing. Click
                                            <uicontrol>Add</uicontrol> to create additional
                                        preconditions. </entry>
                                </row>
                                <row>
                                    <entry>On Record Error <xref
                                            href="../Pipeline_Design/ErrorHandling-Stage.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_w32_8yn_lw"/></xref></entry>
                                    <entry>Error record handling for the stage: <ul
                                            id="ul_swr_ofh_hr">
                                            <li>Discard - Discards the record.</li>
                                            <li>Send to Error - Sends the record to the pipeline for
                                                error handling.</li>
                                            <li>Stop Pipeline - Stops the pipeline. Not valid for
                                                cluster pipelines.</li>
                                        </ul></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta">Use the rows in this step for processors with
                        event generation and error handling - currently the three scripting
                        processors. Xref to the local Event Generation topic!</draft-comment>
                </cmd>
            </step>
            <step>
                <cmd>In the Properties panel, on the <wintitle>General</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_enz_31h_cy">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>General Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row id="P-row-1stS-Name">
                                    <entry>Name</entry>
                                    <entry>Stage name.</entry>
                                </row>
                                <row id="P-row-1stS-Desc">
                                    <entry>Description</entry>
                                    <entry>Optional description.</entry>
                                </row>
                                <row>
                                    <entry>Produce Events</entry>
                                    <entry id="P-entry-1stS-Events">Generates event records when
                                        events occur. Use for event handling. <xref
                                            href="../Event_Handling/EventFramework-Overview.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_plp_tp2_px"/></xref></entry>
                                </row>
                                <row id="P-row-1stS-ReqFields">
                                    <entry>Required Fields <xref
                                            href="../Pipeline_Design/RequiredFields.dita#concept_dnj_bkm_vq">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_fnz_31h_cy"/></xref></entry>
                                    <entry>Fields that must include data to be passed into the
                                        stage. <note outputclass="" type="tip">You might include
                                            fields that the stage uses.</note></entry>
                                </row>
                                <row id="P-row-1stS-PreCond">
                                    <entry>Preconditions <xref
                                            href="../Pipeline_Design/Preconditions.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_gnz_31h_cy"/></xref></entry>
                                    <entry>Conditions that must evaluate to TRUE to allow a record
                                        to enter the stage for processing. Click
                                            <uicontrol>Add</uicontrol> to create additional
                                        preconditions. </entry>
                                </row>
                                <row id="P-row-1stS-Error">
                                    <entry>On Record Error <xref
                                            href="../Pipeline_Design/ErrorHandling-Stage.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_hnz_31h_cy"/></xref></entry>
                                    <entry>Error record handling for the stage: <ul
                                            id="ul_inz_31h_cy">
                                            <li>Discard - Discards the record.</li>
                                            <li>Send to Error - Sends the record to the pipeline for
                                                error handling.</li>
                                            <li>Stop Pipeline - Stops the pipeline. Not valid for
                                                cluster pipelines.</li>
                                        </ul></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta">Use the following step for processors without
                        record handling - Field Remover, Record Deduplicator.</draft-comment>
                </cmd>
            </step>
            <step id="1stStep-ReqField-noEHandling">
                <cmd>In the Properties panel, on the <wintitle>General</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_wjk_pfh_hr">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>General Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Name</entry>
                                    <entry>Stage name.</entry>
                                </row>
                                <row>
                                    <entry>Description</entry>
                                    <entry>Optional description.</entry>
                                </row>
                                <row>
                                    <entry>Required Fields <xref
                                            href="../Pipeline_Design/RequiredFields.dita#concept_dnj_bkm_vq">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_nkk_pfh_hr"/></xref></entry>
                                    <entry>Fields that must include data to be passed into the
                                        stage. <note outputclass="" type="tip">You might include
                                            fields that the stage uses.</note></entry>
                                </row>
                                <row>
                                    <entry>Preconditions <xref
                                            href="../Pipeline_Design/Preconditions.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_pbl_thp_fs"/></xref></entry>
                                    <entry>Conditions that must evaluate to TRUE to allow a record
                                        to enter the stage for processing. Click
                                            <uicontrol>Add</uicontrol> to create additional
                                        preconditions. </entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step id="DEST_INFO">
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>DESTINATION -
                        General</uicontrol></draft-comment>
                </cmd>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>1stStep-NoStageLib</uicontrol> - Use
                        for destinations without stage libs, e.g. Local FS. </draft-comment>
                </cmd>
            </step>
            <step id="1stStep-NoStageLib">
                <cmd>In the Properties panel, on the <wintitle>General</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_fvw_4kg_j5">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>General Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Name</entry>
                                    <entry>Stage name.</entry>
                                </row>
                                <row>
                                    <entry>Description</entry>
                                    <entry>Optional description.</entry>
                                </row>
                                <row>
                                    <entry>Required Fields <xref
                                            href="../Pipeline_Design/RequiredFields.dita#concept_dnj_bkm_vq">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_lww_4kg_j5"/></xref></entry>
                                    <entry>Fields that must include data to be passed into the
                                        stage. <note outputclass="" type="tip">You might include
                                            fields that the stage uses.</note></entry>
                                </row>
                                <row>
                                    <entry>Preconditions <xref
                                            href="../Pipeline_Design/Preconditions.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_sww_4kg_j5"/></xref></entry>
                                    <entry>Conditions that must evaluate to TRUE to allow a record
                                        to enter the stage for processing. Click
                                            <uicontrol>Add</uicontrol> to create additional
                                        preconditions. </entry>
                                </row>
                                <row>
                                    <entry>On Record Error <xref
                                            href="../Pipeline_Design/ErrorHandling-Stage.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_dpb_pyn_lw"/></xref></entry>
                                    <entry>Error record handling for the stage: <ul
                                            id="ul_fxw_4kg_j5">
                                            <li>Discard - Discards the record.</li>
                                            <li>Send to Error - Sends the record to the pipeline for
                                                error handling.</li>
                                            <li>Stop Pipeline - Stops the pipeline.</li>
                                        </ul></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"
                            ><uicontrol>1stStep-StageLib-ReqField-EHandling</uicontrol> - Use this
                        step for destinations with stage library, req fields, and error handling. –
                        Some rows are used by Hive Metastore. Also using these for executors that
                        don't have event handling.</draft-comment>
                </cmd>
            </step>
            <step id="1stStep-StageLib-ReqField-EHandling">
                <cmd>In the Properties panel, on the <wintitle>General</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_tvy_43h_hr">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>General Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row id="row-Name">
                                    <entry>Name</entry>
                                    <entry>Stage name.</entry>
                                </row>
                                <row id="row-Desc">
                                    <entry>Description</entry>
                                    <entry>Optional description.</entry>
                                </row>
                                <row id="row-StageLib">
                                    <entry>Stage Library</entry>
                                    <entry>Library version that you want to use. </entry>
                                </row>
                                <row>
                                    <entry>Required Fields <xref
                                            href="../Pipeline_Design/RequiredFields.dita#concept_dnj_bkm_vq">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_hwy_43h_hr"/></xref></entry>
                                    <entry>Fields that must include data to be passed into the
                                        stage. <note outputclass="" type="tip">You might include
                                            fields that the stage uses.</note></entry>
                                </row>
                                <row>
                                    <entry>Preconditions <xref
                                            href="../Pipeline_Design/Preconditions.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_rfz_thp_fs"/></xref></entry>
                                    <entry>Conditions that must evaluate to TRUE to allow a record
                                        to enter the stage for processing. Click
                                            <uicontrol>Add</uicontrol> to create additional
                                        preconditions. </entry>
                                </row>
                                <row id="row-RecordError">
                                    <entry>On Record Error <xref
                                            href="../Pipeline_Design/ErrorHandling-Stage.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_lqj_pyn_lw"/></xref></entry>
                                    <entry>Error record handling for the stage: <ul
                                            id="ul_fqw_4fy_kt">
                                            <li>Discard - Discards the record.</li>
                                            <li>Send to Error - Sends the record to the pipeline for
                                                error handling.</li>
                                            <li>Stop Pipeline - Stops the pipeline.</li>
                                        </ul></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>1stStep-D-E-EventHandling</uicontrol>
                        - Used by MapR Jobs executor, HDFS Metadata executor, Hadoop FS
                        destination.</draft-comment>
                </cmd>
            </step>
            <step id="1stStep-D-E-EventHandling">
                <cmd>In the Properties panel, on the <wintitle>General</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_wsl_2rx_mx">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>General Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Name</entry>
                                    <entry>Stage name.</entry>
                                </row>
                                <row>
                                    <entry>Description</entry>
                                    <entry>Optional description.</entry>
                                </row>
                                <row>
                                    <entry>Stage Library</entry>
                                    <entry>Library version that you want to use. </entry>
                                </row>
                                <row>
                                    <entry>Produce Events <xref
                                            href="../Event_Handling/EventGenerationStages.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_wrq_mrx_mx"/></xref></entry>
                                    <entry>Generates event records when events occur. Use for event
                                        handling. <xref
                                            href="../Event_Handling/EventFramework-Overview.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_l15_ft2_px"/></xref></entry>
                                </row>
                                <row>
                                    <entry>Required Fields <xref
                                            href="../Pipeline_Design/RequiredFields.dita#concept_dnj_bkm_vq">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_xsl_2rx_mx"/></xref></entry>
                                    <entry>Fields that must include data to be passed into the
                                        stage. <note outputclass="" type="tip">You might include
                                            fields that the stage uses.</note></entry>
                                </row>
                                <row>
                                    <entry>Preconditions <xref
                                            href="../Pipeline_Design/Preconditions.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_ysl_2rx_mx"/></xref></entry>
                                    <entry>Conditions that must evaluate to TRUE to allow a record
                                        to enter the stage for processing. Click
                                            <uicontrol>Add</uicontrol> to create additional
                                        preconditions. </entry>
                                </row>
                                <row>
                                    <entry>On Record Error <xref
                                            href="../Pipeline_Design/ErrorHandling-Stage.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_zsl_2rx_mx"/></xref></entry>
                                    <entry>Error record handling for the stage: <ul
                                            id="ul_atl_2rx_mx">
                                            <li>Discard - Discards the record.</li>
                                            <li>Send to Error - Sends the record to the pipeline for
                                                error handling.</li>
                                            <li>Stop Pipeline - Stops the pipeline.</li>
                                        </ul></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>D-AVRO-Event</uicontrol> - Used in
                        Flume. Flume doesn't have other compression types, so it's not getting that
                        note. </draft-comment>
                </cmd>
            </step>
            <step id="D-AVRO-Event">
                <cmd>For Avro data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_o1j_7nd_9t">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Avro Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Avro Schema Location</entry>
                                    <entry>Location of the Avro schema definition to use when
                                        writing data:<ul id="ul_mr3_sdg_lx">
                                            <li>In Pipeline Configuration - Use the schema that you
                                                provide in the stage configuration. </li>
                                            <li>In Record Header - Use the schema in the avroSchema
                                                record header attribute. Use only when the
                                                avroSchema attribute is defined for all records.
                                                  <xref
                                                  href="../Pipeline_Design/RecordBasedWrites-overview.dita">
                                                  <image href="../Graphics/icon_moreInfo.png"
                                                  scale="10" id="image_alj_pws_nx"/></xref></li>
                                            <li>Confluent Schema Registry - Retrieve the schema from
                                                the Confluent Schema Registry. </li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Avro Schema</entry>
                                    <entry>Avro schema definition used to write the data. <p>You can
                                            optionally use the runtime:loadResource function to use
                                            a schema definition stored in a runtime resource file.
                                        </p></entry>
                                </row>
                                <row>
                                    <entry>Register Schema</entry>
                                    <entry>Select to register a new Avro schema with the Confluent
                                        Schema Registry.</entry>
                                </row>
                                <row>
                                    <entry>Schema Registry URLs</entry>
                                    <entry>Confluent Schema Registry URLs used to look up the schema
                                        or to register a new schema. To add a URL, click
                                            <uicontrol>Add</uicontrol>. Use the following format to
                                        enter the
                                        URL:<codeblock>http://&lt;host name>:&lt;port number></codeblock></entry>
                                </row>
                                <row>
                                    <entry>Look Up Schema By</entry>
                                    <entry>Method used to look up the schema in the Confluent Schema
                                            Registry:<ul id="ul_t62_m3g_lx">
                                            <li>Subject - Look up the specified Avro schema
                                                subject.</li>
                                            <li>Schema ID - Look up the specified Avro schema ID.
                                            </li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Schema Subject</entry>
                                    <entry>Avro schema subject to look up or to register in the
                                        Confluent Schema Registry.<p>If the specified subject to
                                            look up has multiple schema versions, the origin uses
                                            the latest schema version for that subject. To use an
                                            older version, find the corresponding schema ID, and
                                            then set the <uicontrol>Look Up Schema By</uicontrol>
                                            property to Schema ID.</p></entry>
                                </row>
                                <row>
                                    <entry>Schema ID</entry>
                                    <entry>Avro schema ID to look up in the Confluent Schema
                                        Registry.</entry>
                                </row>
                                <row>
                                    <entry>Include Schema</entry>
                                    <entry>Includes the schema in each event. <note>Omitting the
                                            schema definition can improve performance, but requires
                                            the appropriate schema management to avoid losing track
                                            of the schema associated with the data.</note></entry>
                                </row>
                                <row>
                                    <entry>Avro Compression Codec</entry>
                                    <entry>The Avro compression type to use. <p>When using Avro
                                            compression, do not enable other compression available
                                            in the destination. </p></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>D-AVRO-File</uicontrol> - used in
                        Amazon S3 and other file-based destinations that write avro.</draft-comment>
                </cmd>
            </step>
            <step id="D-AVRO-File">
                <cmd>For Avro data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_o7j_3nd_9t">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Avro Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Avro Schema Location</entry>
                                    <entry>Location of the Avro schema definition to use when
                                        writing data:<ul id="ul_mr6_sdg_lx">
                                            <li>In Pipeline Configuration - Use the schema that you
                                                provide in the stage configuration. </li>
                                            <li>In Record Header - Use the schema in the avroSchema
                                                record header attribute. Use only when the
                                                avroSchema attribute is defined for all records.
                                                  <xref
                                                  href="../Pipeline_Design/RecordBasedWrites-overview.dita">
                                                  <image href="../Graphics/icon_moreInfo.png"
                                                  scale="10" id="image_yjw_4ws_nx"/></xref></li>
                                            <li>Confluent Schema Registry - Retrieve the schema from
                                                the Confluent Schema Registry. </li>
                                        </ul><p>The destination includes the schema definition in
                                            each generated file. </p></entry>
                                </row>
                                <row>
                                    <entry>Avro Schema</entry>
                                    <entry>Avro schema definition used to write the data. <p>You can
                                            optionally use the runtime:loadResource function to use
                                            a schema definition stored in a runtime resource file.
                                        </p></entry>
                                </row>
                                <row>
                                    <entry>Register Schema</entry>
                                    <entry>Select to register a new Avro schema with the Confluent
                                        Schema Registry.</entry>
                                </row>
                                <row>
                                    <entry>Schema Registry URLs</entry>
                                    <entry>Confluent Schema Registry URLs used to look up the schema
                                        or to register a new schema. To add a URL, click
                                            <uicontrol>Add</uicontrol>. Use the following format to
                                        enter the
                                        URL:<codeblock>http://&lt;host name>:&lt;port number></codeblock></entry>
                                </row>
                                <row>
                                    <entry>Look Up Schema By</entry>
                                    <entry>Method used to look up the schema in the Confluent Schema
                                            Registry:<ul id="ul_t38_m6g_lx">
                                            <li>Subject - Look up the specified Avro schema
                                                subject.</li>
                                            <li>Schema ID - Look up the specified Avro schema ID.
                                            </li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Schema Subject</entry>
                                    <entry>Avro schema subject to look up or to register in the
                                        Confluent Schema Registry.<p>If the specified subject to
                                            look up has multiple schema versions, the origin uses
                                            the latest schema version for that subject. To use an
                                            older version, find the corresponding schema ID, and
                                            then set the <uicontrol>Look Up Schema By</uicontrol>
                                            property to Schema ID.</p></entry>
                                </row>
                                <row>
                                    <entry>Schema ID</entry>
                                    <entry>Avro schema ID to look up in the Confluent Schema
                                        Registry.</entry>
                                </row>
                                <row>
                                    <entry>Avro Compression Codec</entry>
                                    <entry>The Avro compression type to use. <p>When using Avro
                                            compression, do not enable other compression available
                                            in the destination. </p></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>D-AVRO-Mess</uicontrol> - Used in all
                        message destinations except for Kafka Producer - ie, Kinesis Producer, MapR
                        Streams, Rabbit MQ Producer.</draft-comment>
                </cmd>
            </step>
            <step id="D-AVRO-Mess">
                <cmd>For Avro data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_o2j_4nd_3t">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Avro Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Avro Schema Location</entry>
                                    <entry>Location of the Avro schema definition to use when
                                        writing data:<ul id="ul_mr5_sdg_lx">
                                            <li>In Pipeline Configuration - Use the schema that you
                                                provide in the stage configuration. </li>
                                            <li>In Record Header - Use the schema in the avroSchema
                                                record header attribute. Use only when the
                                                avroSchema attribute is defined for all records.
                                                  <xref
                                                  href="../Pipeline_Design/RecordBasedWrites-overview.dita">
                                                  <image href="../Graphics/icon_moreInfo.png"
                                                  scale="10" id="image_dsv_nws_nx"/></xref></li>
                                            <li>Confluent Schema Registry - Retrieve the schema from
                                                the Confluent Schema Registry. </li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Avro Schema</entry>
                                    <entry>Avro schema definition used to write the data. <p>You can
                                            optionally use the runtime:loadResource function to use
                                            a schema definition stored in a runtime resource file.
                                        </p></entry>
                                </row>
                                <row>
                                    <entry>Register Schema</entry>
                                    <entry>Select to register a new Avro schema with the Confluent
                                        Schema Registry.</entry>
                                </row>
                                <row>
                                    <entry>Schema Registry URLs</entry>
                                    <entry>Confluent Schema Registry URLs used to look up the schema
                                        or to register a new schema. To add a URL, click
                                            <uicontrol>Add</uicontrol>. Use the following format to
                                        enter the
                                        URL:<codeblock>http://&lt;host name>:&lt;port number></codeblock></entry>
                                </row>
                                <row>
                                    <entry>Look Up Schema By</entry>
                                    <entry>Method used to look up the schema in the Confluent Schema
                                            Registry:<ul id="ul_t54_m2g_lx">
                                            <li>Subject - Look up the specified Avro schema
                                                subject.</li>
                                            <li>Schema ID - Look up the specified Avro schema ID.
                                            </li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Schema Subject</entry>
                                    <entry>Avro schema subject to look up or to register in the
                                        Confluent Schema Registry.<p>If the specified subject to
                                            look up has multiple schema versions, the origin uses
                                            the latest schema version for that subject. To use an
                                            older version, find the corresponding schema ID, and
                                            then set the <uicontrol>Look Up Schema By</uicontrol>
                                            property to Schema ID.</p></entry>
                                </row>
                                <row>
                                    <entry>Schema ID</entry>
                                    <entry>Avro schema ID to look up in the Confluent Schema
                                        Registry.</entry>
                                </row>
                                <row>
                                    <entry>Include Schema</entry>
                                    <entry>Includes the schema in each message. <note>Omitting the
                                            schema definition can improve performance, but requires
                                            the appropriate schema management to avoid losing track
                                            of the schema associated with the data.</note></entry>
                                </row>
                                <row>
                                    <entry>Avro Compression Codec</entry>
                                    <entry>The Avro compression type to use. <p>When using Avro
                                            compression, do not enable other compression available
                                            in the destination. </p></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="alisontaylor"><uicontrol>D-AVRO-KAFKA</uicontrol> used in
                        Kafka Producer</draft-comment>
                </cmd>
            </step>
            <step id="D-AVRO-KAFKA">
                <cmd>For Avro data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_o9j_2nd_7t">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Avro Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Avro Schema Location</entry>
                                    <entry>Location of the Avro schema definition to use when
                                        writing data:<ul id="ul_mr9_sdg_lx">
                                            <li>In Pipeline Configuration - Use the schema that you
                                                provide in the stage configuration. </li>
                                            <li>In Record Header - Use the schema in the avroSchema
                                                record header attribute. Use only when the
                                                avroSchema attribute is defined for all records.
                                                  <xref
                                                  href="../Pipeline_Design/RecordBasedWrites-overview.dita">
                                                  <image href="../Graphics/icon_moreInfo.png"
                                                  scale="10" id="image_fvd_sis_nw"/></xref></li>
                                            <li>Confluent Schema Registry - Retrieve the schema from
                                                the Confluent Schema Registry. </li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Avro Schema</entry>
                                    <entry>Avro schema definition used to write the data. <p>You can
                                            optionally use the runtime:loadResource function to use
                                            a schema definition stored in a runtime resource file.
                                        </p></entry>
                                </row>
                                <row>
                                    <entry>Register Schema</entry>
                                    <entry>Select to register a new Avro schema with the Confluent
                                        Schema Registry.</entry>
                                </row>
                                <row>
                                    <entry>Schema Registry URLs </entry>
                                    <entry>Confluent Schema Registry URLs used to look up the schema
                                        or to register a new schema. To add a URL, click
                                            <uicontrol>Add</uicontrol>. Use the following format to
                                        enter the
                                        URL:<codeblock>http://&lt;host name>:&lt;port number></codeblock></entry>
                                </row>
                                <row>
                                    <entry>Look Up Schema By</entry>
                                    <entry>Method used to look up the schema in the Confluent Schema
                                            Registry:<ul id="ul_t93_m5g_lx">
                                            <li>Subject - Look up the specified Avro schema
                                                subject.</li>
                                            <li>Schema ID - Look up the specified Avro schema ID.
                                            </li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Schema Subject</entry>
                                    <entry>Avro schema subject to look up or to register in the
                                        Confluent Schema Registry.<p>If the specified subject to
                                            look up has multiple schema versions, the origin uses
                                            the latest schema version for that subject. To use an
                                            older version, find the corresponding schema ID, and
                                            then set the <uicontrol>Look Up Schema By</uicontrol>
                                            property to Schema ID.</p></entry>
                                </row>
                                <row>
                                    <entry>Schema ID</entry>
                                    <entry>Avro schema ID to look up in the Confluent Schema
                                        Registry.</entry>
                                </row>
                                <row>
                                    <entry>Include Schema</entry>
                                    <entry>Includes the schema in each message. <note>If you
                                            configured Kafka Producer to embed the Avro schema ID in
                                            each message that it writes, clear this
                                        property.</note></entry>
                                </row>
                                <row>
                                    <entry>Avro Compression Codec</entry>
                                    <entry>The Avro compression type to use. <p>When using Avro
                                            compression, do not enable other compression available
                                            in the destination. </p></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>D-Binary</uicontrol> - Used by Kafka
                        Consumer and Amazon S3 dest.</draft-comment>
                </cmd>
            </step>
            <step id="D-Binary">
                <cmd>For binary data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following property:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_xct_mbm_gt">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Binary Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Binary Field Path</entry>
                                    <entry>Field that contains the binary data.</entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>DelimProps:</uicontrol> Use for the
                        appropriate delimited destinations - currently Amazon S3, Flume, Hadoop FS,
                        Kafka Producer, and Kinesis Firehose:</draft-comment>
                </cmd>
            </step>
            <step id="DelimProps">
                <cmd>For delimited data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_wb3_2kg_br">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Delimited Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Delimiter Format</entry>
                                    <entry>Format for delimited data:<ul
                                            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/ul_delFileTypes"
                                            id="ul_k3j_vvf_jr">
                                            <li/>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Header Line</entry>
                                    <entry>Indicates whether to create a header line.</entry>
                                </row>
                                <row>
                                    <entry>Replace New Line Characters</entry>
                                    <entry>Replaces new line characters with the configured
                                            string.<p>Recommended when writing data as a single line
                                            of text.</p></entry>
                                </row>
                                <row>
                                    <entry>New Line Character Replacement</entry>
                                    <entry>String to replace each new line character. For example,
                                        enter a space to replace each new line character with a
                                        space. <p>Leave empty to remove the new line
                                        characters.</p></entry>
                                </row>
                                <row>
                                    <entry>Delimiter Character</entry>
                                    <entry>Delimiter character for a custom delimiter format. Select
                                        one of the available options or use Other to enter a custom
                                        character. <p>You can enter a Unicode control character
                                            using the format \u<i>NNNN</i>, where ​<i>N</i> is a
                                            hexadecimal digit from the numbers 0-9 or the letters
                                            A-F. For example, enter \u0000 to use the null character
                                            as the delimiter or \u2028 to use a line separator as
                                            the delimiter.</p><p>Default is the pipe character ( |
                                            ).</p></entry>
                                </row>
                                <row>
                                    <entry>Escape Character </entry>
                                    <entry>Escape character for a custom delimiter format. Select
                                        one of the available options or use Other to enter a custom
                                        character. <p>Default is the backslash character ( \
                                        ).</p></entry>
                                </row>
                                <row>
                                    <entry>Quote Character</entry>
                                    <entry>Quote character for a custom delimiter format. Select one
                                        of the available options or use Other to enter a custom
                                        character. <p>Default is the quotation mark character ( "
                                            ).</p></entry>
                                </row>
                                <row conref="ReusableTables.dita#concept_wfr_rnw_yq/D-CHARSET-other">
                                    <entry/>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>JSONProps</uicontrol> - Used for
                        Hadoop FS, Kafka Producer, Amazon S3, Kinesis Producer, and Kinesis
                        Firehose.</draft-comment>
                </cmd>
            </step>
            <step id="JSONProps">
                <cmd>For JSON data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following property:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_lgq_53c_wr">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>JSON Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>JSON Content</entry>
                                    <entry>Determines how JSON data is written:<ul
                                            id="ul_mss_w3c_wr">
                                            <li>JSON Array of Objects - Each file includes a single
                                                array. In the array, each element is a JSON
                                                representation of each record.</li>
                                            <li>Multiple JSON Objects - Each file includes multiple
                                                JSON objects. Each object is a JSON representation
                                                of a record.</li>
                                        </ul></entry>
                                </row>
                                <row conref="ReusableTables.dita#concept_wfr_rnw_yq/D-CHARSET-other">
                                    <entry/>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><b>D-PROTO-props</b> - used by all protobuf
                            destinations<p>NOTE: when making changes, make sure to make any related
                            ones to BOTH origin tables.</p></draft-comment>
                </cmd>
            </step>
            <step id="D-PROTO-props">
                <cmd>For protobuf data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_vmt_tdp_45">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Protobuf Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Protobuf Descriptor File </entry>
                                    <entry>Descriptor file (.desc) to use. The descriptor file must
                                        be in the <ph
                                            conref="ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                        /> resources directory, <codeph>$SDC_RESOURCES</codeph>.
                                            <p>For more information about environment variables, see
                                                <xref
                                                href="../Configuration/DCEnvironmentConfig.dita#concept_rng_qym_qr"
                                            />. For information about generating the descriptor
                                            file, see <xref
                                                href="../Pipeline_Design/Protobuf-Prerequisites.dita"
                                            />.</p></entry>
                                </row>
                                <row>
                                    <entry>Message Type</entry>
                                    <entry>The fully-qualified name for the message type to use when
                                        reading data.<p>Use the following format:
                                                <codeph>&lt;package name>.&lt;message
                                            type></codeph>. </p>Use a message type defined in the
                                        descriptor file.</entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta">SDC Record - not used yet.</draft-comment>
                </cmd>
            </step>
            <step>
                <cmd>For SDC Record data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_fgj_mty_wx">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry/>
                                    <entry/>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry/>
                                    <entry/>
                                </row>
                                <row>
                                    <entry/>
                                    <entry/>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>TextProps</uicontrol> - Using for
                        Hadoop FS, Kafka Producer, and Amazon S3.</draft-comment>
                </cmd>
            </step>
            <step id="TextProps">
                <cmd>For text data, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_egv_3df_jr">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Text Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Text Field Path</entry>
                                    <entry>Field that contains the text data to be written. All data
                                        must be incorporated into the specified field. </entry>
                                </row>
                                <row>
                                    <entry>Record Separator</entry>
                                    <entry>Characters to use to separate records. Use any valid Java
                                        string literal. For example, when writing to Windows, you
                                        might use \r\n to separate records. <p>By default, the
                                            destination uses \n.</p></entry>
                                </row>
                                <row>
                                    <entry>Insert Record Separator if No Text</entry>
                                    <entry>When a record does not include the text field, inserts
                                        the configured record separator string to create an empty
                                            line.<p>When not selected, records without the text
                                            field are discarded.</p></entry>
                                </row>
                                <row conref="ReusableTables.dita#concept_wfr_rnw_yq/D-CHARSET-other">
                                    <entry/>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd/>
                <info>
                    <draft-comment author="Loretta"><b>D-WHOLEFile-props</b> - Whole table used by
                        Hadoop FS, Local FS, and MapR FS. Rows used by S3 and Azure Data Lake
                        Store</draft-comment>
                </info>
            </step>
            <step id="D-WholeFile_props">
                <cmd>For whole files, on the <wintitle>Data Format</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_amd_xml_zw">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Whole File Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row id="row-FileNameExp">
                                    <entry>File Name Expression</entry>
                                    <entry>
                                        <p>Expression to use for the file names. </p>
                                        <p>For tips on how to name files based on input file names,
                                            see <xref
                                                href="../Pipeline_Design/WholeFile-Writing.dita#concept_a2s_4jw_1x"
                                            />.</p>
                                    </entry>
                                </row>
                                <row id="row-PermExp">
                                    <entry>Permissions Expression <xref
                                            href="../Pipeline_Design/WholeFile-AccessPermissions.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_zwb_ccw_1x"/></xref></entry>
                                    <entry>Expression that defines the access permissions for output
                                        files. Expressions should evaluate to a symbolic or
                                        numeric/octal representation of the permissions you want to
                                        use. <p>By default, with no specified expression, files use
                                            the default permissions of the destination system.
                                            </p><p>To use the original source file access
                                            permissions, use the following expression:
                                            <codeblock>${record:value('/fileInfo/permissions')}</codeblock></p></entry>
                                </row>
                                <row id="row-FileExists">
                                    <entry>File Exists</entry>
                                    <entry>Action to take when a file of the same name already
                                        exists in the output directory. Use one of the following
                                            options:<ul id="ul_a4s_l5l_zw">
                                            <li>Send to Error - Handles the record based on stage
                                                error record handling. </li>
                                            <li>Overwrite - Overwrites the existing file.</li>
                                        </ul></entry>
                                </row>
                                <row id="row-IncludeChecksum">
                                    <entry>Include Checksum in Events <xref
                                            href="../Pipeline_Design/WholeFile-IncludingChecksumEvent.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_fyz_ywp_vx"/></xref></entry>
                                    <entry>Includes checksum information in whole file event
                                        records. <p>Use only when the destination generates event
                                            records. </p></entry>
                                </row>
                                <row id="row-ChecksumAlgo">
                                    <entry>Checksum Algorithm</entry>
                                    <entry>Algorithm to generate the checksum.</entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd/>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>DESTINATION -
                        Specific</uicontrol></draft-comment>
                </cmd>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>FS-OutputFiles</uicontrol> - Hadoop
                        FS, Local FS and MapR FS conref rows/partial rows in the table. Data Lake
                        Store also steals rows and entries from here. </draft-comment>
                </cmd>
            </step>
            <step id="FS-OutputFiles">
                <cmd>On the <wintitle>Output Files</wintitle> tab, configure the following
                    options:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_lpp_dd1_s5">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Output Files Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Idle Timeout (secs)</entry>
                                    <entry id="entry-IdleTimeout">Maximum time that an output file
                                        can remain idle. After no records are written to a file for
                                        this amount of time, the destination closes the file. Enter
                                        a time in seconds or use the <codeph>MINUTES</codeph> or
                                            <codeph>HOURS</codeph> constant in an expression to
                                        define the time increment.<p>Use -1 to set no limit. Default
                                            is 1 hour, defined as follows: <codeph>${1 *
                                                HOURS}</codeph>. </p><p>Not available when using the
                                            whole file data format. </p></entry>
                                </row>
                                <row id="row-FileType">
                                    <entry>File Type</entry>
                                    <entry>Output file type:<ul id="ul_pzp_dd1_s5">
                                            <li>Text files</li>
                                            <li>Sequence files</li>
                                            <li>Whole files - Select when using the whole file data
                                                format.</li>
                                        </ul></entry>
                                </row>
                                <row id="row-DataFormat">
                                    <entry>Data Format</entry>
                                    <entry id="entry-HDFSdataformat">Format of data to be written.
                                        Use one of the following options:<ul id="ul_vzp_dd1_s5">
                                            <li>Avro</li>
                                            <li>Binary</li>
                                            <li>Delimited</li>
                                            <li>JSON</li>
                                            <li>Protobuf</li>
                                            <li>Text</li>
                                            <li>Whole File <xref
                                                  href="../Pipeline_Design/WholeFile.dita">
                                                  <image href="../Graphics/icon_moreInfo.png"
                                                  scale="10" placement="inline"
                                                  id="image_ylz_vsm_zw"/></xref></li>
                                        </ul></entry>
                                </row>
                                <row id="row-FilePrefix">
                                    <entry>File Prefix</entry>
                                    <entry>Prefix to use for output files. Use when writing to a
                                        directory that receives files from other sources.<p>Uses the
                                            prefix sdc-${sdc:id()} by default. The prefix evaluates
                                            to sdc-&lt;<ph
                                                conref="ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                            /> ID>. </p><p>The <ph
                                                conref="ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                            /> ID is stored in the following file:
                                                <filepath>$SDC_DATA/sdc.id</filepath>. For more
                                            information about environment variables, see <xref
                                                href="../Configuration/DCEnvironmentConfig.dita#concept_rng_qym_qr"
                                            />.</p></entry>
                                </row>
                                <row id="row-FileSuffix">
                                    <entry>File Suffix</entry>
                                    <entry>Suffix to use for output files, such as txt or json. When
                                        used, the destination adds a period and the configured
                                        suffix as follows: &lt;filename>.&lt;suffix>.<p>You can
                                            include periods within the suffix, but do not start the
                                            suffix with a period. Forward slashes are not
                                            allowed.</p><p>Not available for the whole file data
                                            format. </p></entry>
                                </row>
                                <row id="row-DirectoryinHeader">
                                    <entry>Directory in Header <xref
                                            href="../Pipeline_Design/RecordBasedWrites-overview.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_ydt_vvg_1w"/></xref>
                                    </entry>
                                    <entry>Indicates that the target directory is defined in record
                                        headers. Use only when the targetDirectory header attribute
                                        is defined for all records. </entry>
                                </row>
                                <row id="row-DirectoryTemplate">
                                    <entry>Directory Template <xref
                                            href="../Destinations/HadoopFS-DirectoryTemplates.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_c1q_dd1_s5"/></xref></entry>
                                    <entry id="entry-DirectoryTemplate">Template for creating output
                                        directories. You can use constants, field values, and
                                        datetime variables. <p>Output directories are created based
                                            on the smallest datetime variable in the
                                        template.</p></entry>
                                </row>
                                <row id="row-DataTimeZone">
                                    <entry>Data Time Zone</entry>
                                    <entry>Time zone for the destination system. Used to resolve
                                        datetimes in the directory template and evaluate where
                                        records are written.</entry>
                                </row>
                                <row id="row-TimeBasis">
                                    <entry>Time Basis <xref
                                            href="../Destinations/HadoopFS-TimeBasis.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_f1q_dd1_s5"/></xref></entry>
                                    <entry id="entry-TimeBasis">Time basis to use for creating
                                        output directories and writing records to the directories.
                                        Use one of the following expressions:<ul id="ul_h1q_dd1_s5">
                                            <li>${time:now()} - Uses the processing time as the time
                                                basis. </li>
                                            <li>${record:value(&lt;date field path>)} - Uses the
                                                time associated with the record as the time
                                                basis.</li>
                                        </ul></entry>
                                </row>
                                <row id="row-MaxRecords">
                                    <entry>Max Records in a File</entry>
                                    <entry>Maximum number of records to be written to an output
                                        file. Additional records are written to a new file. <p>Use 0
                                            to opt out of this property. </p><p>Not available when
                                            using the whole file data format. </p></entry>
                                </row>
                                <row id="row-MaxFileSize">
                                    <entry>Max File Size (MB)</entry>
                                    <entry>Maximum size of an output file. Additional records are
                                        written to a new file. <p>Use 0 to opt out of this property.
                                            </p><p>Not available when using the whole file data
                                            format. </p></entry>
                                </row>
                                <row id="row-CCodec">
                                    <entry>Compression Codec</entry>
                                    <entry>Compression type for output files:<ul id="ul_o1q_dd1_s5">
                                            <li>None </li>
                                            <li>gzip</li>
                                            <li>bzip2</li>
                                            <li>Snappy</li>
                                            <li>LZ4</li>
                                            <li>Other</li>
                                        </ul></entry>
                                </row>
                                <row id="row-CCodecClass">
                                    <entry>Compression Codec Class</entry>
                                    <entry>Full class name of the other compression codec that you
                                        want to use. </entry>
                                </row>
                                <row id="row-SequenceFileKey">
                                    <entry>Sequence File Key</entry>
                                    <entry>Record key for creating sequence files. Use one of the
                                        following options:<ul id="ul_v1q_dd1_s5">
                                            <li>${record:value(&lt;field path>)}</li>
                                            <li>${uuid()}</li>
                                        </ul></entry>
                                </row>
                                <row id="row-CompressionType">
                                    <entry>Compression Type</entry>
                                    <entry>Compression type for sequence files when using a
                                        compression codec:<ul id="ul_bbq_dd1_s5">
                                            <li>Block Compression</li>
                                            <li>Record Compression</li>
                                        </ul></entry>
                                </row>
                                <row id="row-RollAttri">
                                    <entry>Use Roll Attribute <xref
                                            href="../Pipeline_Design/RecordBasedWrites-overview.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                            /></xref>
                                    </entry>
                                    <entry>Checks the record header for the roll header attribute
                                        and closes the current file when the roll attribute exists.
                                            <p>Can be used with Max Records in a File and Max File
                                            Size to close files.</p></entry>
                                </row>
                                <row id="row-RollAttrName">
                                    <entry>Roll Attribute Name</entry>
                                    <entry>Name of the roll header attribute.<p>Default is
                                        roll.</p></entry>
                                </row>
                                <row id="row-ValidateHDFSPerms">
                                    <entry>Validate HDFS Permissions</entry>
                                    <entry id="D-entry-ValidatePermissions">When you start the
                                        pipeline, the destination tries writing to the configured
                                        directory template to validate permissions. The pipeline
                                        does not start if validation fails.<note>Do not use this
                                            option when the directory template uses expressions to
                                            represent the entire directory.</note></entry>
                                </row>
                                <row>
                                    <entry>Skip File Recovery</entry>
                                    <entry id="entry-SkipRecovery">Determines whether the
                                        destination performs file recovery after an unexpected stop
                                        of the pipeline. </entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta">Elasticsearch properties - all used by
                        Elasticsearch destination. All but Default Operation and Unsupported
                        Operation Handling used by Configuring a Pipeline > Error handling. Default
                        Operation and Unsupported Operation Handling descriptions used by Kudu, JDBC
                        Producer and JDBC Tee</draft-comment>
                </cmd>
            </step>
            <step id="ELASTICprops-Step">
                <cmd>On the <wintitle>Elasticsearch</wintitle> tab, configure the following
                    properties:</cmd>
                <info id="ElasticProps-Info">
                    <table frame="all" rowsep="1" colsep="1" id="table_ht4_x5v_4r">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Elasticsearch Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row id="row_ElasticCluster">
                                    <entry>Cluster HTTP URI</entry>
                                    <entry>Use when the cluster uses a custom HTTP URI. Use the
                                        following format:
                                            <codeblock>&lt;host>:&lt;port></codeblock><p>Unless
                                            configured, the destination uses the default HTTP URI to
                                            verify that the cluster version is compatible with the
                                            destination libraries.</p></entry>
                                </row>
                                <row id="row_ElasticHTTP">
                                    <entry>Additional HTTP Params</entry>
                                    <entry>Additional HTTP parameters that you want to send as
                                        querystring parameters to Elasticsearch. Enter the exact
                                        parameter name and value expected by Elasticsearch.</entry>
                                </row>
                                <row>
                                    <entry>Detect Additional Nodes in Cluster</entry>
                                    <entry>
                                        <p>Detects additional nodes in the cluster based on the
                                            configured Cluster URI. </p>
                                        <p>Selecting this property is the equivalent to setting the
                                            client.transport.sniff Elasticsearch property to true. </p>
                                        <p>Use only when the Data Collector shares the same network
                                            as the Elasticsearch cluster. Do not use for Elastic
                                            Cloud or Docker clusters. </p>
                                    </entry>
                                </row>
                                <row id="row_ElasticSecurity">
                                    <entry>Use Security</entry>
                                    <entry>Specifies whether security is enabled on the
                                        Elasticsearch cluster. </entry>
                                </row>
                                <row id="row_ElasticTime">
                                    <entry>Time Basis <xref
                                            href="../Destinations/Elastic-TimeBasis.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_w4w_q3p_ht"/>
                                        </xref></entry>
                                    <entry>
                                        <p>Time basis to use for writing to time-based indexes. Use
                                            one of the following expressions:<ul id="ul_wbn_qdt_r5">
                                                <li><codeph>${time:now()}</codeph> - Uses the
                                                  processing time as the time basis. The processing
                                                  time is the time associated with the <ph
                                                  conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                                  /> running the pipeline. </li>
                                                <li>An expression that calls a field and resolves to
                                                  a datetime value, such as
                                                  <codeph>${record:value(&lt;date field
                                                  path>)}</codeph>. Uses the datetime result as the
                                                  time basis. </li>
                                            </ul></p>
                                        <p>When the Index definition does not include datetime
                                            variables, you can ignore this property. </p>
                                        <p>Default is <codeph>${time:now()}</codeph>.</p>
                                    </entry>
                                </row>
                                <row id="row_ElasticZone">
                                    <entry>Data Time Zone</entry>
                                    <entry>Time zone for the destination system. Used to resolve
                                        datetimes in time-based indexes. </entry>
                                </row>
                                <row id="row_ElasticIndex">
                                    <entry>Index</entry>
                                    <entry>Index information for the generated documents. You can
                                        use a constant, datetime variables, a field that includes
                                        the index information, or any valid combination. <p>When
                                            using datetime variables, make sure to configure the
                                            time basis appropriately. For details about datetime
                                            variables, see <xref
                                                href="../Expression_Language/DateTimeVariables.dita#concept_gh4_qd2_sv"
                                            />.</p></entry>
                                </row>
                                <row id="row_ElasticMapping">
                                    <entry>Mapping</entry>
                                    <entry>Mapping information for the generated documents. You can
                                        use a constant or a field that includes the mapping
                                        information. </entry>
                                </row>
                                <row id="row_ElasticDocID">
                                    <entry>Document ID <xref
                                            href="../Destinations/Elastic-DocID.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_r1f_gfg_z3"/>
                                        </xref></entry>
                                    <entry>ID for the record. Use to specify the ID for the
                                        generated documents. When you do not specify an ID,
                                        Elasticsearch creates an ID for each document.<p>By default,
                                            the destination allows Elasticsearch to create the
                                            ID.</p></entry>
                                </row>
                                <row id="row_ElasticCharset">
                                    <entry>Data Charset</entry>
                                    <entry>
                                        <p>Character encoding of the data to be processed. </p>
                                    </entry>
                                </row>
                                <row>
                                    <entry>Default Operation <xref
                                            href="../Destinations/Elastic-DefineOperation.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_r1f_ggg_z5"/>
                                        </xref></entry>
                                    <entry id="entry_DefaultOperation">Default CRUD operation to
                                        perform if the sdc.operation.type record header attribute is
                                        not set. </entry>
                                </row>
                                <row>
                                    <entry>Unsupported Operation Handling</entry>
                                    <entry id="entry_UnsupportedOperation">Action to take when the
                                        CRUD operation type defined in the sdc.operation.type record
                                        header attribute is not supported:<ul id="ul_sgk_pg3_1y">
                                            <li>Discard - Discards the record.</li>
                                            <li>Send to Error - Sends the record to the pipeline for
                                                error handling.</li>
                                            <li>Use Default Operation - Writes the record to the
                                                destination system using the default operation.</li>
                                        </ul></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step id="ElasticSHIELD-step">
                <cmd>If you enabled security, on the <wintitle>Security</wintitle> tab, configure
                    the following property:</cmd>
                <info id="ElasticSHIELD-Info">
                    <table frame="all" rowsep="1" colsep="1" id="table_jsk_fhg_z5">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Security Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Security Username/Password</entry>
                                    <entry>Elasticsearch username and password. <p>Enter the
                                            username and password using the following
                                            syntax:<codeblock>&lt;username>:&lt;password></codeblock></p><note
                                            conref="ReusablePhrases.dita#concept_vhs_5tz_xp/Tip_Usernames"
                                        /></entry>
                                </row>
                                <row>
                                    <entry>SSL Truststore Path</entry>
                                    <entry>
                                        <p>Location of the truststore file. </p>
                                        <p>Configuring this property is the equivalent to
                                            configuring the shield.ssl.truststore.path Elasticsearch
                                            property. </p>
                                        <p>Not necessary for Elastic Cloud clusters. </p>
                                    </entry>
                                </row>
                                <row>
                                    <entry>SSL Truststore Password</entry>
                                    <entry>
                                        <p>Password for the truststore file. </p>
                                        <p>Configuring this property is the equivalent to
                                            configuring the shield.ssl.truststore.password
                                            Elasticsearch property. </p>
                                        <p>Not necessary for Elastic Cloud clusters. </p>
                                    </entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>FS-LateRecords</uicontrol> - for
                        Hadoop FS and Local FS</draft-comment>
                </cmd>
            </step>
            <step id="FS-LateRecords">
                <cmd>On the <wintitle>Late Records</wintitle> tab, configure the following
                    properties:</cmd>
                <info>
                    <note type="tip">These properties are relevant for a time basis based on the
                        time of a record. If you use processing time as the time basis, set the late
                        record time limit to one second.</note>
                    <table frame="all" rowsep="1" colsep="1" id="table_wv3_xzd_br">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Late Records Property <xref
                                            href="../Destinations/HadoopFS-LateRecordHandling.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_skv_3kw_45"/>
                                        </xref>
                                    </entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Late Record Time Limit (secs)</entry>
                                    <entry>Time limit for output directories to accept data. <p>You
                                            can enter a time in seconds, or use the expression to
                                            enter a time in hours. You can also use MINUTES in the
                                            default expression to define the time in minutes.
                                        </p></entry>
                                </row>
                                <row>
                                    <entry>Late Record Handling</entry>
                                    <entry>Determines how to handle late records:<ul
                                            id="ul_gx4_c12_br">
                                            <li>Send to error - Sends the record to the stage for
                                                error handling. </li>
                                            <li>Send to late records file - Sends the record to a
                                                late records file.</li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Late Record Directory Template <xref
                                            href="../Destinations/HadoopFS-DirectoryTemplates.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_blv_3kw_45"/></xref></entry>
                                    <entry>Template for creating late record directories. You can
                                        use constants, field values, and datetime variables.
                                            <p>Output directories are created based on the smallest
                                            datetime variable in the template.</p></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>KafkaConfig</uicontrol> - used for
                        the Kafka Producer - Kafka tab properties. Rows in the table are used for
                        Configuring a Pipeline, error handling > Write to Kafka, and DPM chapter >
                        Aggregated Statistics > Configuring a Pipeline to Aggregate Statistics. --
                        Message per Batch also used by RabbitMQ Producer. Some rows also used by
                        MapR Streams Producer.</draft-comment>
                </cmd>
            </step>
            <step id="KafkaConfig">
                <cmd>On the <wintitle>Kafka</wintitle> tab, configure the following
                    properties:</cmd>
                <info>
                    <p>
                        <table frame="all" rowsep="1" colsep="1" id="KafkaTableProperties">
                            <tgroup cols="2">
                                <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                                <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                                <thead>
                                    <row>
                                        <entry>Kafka Properties</entry>
                                        <entry>Description</entry>
                                    </row>
                                </thead>
                                <tbody>
                                    <row id="KPBrokerURI">
                                        <entry>Broker URI</entry>
                                        <entry>Connection string for the Kafka broker. Use the
                                            following format:
                                                <codeph>&lt;host>:&lt;port></codeph>.<p>To ensure a
                                                connection, enter a comma-separated list of
                                                additional broker URI.</p></entry>
                                    </row>
                                    <row id="KPRuntimeTopic">
                                        <entry>Runtime Topic Resolution <xref
                                                href="../Destinations/KProducer-RuntimeResolution.dita"
                                                  ><image href="../Graphics/icon_moreInfo.png"
                                                  scale="10" id="image_ekt_x5g_cs"/>
                                            </xref></entry>
                                        <entry id="KPRuntimeTopicEntry">Evaluates an expression at
                                            runtime to determine the topic to use for each
                                            record.</entry>
                                    </row>
                                    <row id="KPTopic">
                                        <entry>Topic</entry>
                                        <entry>Topic to use. <p>Not available when using runtime
                                                topic resolution.</p></entry>
                                    </row>
                                    <row id="KPTopicEx">
                                        <entry>Topic Expression</entry>
                                        <entry>Expression used to determine where each record is
                                            written when using runtime topic resolution. Use an
                                            expression that evaluates to a topic name. </entry>
                                    </row>
                                    <row id="KPTopicWList">
                                        <entry>Topic White List</entry>
                                        <entry>List of valid topic names to write to when using
                                            runtime topic resolution. Use to avoid writing to
                                            invalid topics. Records that resolve to invalid topic
                                            names are passed to the stage for error handling. <p>Use
                                                an asterisk (*) to allow writing to any topic name.
                                                By default, all topic names are valid.</p></entry>
                                    </row>
                                    <row id="KPPartStrategy">
                                        <entry>Partition Strategy </entry>
                                        <entry>Strategy to use to write to partitions:<ul
                                                id="ul_tq2_yr3_br">
                                                <li>Round Robin - Takes turns writing to different
                                                  partitions.</li>
                                                <li>Random - Writes to partitions randomly.</li>
                                                <li>Expression - Uses an expression to write data to
                                                  different partitions. </li>
                                                <li>Default - Uses the default partition strategy
                                                  that Kafka provides.</li>
                                            </ul></entry>
                                    </row>
                                    <row id="KPPartExpr">
                                        <entry>Partition Expression <xref
                                                href="../Destinations/KProducer-PartitionStrategy.dita#concept_qpm_xp4_4r">
                                                <image href="../Graphics/icon_moreInfo.png"
                                                  scale="10" id="image_as2_sc1_ft"/></xref></entry>
                                        <entry id="KPPartExpr_entry">Expression to use when using
                                            the expression partition strategy. <p>Define the
                                                expression to evaluate to the partition where you
                                                want each record written. Partition numbers start
                                                with 0.</p><p
                                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/EEditor"
                                            /></entry>
                                    </row>
                                    <row id="KPOneMessPBatch">
                                        <entry>One Message per Batch</entry>
                                        <entry>For each batch, writes the records to each partition
                                            as a single message. </entry>
                                    </row>
                                    <row id="KPKConfigs">
                                        <entry>Kafka Configuration</entry>
                                        <entry>Additional Kafka properties to use. Click the
                                                <uicontrol>Add</uicontrol> icon and define the Kafka
                                            property name and value. <p>Use the property names and
                                                values as expected by Kafka. Do not use the
                                                broker.list property.</p><p>For information about
                                                enabling secure connections to Kafka, see <xref
                                                  href="Reusable_Topics/Kafka-EnablingSecurity.dita"
                                                />.</p></entry>
                                    </row>
                                    <row>
                                        <entry>Key Serializer <xref
                                                href="../Destinations/KProducer-DataFormat.dita">
                                                <image href="../Graphics/icon_moreInfo.png"
                                                  scale="10" id="image_as8_sc7_ft"/></xref></entry>
                                        <entry>Method used to serialize the Kafka message key when
                                            the configured data format is Avro. <p>Set to Confluent
                                                to embed the Avro schema ID in each message that
                                                Kafka Producer writes. </p></entry>
                                    </row>
                                    <row>
                                        <entry>Value Serializer</entry>
                                        <entry>Method used to serialize the Kafka message value when
                                            the configured data format is Avro. <p>Set to Confluent
                                                to embed the Avro schema ID in each message that
                                                Kafka Producer writes.</p></entry>
                                    </row>
                                </tbody>
                            </tgroup>
                        </table>
                    </p>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta">MapRStreams-props - used by MapR Streams
                        Producer and Info tag used by Configuring a Pipeline > Write to MapR
                        Streams. </draft-comment>
                </cmd>
            </step>
            <step id="MAPRStreams-Step">
                <cmd>On the <wintitle>MapR Streams Producer</wintitle> tab, configure the following
                    properties:</cmd>
                <info id="MapRStreams-Info">
                    <table frame="all" rowsep="1" colsep="1" id="table_izf_lxn_2v">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>MapR Streams Producer Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row
                                    conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/KPRuntimeTopic">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/KPTopic">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/KPTopicEx">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/KPTopicWList">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/KPPartStrategy">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/KPPartExpr">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/KPOneMessPBatch">
                                    <entry/>
                                </row>
                                <row>
                                    <entry>MapR Streams Configuration <xref
                                            href="../Destinations/MapRStreamsProd-AddProps.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_dgb_pns_2v"/></xref>
                                    </entry>
                                    <entry>Additional configuration properties to use. To add
                                        properties, click <uicontrol>Add</uicontrol> and define the
                                        property name and value. <p>Use the property names and
                                            values as expected by MapR.</p><p>You can use MapR
                                            Streams properties and set of Kafka properties supported
                                            by MapR Streams. </p></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>RPCdest</uicontrol> - Used for Config
                        RPC Dest and pipeline error handling > Write to pipeline.</draft-comment>
                </cmd>
            </step>
            <step id="RPCdest">
                <cmd>On the <wintitle>RPC</wintitle> tab, configure the following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_pcc_mgx_dt">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>RPC Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row id="row-RPCconnect">
                                    <entry>SDC RPC Connection <xref
                                            href="../Destinations/RPCdest-Connections.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                placement="inline" id="image_bb2_k4b_ft"
                                        /></xref></entry>
                                    <entry>Connection information for the destination pipeline to
                                        continue processing data. Use the following format:
                                            <codeph>&lt;host>:&lt;port></codeph>. <p>Use a single
                                            RPC connection for each destination pipeline. Add
                                            additional connections as needed.</p><p>Use the port
                                            number when you configure the SDC RPC origin that
                                            receives the data.</p></entry>
                                </row>
                                <row id="row-RPCID">
                                    <entry>SDC RPC ID</entry>
                                    <entry>User-defined ID to allow the destination to pass data to
                                        an SDC RPC origin. Use this ID in all SDC RPC origins to
                                        process data from the destination.</entry>
                                </row>
                                <row id="row-SSLenabled">
                                    <entry>TLS Enabled <xref
                                            href="../RPC_Pipelines/EnablingEncryption.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                placement="inline" id="image_a5x_jzn_vs"
                                        /></xref></entry>
                                    <entry>Enables the secure transfer of data using TLS. <p>To use
                                            encryption, both the SDC RPC origin and SDC RPC
                                            destination must be enabled for TLS.</p></entry>
                                </row>
                                <row id="row-TrustStore">
                                    <entry>Truststore File</entry>
                                    <entry>Truststore file for TLS. Required if the keystore file is
                                        a self-signed certificate.<p>Must be stored in the <ph
                                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                            /> resources directory,
                                                <filepath>$SDC_RESOURCES</filepath>. For more
                                            information about environment variables, see <xref
                                                href="../Configuration/DCEnvironmentConfig.dita#concept_rng_qym_qr"
                                            />.</p></entry>
                                </row>
                                <row id="row-TSpass">
                                    <entry>Truststore Password</entry>
                                    <entry>Password for the truststore file.<note
                                            conref="ReusablePhrases.dita#concept_vhs_5tz_xp/Tip_Passwords"
                                        /></entry>
                                </row>
                                <row id="row-verifyHost">
                                    <entry>Verify Host in Server Certificate</entry>
                                    <entry id="entry-verifyHost">Verifies the host in the SDC RPC origin keystore
                                        file.</entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="Loretta"><uicontrol>RPCdestAdv </uicontrol>- Used in RPC
                        destination &amp; pipeline error config - write to pipeline.</draft-comment>
                </cmd>
            </step>
            <step id="RPCadv">
                <cmd>On the <wintitle>Advanced</wintitle> tab, configure the following
                    properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_mhd_nd1_ft">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Advanced Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row id="row-RetriesBatch">
                                    <entry>Retries Per Batch</entry>
                                    <entry>Number of times the destination tries to write a batch to
                                        the SDC RPC origin. <p id="p-RetriesBatch">When the destination cannot write the
                                            batch within the configured number of retries, it fails
                                            the batch.</p><p id="p-RetriesBatchDefault">Default is 3.</p></entry>
                                </row>
                                <row id="row-BackOffPeriod">
                                    <entry>Back Off Period</entry>
                                    <entry>Milliseconds to wait before retrying writing a batch to
                                        the SDC RPC origin.<p id="p-BackOffExample">The value that you enter increases
                                            exponentially after each retry. For example, if you set
                                            the back off period to 10, the destination attempts the
                                            first retry after waiting 10 milliseconds, attempts the
                                            second retry after waiting 100 milliseconds, and
                                            attempts the third retry after waiting 1,000
                                            milliseconds. Set to 0 to retry
                                            immediately.</p><p id="p-BackOffDefault">Default is 0.</p></entry>
                                </row>
                                <row id="row-ConTimeout">
                                    <entry>Connection Timeout (ms)</entry>
                                    <entry>Milliseconds to establish a connection to the SDC RPC
                                        origin. <p>The destination retries the connection based on
                                            the Retries Per Batch property.</p><p>Default is 5000
                                            milliseconds.</p></entry>
                                </row>
                                <row id="row-ReadTimeout">
                                    <entry>Read Timeout (ms)</entry>
                                    <entry>Milliseconds to wait for the SDC RPC origin to read data
                                        from a batch. <p id="p-ReadTimeout">The destination retries the write based on
                                            the Retries Per Batch property.</p><p id="p-ReadTimeoutDefault">Default is 2000
                                            milliseconds.</p></entry>
                                </row>
                                <row id="row-UseCompression">
                                    <entry>Use Compression <xref
                                            href="../Destinations/RPC-Compression.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                placement="inline"/></xref></entry>
                                    <entry>Enables the destination to use compression to pass data
                                        to the SDC RPC origin. Enabled by default. </entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="alisontaylor">The following steps are used in "Step 1.
                        Install the StreamSets Custom Service Descriptor" in the Installation
                        chapter and the Upgrade chapter.</draft-comment>
                </cmd>
            </step>
            <step id="CSDInstallDownload">
                <cmd>Use the following URL to download the CSD from the StreamSets website: <xref
                        href="https://streamsets.com/opensource" format="html" scope="external"
                    />.</cmd>
            </step>
            <step id="CSDInstallPath">
                <cmd>Copy the <ph
                        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                    /> CSD file to the<uicontrol> Local Descriptor Repository Path</uicontrol>. By
                    default, the path is <codeph>/opt/cloudera/csd</codeph>.</cmd>
                <info>To verify the path to use, in Cloudera Manager, click <menucascade>
                        <uicontrol>Administration</uicontrol>
                        <uicontrol>Settings</uicontrol>
                    </menucascade>. In the navigation panel, select the <uicontrol>Custom Service
                        Descriptors</uicontrol> category. Place the CSD file in the path configured
                    for <uicontrol>Local Descriptor Repository Path</uicontrol>. </info>
            </step>
            <step id="CSDInstallFileOwnership">
                <cmd>Set the file ownership to <codeph>cloudera-scm:cloudera-scm</codeph> with
                    permission <uicontrol>644</uicontrol>. </cmd>
                <info>For example:
                    <codeblock>chown cloudera-scm:cloudera-scm /opt/cloudera/csd/STREAMSETS*.jar
chmod 644 /opt/cloudera/csd/STREAMSETS*.jar</codeblock></info>
            </step>
            <step id="CSDInstallRestart">
                <cmd>Use one of the following commands to restart Cloudera Manager Server:</cmd>
                <info><p>For Ubuntu and CentOS 6:
                        <codeblock>service cloudera-scm-server restart</codeblock></p>For CentOS 7:
                    <codeblock>systemctl restart cloudera-scm-server</codeblock></info>
            </step>
            <step id="CSDInstallRestartService">
                <cmd>In Cloudera Manager, to restart the Cloudera Management Service, click <menucascade>
                        <uicontrol>Home</uicontrol>
                        <uicontrol>Status</uicontrol>
                    </menucascade>. To the right of Cloudera Management Service, click the
                        <uicontrol>Menu</uicontrol> icon and select
                    <uicontrol>Restart</uicontrol>.</cmd>
            </step>
            <step>
                <cmd>
                    <draft-comment author="alisontaylor">The following steps are used in "Step 2.
                        Manually Install the Parcel and Checksum Files (Optional)" used in the
                        Installation and Upgrade chapters.</draft-comment>
                </cmd>
            </step>
            <step id="ParcelDownload">
                <cmd>Download the StreamSets parcel and related checksum file for the Cloudera
                    Manager Server operating system from the following location:</cmd>
                <info><xref href="https://archives.streamsets.com/index.html" format="html"
                        scope="external"/></info>
            </step>
            <step id="ParcelRepoPath">
                <cmd>Copy the StreamSets parcel and checksum files to the <uicontrol>Cloudera
                        Manager Local Parcel Repository Path</uicontrol>. </cmd>
                <info>By default, the path is <codeph>/opt/cloudera/parcel-repo</codeph>.</info>
                <info>To verify the path to use, click <menucascade>
                        <uicontrol>Administration</uicontrol>
                        <uicontrol>Settings</uicontrol>
                    </menucascade>. In the navigation panel, select the
                        <uicontrol>Parcels</uicontrol> category. Place the StreamSets parcel file in
                    the path configured for <uicontrol>Local Parcel Repository Path</uicontrol>.
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="alisontaylor">The following steps are used for the
                        Enabling SSL topics for the MongoDB origin and destination, and for the
                        Configuring Secure Connections to LDAP topic in Configuration
                        chapter</draft-comment>
                </cmd>
            </step>
            <step id="MongoDBEnableSSL_step1">
                <cmd>In the <uicontrol>Advanced</uicontrol> tab for the stage, select the
                        <uicontrol>SSL Enabled</uicontrol> property.</cmd>
            </step>
            <step id="MongoDBEnableSSL_step2">
                <cmd>Define the following options in the SDC_JAVA_OPTS environment variable in the
                    Data Collector environment configuration file:</cmd>
                <choices id="choices_vwy_pg2_ww">
                    <choice><codeph>javax.net.ssl.trustStore</codeph> - path to truststore
                        file</choice>
                    <choice><codeph>javax.net.ssl.trustStorePassword</codeph> - truststore
                        password</choice>
                </choices>
                <info>
                    <p conref="ReusablePhrases.dita#concept_vhs_5tz_xp/EnvFileLocation"/>
                    <p>For example, define the options as
                        follows:<codeblock>export SDC_JAVA_OPTS="<b class="+ topic/ph hi-d/b ">-Djavax.net.ssl.trustStore=&lt;path to truststore file> -Djavax.net.ssl.trustStorePassword=&lt;password></b> 
-Xmx1024m  -Xms1024m -server ${SDC_JAVA_OPTS}"                   </codeblock></p>
                    <p>Or to secure the password, save the password in a text file and then define
                        the truststore password option as follows:
                            <codeph>-Djavax.net.ssl.trustStorePassword=$(cat
                            passwordfile.txt)</codeph></p>
                </info>
            </step>
            <step id="MongoDBEnableSSL_step3">
                <cmd>Restart <ph
                        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                    /> to enable the changes.</cmd>
            </step>
            <step>
                <cmd>
                    <draft-comment author="alisontaylor">The following step is used for the MongoDB
                        origin and destination configuring topics.</draft-comment>
                </cmd>
            </step>
            <step id="MongoDB_Credentials_step">
                <cmd>To enter credentials, click the <uicontrol>Credentials</uicontrol> tab and
                    configure the following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_bdl_csd_3t">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Credentials</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Authentication Type</entry>
                                    <entry>Authentication to use. To use authentication, select
                                        Username/Password.</entry>
                                </row>
                                <row>
                                    <entry>Username</entry>
                                    <entry>MongoDB user name.</entry>
                                </row>
                                <row>
                                    <entry>Password</entry>
                                    <entry>MongoDB password.<note
                                            conref="ReusablePhrases.dita#concept_vhs_5tz_xp/Tip_Usernames"
                                        /></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>
                    <draft-comment author="alisontaylor">The following two steps are reused in the
                        Tarball and RPM upgrade section - Update the Configuration
                        Files</draft-comment>
                </cmd>
            </step>
            <step id="MainConfigFile">
                <cmd>Compare the previous and new versions of the <codeph>sdc.properties</codeph>
                    file, and update the new file as needed with the same customized property
                    values.</cmd>
            </step>
            <step id="RemainingConfigFiles">
                <cmd>Compare the previous and new versions of the remaining files, and update the
                    new files as needed with the same customized property values:</cmd>
                <info>
                    <ul>
                        <li>The appropriate realm.properties file, based on the authentication type
                            that you use.</li>
                        <li><codeph>email-password.txt</codeph></li>
                        <li>keystore files</li>
                        <li>LDAP files</li>
                        <li>log4j properties file</li>
                        <li>security policy file</li>
                        <li>Vault properties file</li>
                    </ul>
                </info>
            </step>
            <step>
                <cmd> </cmd>
            </step>
        </steps>
    </taskbody>
</task>
