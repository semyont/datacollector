
<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />        
      <meta name="copyright" content="(C) Copyright 2005" /><meta name="DC.rights.owner" content="(C) Copyright 2005" /><meta name="DC.Type" content="concept" /><meta name="DC.Title" content="Destinations" /><meta name="abstract" content="A destination stage represents the target for a pipeline. You can use one or more destinations in a pipeline." /><meta name="description" content="A destination stage represents the target for a pipeline. You can use one or more destinations in a pipeline." /><meta name="DC.Relation" scheme="URI" content="../Destinations/Destinations-title.html" /><meta name="DC.Format" content="XHTML" /><meta name="DC.Identifier" content="concept_hpr_twm_jq" /><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>Destinations</title><!--  Generated with Oxygen version 18.1, build number 2016112217.  --><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/skins/skin.css" /><link rel="stylesheet" type="text/css" href="../skin.css" /><script type="text/javascript"><!--
            
            var prefix = "../index.html";
            
            --></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.11.3.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.highlight-3.js"><!----></script><script type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
</head>
<body onload="highlightSearchTerm()" class="frmBody">
<table class="nav"><tbody><tr><td colspan="2"><div id="printlink"><a href="javascript:window.print();" title="Print this page"></a></div><div id="permalink"><a href="#" title="Link to this page"></a></div></td></tr><tr><td style="width:75%;"><span class="topic_breadcrumb_links"><span class="topic_breadcrumb_link"><a class="navheader_parent_path" href="../Destinations/Destinations-title.html" title="Destinations">Destinations</a></span></span></td><td><span id="topic_navigation_links" class="navheader">
<span class="navparent"><a class="link" href="../Destinations/Destinations-title.html" title="Destinations"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Destinations</span></a></span>  </span></td></tr></tbody></table>
<div class="nested0" id="concept_hpr_twm_jq">
 <h1 class="title topictitle1">Destinations</h1>

 
 <div class="body conbody"><p class="shortdesc">A destination stage represents the target for a pipeline. You can use one or more
    destinations in a pipeline.</p>

  <div class="p">You can use the following
      types of destinations in a pipeline: <ul class="ul" id="concept_hpr_twm_jq__ul_mxz_jxm_jq">
        <li class="li"><a class="xref" href="AmazonS3.html#concept_avx_bnq_rt" title="The Amazon S3 destination writes data to Amazon S3. To write data to an Amazon Kinesis Firehose delivery system, use the Kinesis Firehose destination. To write data to Amazon Kinesis Streams, use the Kinesis Producer destination.">Amazon S3</a> - Writes data to Amazon
          S3. </li>

        <li class="li"><a class="xref" href="DataLakeStore.html#concept_jzm_kf4_zx">Azure Data Lake Store</a> - Writes
          data to the Azure Data Lake Store.</li>

        <li class="li"><a class="xref" href="Cassandra.html#concept_hfy_mfd_sr" title="The Cassandra destination writes data to a Cassandra cluster.">Cassandra</a> - Writes data to a
          Cassandra cluster.</li>

        <li class="li"><a class="xref" href="Elasticsearch.html#concept_u5t_vpv_4r" title="The Elasticsearch destination writes data to an Elasticsearch cluster, including Elastic Cloud clusters (formerly Found clusters) and Shield-enabled clusters. The destination uses the Elasticsearch HTTP API to write each record to Elasticsearch as a document.">Elasticsearch</a> - Writes data to
          an Elasticsearch cluster.</li>

        <li class="li"><a class="xref" href="Flume.html#concept_pzn_hl4_yr" title="The Flume destination writes data to a Flume source. When you write data to Flume, you pass data to a Flume client. The Flume client passes data to hosts based on client configuration properties.">Flume</a> - Writes data to a Flume
          source.</li>

        <li class="li"><a class="xref" href="Bigtable.html#concept_pl5_tmq_tx" title="The Google Bigtable destination writes data to Google Cloud Bigtable.">Google Bigtable</a> - Writes data to
          Google Cloud Bigtable.</li>

        <li class="li"><a class="xref" href="HadoopFS-destination.html#concept_awl_4km_zq" title="You can use Kerberos authentication to connect to HDFS. When you use Kerberos authentication, Data Collector uses the Kerberos principal and keytab to connect to HDFS. You can configure the Hadoop FS destination to use an HDFS user to write data to HDFS.">Hadoop FS</a> - Writes data
          to the Hadoop Distributed File System (HDFS).</li>

        <li class="li"><a class="xref" href="HBase.html#concept_wsz_5t5_vr" title="The HBase destination writes data to an HBase cluster. The destination can write data to HBase as text, binary data, or JSON strings. You can define the data format for each column written to HBase.">HBase</a> - Writes data to an HBase
          cluster.</li>

        <li class="li"><a class="xref" href="HiveMetastore.html#concept_gcr_z2t_zv" title="The Hive Metastore destination works with the Hive Metadata processor and the Hadoop FS or MapR FS destination as part of the Drift Synchronization Solution for Hive.">Hive Metastore</a> - Creates and
          updates Hive tables as needed.</li>

        <li class="li"><a class="xref" href="Hive.html#concept_kvs_3hh_ht" title="The Hive Streaming destination writes data to Hive tables stored in the ORC (Optimized Row Columnar) file format.">Hive Streaming</a> - Writes data to
          Hive.</li>

        <li class="li"><a class="xref" href="InfluxDB.html#concept_inf_db_sr" title="The InfluxDB destination writes data to an InfluxDB database.">InfluxDB</a> - Writes data to
          InfluxDB.</li>

        <li class="li"><a class="xref" href="JDBCProducer.html#concept_kvs_3hh_ht" title="The JDBC Producer destination uses a JDBC connection to write data to a database table. You can also use the JDBC Producer to write change capture data from a Microsoft SQL Server change log.">JDBC Producer</a> - Writes data to
          JDBC.</li>

        <li class="li"><a class="xref" href="KProducer.html#concept_oq2_5jl_zq" title="The Kafka Producer destination writes data to a Kafka cluster.">Kafka Producer</a> - Writes data to a
          Kafka cluster.</li>

        <li class="li"><a class="xref" href="KinFirehose.html#concept_bjv_dpk_kv" title="The Kinesis Firehose destination writes data to an Amazon Kinesis Firehose delivery stream. Firehose automatically delivers the data to the Amazon S3 bucket or Amazon Redshift table that you specify in the delivery stream.">Kinesis Firehose</a> - Writes data
          to a Kinesis Firehose delivery stream.</li>

        <li class="li"><a class="xref" href="KinProducer.html#concept_swk_h1j_yr" title="The Kinesis Producer destination writes data to Amazon Kinesis Streams. To write data to an Amazon Kinesis Firehose delivery system, use the Kinesis Firehose destination. To write data to Amazon S3, use the Amazon S3 destination.">Kinesis Producer</a> - Writes data
          to Kinesis Streams.</li>

        <li class="li"><a class="xref" href="Kudu.html#concept_chy_xxg_4v" title="The Kudu destination writes data to a Kudu cluster.">Kudu</a> - Writes data to Kudu.</li>

        <li class="li"><a class="xref" href="LocalFS.html#concept_zvc_bv5_1r">Local FS</a> - Writes data to a local
          file system. </li>

        <li class="li"><a class="xref" href="MapRDB.html#concept_vxg_w2z_yv" title="The MapR DB destination writes data to MapR DB binary tables. The destination can write data to MapR DB as text, binary data, or JSON strings. You can define the data format for each column written to MapR DB.">MapR DB</a> - Writes data as text, binary
          data, or JSON strings to MapR DB binary tables.</li>

        <li class="li"><a class="xref" href="MapRDBJSON.html#concept_i4h_2kj_dy" title="The MapR DB JSON destination writes data as JSON documents to MapR DB JSON tables. The destination converts each record into a JSON document and writes the document to the JSON table that you specify.">MapR DB JSON</a> - Writes data as JSON documents to
          MapR DB JSON tables.</li>

        <li class="li"><a class="xref" href="MapRFS.html#concept_spv_xlc_fv" title="The MapR FS destination writes files to MapR FS. You can write the data to MapR as flat files or Hadoop sequence files.">MapR FS</a> - Writes data to MapR
          FS.</li>

        <li class="li"><a class="xref" href="MapRStreamsProd.html#concept_cfj_qbn_2v" title="The MapR Streams Producer destination writes messages to MapR Streams.">MapR Streams Producer</a> -
          Writes data to MapR Streams.</li>

        <li class="li"><a class="xref" href="MongoDB.html#concept_eth_k5n_4v">MongoDB</a> - Writes data to
          MongoDB.</li>

        <li class="li"><a class="xref" href="MongoDB.html#concept_eth_k5n_4v">Rabbit MQ Producer</a> - Writes data to
          RabbitMQ.</li>

        <li class="li"><a class="xref" href="Redis.html#concept_ktc_gw2_gw" title="The Redis destination writes data to Redis.">Redis</a> - Writes data to Redis.</li>

        <li class="li"><a class="xref" href="Salesforce.html#concept_rlb_rt3_rx" title="The Salesforce destination writes data to Salesforce objects.">Salesforce</a> - Writes data to
          Salesforce.</li>

        <li class="li"><a class="xref" href="SDC_RPCdest.html#concept_lfk_hx2_ct" title="The SDC RPC destination enables connectivity between two SDC RPC pipelines. The SDC RPC destination passes data to one or more SDC RPC origins. Use the SDC RPC destination as part of an SDC RPC origin pipeline.">SDC RPC</a> - Passes data to an SDC
          RPC origin in an SDC RPC pipeline.</li>

        <li class="li"><a class="xref" href="Solr.html#concept_lfk_hx2_ct">Solr</a> - Writes data to a Solr node or
          cluster.</li>

        <li class="li"><a class="xref" href="ToError.html#concept_ryn_v3z_lr" title="The To Error destination passes records to the pipeline for error handling. Use the To Error destination to send a stream of records to pipeline error handling.">To Error</a> - Passes records to the
          pipeline for error handling.</li>

        <li class="li"><a class="xref" href="Trash.html#concept_htf_ydj_wq" title="The Trash destination discards records. Use the Trash destination as a visual representation of records discarded from the pipeline. Or, you might use the Trash destination during development as a temporary placeholder.">Trash</a> - Removes records from the
          pipeline.</li>

        <li class="li"><a class="xref" href="WaveAnalytics.html#concept_hlx_r53_rx" title="The Wave Analytics destination writes data to Salesforce Wave Analytics. The destination connects to Wave Analytics to create a dataset with external data.">Wave Analytics</a> - Writes data
          to Salesforce Wave Analytics.</li>

      </ul>
To help create or test pipelines, you can use the following development destination:<ul class="ul" id="concept_hpr_twm_jq__ul_wvk_p3f_lx">
        <li class="li">To Event</li>

      </ul>
</div>

    <p class="p">For more information, see <a class="xref" href="../Pipeline_Design/DevStages.html#concept_czx_ktn_ht">Development Stages</a>.</p>

 </div>

<div class="related-links"></div>
</div>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../Destinations/Destinations-title.html" title="Destinations"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Destinations</span></a></span>  </div><div class="footer" id="webhelp_copyright_information"><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script></div>
</body>
</html>