<?xml version="1.0" encoding="UTF-8"?><toc xmlns="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml"><title><span xmlns="http://www.w3.org/1999/xhtml" class="booktitle">  <span class="ph mainbooktitle">Data Collector User Guide</span>  </span></title><topic href="Getting_Started/GettingStarted_Title.html#concept_htw_ghg_jq" data-id="concept_htw_ghg_jq"><title>Getting Started</title><topicmeta></topicmeta><topic href="Getting_Started/GettingStarted_Title.html#concept_sjz_rmx_3q" data-id="concept_sjz_rmx_3q"><title>What is StreamSets Data Collector?</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Getting_Started/GettingStarted_Title.html#concept_rlj_ftm_lq" data-id="concept_rlj_ftm_lq"><title>How should I use Data Collector?</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Use StreamSets <span class="ph">Data                   Collector</span> like a pipe     for a data stream. Throughout your enterprise data topology, you have streams of data that you     need to move, collect, and process on the way to their destinations. <span class="ph">Data                   Collector</span> provides the     crucial connection between hops in the stream. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Getting_Started/GettingStarted_Title.html#concept_bl5_dl4_1r" data-id="concept_bl5_dl4_1r"><title>How does this really work?</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Let's walk through it...</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Getting_Started/GettingStarted_Title.html#task_qsy_lsf_tq" data-id="task_qsy_lsf_tq"><title>Logging In and Creating a Pipeline</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Getting_Started/GettingStarted_Title.html#concept_yth_5n5_jq" data-id="concept_yth_5n5_jq"><title>Data Collector Console</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Getting_Started/GettingStarted_Title.html#task_r3q_fnx_pr" data-id="task_r3q_fnx_pr"><title>Configuring Console Settings</title><topicmeta></topicmeta></topic></topic></topic><topic href="WhatsNew/WhatsNew_Title.html#concept_hz3_5fk_fy" data-id="concept_hz3_5fk_fy"><title>What's New</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="WhatsNew/WhatsNew_Title.html#concept_kzc_4sd_yy" data-id="concept_kzc_4sd_yy"><title>What's New in 2.4.0.0</title><topicmeta></topicmeta></topic><topic href="WhatsNew/WhatsNew_Title.html#concept_bml_dbt_wy" data-id="concept_bml_dbt_wy"><title>What's New in 2.3.0.1</title><topicmeta></topicmeta></topic><topic href="WhatsNew/WhatsNew_Title.html#concept_yym_xqt_5y" data-id="concept_yym_xqt_5y"><title>What's New in 2.3.0.0</title><topicmeta></topicmeta></topic><topic href="WhatsNew/WhatsNew_Title.html#concept_wbf_dgk_fy" data-id="concept_wbf_dgk_fy"><title>What's New in 2.2.1.0</title><topicmeta></topicmeta></topic><topic href="WhatsNew/WhatsNew_Title.html#concept_oyv_zfk_fy" data-id="concept_oyv_zfk_fy"><title>What's New in 2.2.0.0</title><topicmeta></topicmeta></topic></topic><topic href="Installation/Install_title.html" data-id="concept_l4q_flb_kr"><title>Installation</title><topicmeta></topicmeta><topic href="Installation/InstallationAndConfig.html#concept_gbn_4lv_1r" data-id="concept_gbn_4lv_1r"><title>Installation</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Installation/InstallationAndConfig.html#concept_vzg_n2p_kq" data-id="concept_vzg_n2p_kq"><title>Installation Requirements</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Install <span class="ph">Data                   Collector</span> on a machine     that meets the following minimum requirements. To run pipelines in cluster execution mode, each     node in the cluster must meet the minimum requirements. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Installation/Installing_the_DC.html#task_bt1_zcp_kq" data-id="task_bt1_zcp_kq"><title>Full Installation and Launch (Manual Start)</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Installation/FullInstall_ServiceStart.html#concept_e45_3dr_bx" data-id="concept_e45_3dr_bx"><title>Full Installation and Launch (Service Start)</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Installation/FullInstall_ServiceStart.html#task_th5_1yj_dx" data-id="task_th5_1yj_dx"><title>Installing from the RPM Package</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you install from the RPM package, <span class="ph">Data                   Collector</span> uses         the default directories and the default system user and group. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Installation/FullInstall_ServiceStart.html#task_pnf_344_1r" data-id="task_pnf_344_1r"><title>Installing from the Tarball</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">This procedure walks through setting the default directories and the default system         user and group used to start <span class="ph">Data                   Collector</span> as a         service.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Installation/CoreInstall_Overview.html#concept_vvw_p3m_s5" data-id="concept_vvw_p3m_s5"><title>Core Installation</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Installation/CoreInstall_Overview.html#task_ijj_cvr_kv" data-id="task_ijj_cvr_kv"><title>Installing the Core RPM Package</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">To install the core version of <span class="ph">Data                   Collector</span>,         download the RPM package. After you perform the core installation and launch, install         individual stage libraries as needed. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Installation/CoreInstall_Overview.html#task_eyy_qbn_s5" data-id="task_eyy_qbn_s5"><title>Installing the Core Tarball</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">To install the core version of <span class="ph">Data                   Collector</span>,         download the core tarball. After you perform the core installation and launch, install         individual stage libraries as needed. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Installation/AddtionalStageLibs.html#concept_fb2_qmn_bz" data-id="concept_fb2_qmn_bz"><title>Install Additional Stage Libraries</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Installation/AddtionalStageLibs.html#concept_amc_cf3_dx" data-id="concept_amc_cf3_dx"><title>Installing for RPM</title><topicmeta></topicmeta></topic><topic href="Installation/AddtionalStageLibs.html#concept_h5k_jbl_nx" data-id="concept_h5k_jbl_nx"><title>Installing for Tarball Using the Package Manager</title><topicmeta></topicmeta></topic><topic href="Installation/AddtionalStageLibs.html#concept_bnl_n3n_s5" data-id="concept_bnl_n3n_s5"><title>Installing for Tarball Using the Command Line</title><topicmeta></topicmeta></topic><topic href="Installation/AddtionalStageLibs.html#concept_evs_xkm_s5" data-id="concept_evs_xkm_s5"><title>Available Stage Libraries</title><topicmeta></topicmeta></topic></topic><topic href="Installation/Installing_the_DC-Docker.html#concept_jxh_qxr_kv" data-id="concept_jxh_qxr_kv"><title>Run Data Collector from Docker</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Installation/CMInstall-Overview.html#concept_nb5_c3m_25" data-id="concept_nb5_c3m_25"><title>Installation with Cloudera Manager</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Installation/CMInstall-Overview.html#task_hzt_dgn_25" data-id="task_hzt_dgn_25"><title>Step 1. Install the StreamSets Custom Service Descriptor</title><topicmeta></topicmeta></topic><topic href="Installation/CMInstall-Overview.html#task_opg_yrm_25" data-id="task_opg_yrm_25"><title>Step 2. Manually Install the Parcel and Checksum Files (Optional)</title><topicmeta></topicmeta></topic><topic href="Installation/CMInstall-Overview.html#unique_946864881" data-id="task_opg_yrm_25"><title>Step 3. Distribute and Activate the StreamSets Parcel</title><topicmeta></topicmeta></topic><topic href="Installation/CMInstall-Overview.html#task_u1v_nkt_25" data-id="task_u1v_nkt_25"><title>Step 4. Configure the StreamSets Service</title><topicmeta></topicmeta></topic><topic href="Installation/CMInstall-Overview.html#task_zn4_qrn_25" data-id="task_zn4_qrn_25"><title>Configuring Data Collector with Cloudera Manager</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When administering <span class="ph">Data                   Collector</span> with         Cloudera Manager, configure all <span class="ph">Data                   Collector</span>         configuration properties and environment variables through Cloudera Manager. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Installation/CMInstall-Overview.html#task_azc_wgy_w5" data-id="task_azc_wgy_w5"><title>Enabling Kerberos with Cloudera Manager</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">To enable <span class="ph">Data                   Collector</span> to use         Kerberos, use Cloudera Manager.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Installation/CMInstall-Overview.html#task_qvz_xdb_1x" data-id="task_qvz_xdb_1x"><title>Storing Custom Stage Libraries with Cloudera Manager (Optional)</title><topicmeta></topicmeta></topic></topic><topic href="Installation/MapR-Prerequisites.html" data-id="concept_jgs_qpg_2v"><title>MapR Prerequisites</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Installation/CreateAnotherDC.html#concept_p2w_x3z_yx" data-id="concept_p2w_x3z_yx"><title>Creating Another Data Collector Instance</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Installation/Uninstall.html#concept_fc3_vly_py" data-id="concept_fc3_vly_py"><title>Uninstallation</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Installation/Uninstall.html#task_kf4_gmy_py" data-id="task_kf4_gmy_py"><title>Uninstalling the Tarball (Manual Start)</title><topicmeta></topicmeta></topic><topic href="Installation/Uninstall.html#task_rnf_3cb_qy" data-id="task_rnf_3cb_qy"><title>Uninstalling the Tarball (Service Start)</title><topicmeta></topicmeta></topic><topic href="Installation/Uninstall.html#task_k4s_mjc_qy" data-id="task_k4s_mjc_qy"><title>Uninstalling the RPM Package</title><topicmeta></topicmeta></topic><topic href="Installation/Uninstall.html#task_ir2_y5c_qy" data-id="task_ir2_y5c_qy"><title>Uninstalling from Cloudera Manager</title><topicmeta></topicmeta></topic></topic></topic><topic href="Configuration/Config_title.html" data-id="concept_ylh_yyz_ky"><title>Configuration</title><topicmeta></topicmeta><topic href="Configuration/Authentication.html#concept_dns_dvg_h5" data-id="concept_dns_dvg_h5"><title>User Authentication</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Configuration/Authentication.html#concept_x2j_5ts_g5" data-id="concept_x2j_5ts_g5"><title>Configuring LDAP Authentication</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">If your organization uses LDAP, configure <span class="ph">Data                   Collector</span> to use         LDAP authentication. After you configure LDAP authentication, users log in to <span class="ph">Data                   Collector</span> using         their LDAP username and password. </p>
</shortdesc><topicmeta></topicmeta><topic href="Configuration/Authentication.html#task_tjw_3ss_5x" data-id="task_tjw_3ss_5x"><title>Step 1. Configure LDAP Connection Information</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">To enable LDAP authentication, configure LDAP connection information in the <span class="ph">Data                   Collector</span>         configuration files, <samp class="ph codeph">sdc.properties</samp> and <samp class="ph codeph">ldap-login.conf</samp>,         located in the <samp class="ph codeph">$SDC_CONF</samp> directory.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Configuration/Authentication.html#concept_elh_wyw_ty" data-id="concept_elh_wyw_ty"><title>Example for OpenLDAP</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Let's look at an example <samp class="ph codeph">ldap-login.conf</samp> file and see how <span class="ph">Data                   Collector</span> uses         the LDAP connection information to authenticate LDAP users.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Configuration/Authentication.html#concept_kkr_2zw_ty" data-id="concept_kkr_2zw_ty"><title>Example for Active Directory</title><topicmeta></topicmeta></topic><topic href="Configuration/Authentication.html#task_wyf_kkw_ty" data-id="task_wyf_kkw_ty"><title>Step 2. Configure Secure Connections to LDAP (Optional)</title><topicmeta></topicmeta></topic><topic href="Configuration/Authentication.html#concept_x3x_lts_5x" data-id="concept_x3x_lts_5x"><title>Step 3. Map LDAP Groups to Data Collector Roles</title><topicmeta></topicmeta></topic><topic href="Configuration/Authentication.html#concept_o4n_gvs_5x" data-id="concept_o4n_gvs_5x"><title>Step 4. Configure Multiple LDAP Servers (Optional)</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">If your organization has multiple LDAP servers, you can configure <span class="ph">Data                   Collector</span> to         connect to each of the servers.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Configuration/Authentication.html#concept_fyr_dkv_1x" data-id="concept_fyr_dkv_1x"><title>Step 5. Enable LDAP Authentication for MapR Stages</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">To use MapR stages with a <span class="ph">Data                   Collector</span>         configured to use LDAP authentication, you must perform an additional step after configuring         LDAP authentication.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Configuration/Authentication.html#concept_wgy_rxt_5x" data-id="concept_wgy_rxt_5x"><title>Configuring File-Based Authentication</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">If your organization does not use LDAP, configure <span class="ph">Data                   Collector</span> to use         the default file-based authentication. </p>
</shortdesc><topicmeta></topicmeta><topic href="Configuration/Authentication.html#task_wh3_tdv_5x" data-id="task_wh3_tdv_5x"><title>Step 1. Configure Authentication Properties</title><topicmeta></topicmeta></topic><topic href="Configuration/Authentication.html#task_nsz_lp4_1r" data-id="task_nsz_lp4_1r"><title>Step 2. Configure Users, Groups, and Roles</title><topicmeta></topicmeta></topic></topic></topic><topic href="Configuration/RolesandPermissions.html#concept_k1r_prc_yy" data-id="concept_k1r_prc_yy"><title>Roles and Permissions</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Configuration/RolesandPermissions.html#concept_zyl_qld_yy" data-id="concept_zyl_qld_yy"><title>Roles</title><topicmeta></topicmeta></topic><topic href="Configuration/RolesandPermissions.html#concept_i1p_hzd_yy" data-id="concept_i1p_hzd_yy"><title>Pipeline Permissions</title><topicmeta></topicmeta></topic><topic href="Configuration/RolesandPermissions.html#concept_hjj_prj_yy" data-id="concept_hjj_prj_yy"><title>Roles and Permissions for Common Tasks</title><topicmeta></topicmeta></topic><topic href="Configuration/RolesandPermissions.html#concept_p11_msc_1z" data-id="concept_p11_msc_1z"><title>Transfer Pipeline Permissions</title><topicmeta></topicmeta><topic href="Configuration/RolesandPermissions.html#task_wkr_gdd_1z" data-id="task_wkr_gdd_1z"><title>Transferring Permissions</title><topicmeta></topicmeta></topic></topic></topic><topic href="Configuration/DCConfig.html#concept_pq5_xjq_kr" data-id="concept_pq5_xjq_kr"><title>Data Collector Configuration</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Configuration/DCConfig.html#concept_hnm_n4l_xs" data-id="concept_hnm_n4l_xs"><title>Enabling Kerberos Authentication</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can use Kerberos authentication to connect to external systems as well as YARN     clusters. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Configuration/DCConfig.html#concept_aqc_dbt_zr" data-id="concept_aqc_dbt_zr"><title>Referencing Sensitive Values in Files</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">For increased security you can store sensitive information, such as a password, in     separate files and reference the files in the <span class="ph">Data                   Collector</span>     configuration file, <samp class="ph codeph">$SDC_CONF/sdc.properties</samp>, as follows:     ${file("&lt;filename&gt;")}.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Configuration/DCConfig.html#concept_gvn_rnr_pt" data-id="concept_gvn_rnr_pt"><title>Referencing Environment Variables</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can reference an environment variable in the <span class="ph">Data                   Collector</span>     configuration file, <samp class="ph codeph">$SDC_CONF/sdc.properties</samp>, as follows:     ${env("&lt;environment variable name&gt;")}. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Configuration/DCConfig.html#task_nkc_ydl_bw" data-id="task_nkc_ydl_bw"><title>Running Multiple Concurrent Pipelines</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">By default, <span class="ph">Data                   Collector</span> can         run approximately 22 standalone pipelines concurrently. If you plan to run a larger number         of pipelines at the same time, increase the thread pool size.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Configuration/DCConfig.html#concept_xyp_lt4_cw" data-id="concept_xyp_lt4_cw"><title>HTTP Protocols</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure <span class="ph">Data                   Collector</span> to use         HTTP or HTTPS. By default <span class="ph">Data                   Collector</span> uses         HTTP.</p>
</shortdesc><topicmeta></topicmeta><topic href="Configuration/DCConfig.html#concept_ecx_hkq_kr" data-id="concept_ecx_hkq_kr"><title>Configuring HTTPS for Standalone Pipelines</title><topicmeta></topicmeta></topic><topic href="Configuration/DCConfig.html#concept_rdt_h54_cw" data-id="concept_rdt_h54_cw"><title>Configuring HTTPS for Cluster Pipelines</title><topicmeta></topicmeta></topic><topic href="Configuration/DCConfig.html#concept_ihc_vlr_dw" data-id="concept_ihc_vlr_dw"><title>Keystore Files for Cluster Pipelines</title><topicmeta></topicmeta></topic><topic href="Configuration/DCConfig.html#concept_xxz_vlr_dw" data-id="concept_xxz_vlr_dw"><title>Truststore Files for Cluster Pipelines</title><topicmeta></topicmeta></topic></topic><topic href="Configuration/DCConfig.html#concept_gfx_rvf_qv" data-id="concept_gfx_rvf_qv"><title>Blacklist and Whitelist for Stage Libraries</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">By default, almost all installed stage libraries are available for use in <span class="ph">Data                   Collector</span>. You         can use  blacklist and whitelist properties to limit the stage libraries that can be         used.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Configuration/DCConfig.html#task_lxk_kjw_1r" data-id="task_lxk_kjw_1r"><title>Configuring Data Collector</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can customize <span class="ph">Data                   Collector</span> by         editing the <span class="ph">Data                   Collector</span>         configuration file, <samp class="ph codeph">sdc.properties</samp>. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Configuration/DCEnvironmentConfig.html#concept_rng_qym_qr" data-id="concept_rng_qym_qr"><title>Data Collector Environment Configuration</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Configuration/DCEnvironmentConfig.html#concept_mnx_j3r_3v" data-id="concept_mnx_j3r_3v"><title>Data Collector Directories</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can edit the <span class="ph">Data                   Collector</span>         environment configuration file to modify the directories used to store configuration, data,         log, and resource files.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Configuration/DCEnvironmentConfig.html#concept_htz_t1s_3v" data-id="concept_htz_t1s_3v"><title>User and Group for Service Start</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you run <span class="ph">Data                   Collector</span> as a         service, you must create a system user and group named sdc, or you must edit the values of         the SDC_USER and SDC_GROUP environment variables to point to an existing system user or         group.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Configuration/DCEnvironmentConfig.html#concept_vrx_4fg_qr" data-id="concept_vrx_4fg_qr"><title>Java Configuration Options</title><topicmeta></topicmeta><topic href="Configuration/DCEnvironmentConfig.html#concept_mdc_shg_qr" data-id="concept_mdc_shg_qr"><title>Java Heap Size</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can define the <span class="ph">Data                   Collector</span> Java heap     size. By default, the  Java heap size is 1024 MB. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Configuration/DCEnvironmentConfig.html#concept_wk1_pyw_4x" data-id="concept_wk1_pyw_4x"><title>Remote Debugging</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can enable remote debugging to debug a <span class="ph">Data                   Collector</span>         instance running on a remote machine. To enable remote debugging, define debugging options         in the SDC_JAVA_OPTS environment variable in the <span class="ph">Data                   Collector</span>         environment configuration file.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Configuration/DCEnvironmentConfig.html#concept_kqh_lj3_vx" data-id="concept_kqh_lj3_vx"><title>Garbage Collector</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can define the Java garbage collector that <span class="ph">Data                   Collector</span> uses.         By default, <span class="ph">Data                   Collector</span> uses         the Concurrent Mark Sweep (CMS) garbage collector.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Configuration/DCEnvironmentConfig.html#concept_txl_qyc_ww" data-id="concept_txl_qyc_ww"><title>TLS Protocol Versions</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you use <span class="ph">Data                   Collector</span> with         Java 7, <span class="ph">Data                   Collector</span> is configured to use TLS versions 1.1 and 1.2. To connect to a system that uses an         earlier version of TLS, modify the <samp class="ph codeph">Dhttps.protocols</samp> option in the         SDC_JAVA7_OPTS environment variable in the <span class="ph">Data                   Collector</span>         environment configuration file.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Configuration/DCEnvironmentConfig.html#concept_kxf_y2m_sr" data-id="concept_kxf_y2m_sr"><title>Permanent Generation Size</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you use <span class="ph">Data                   Collector</span> with Java 7,     you can define the Java Permanent Generation size, also known as the PermGen size.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Configuration/DCEnvironmentConfig.html#concept_tm4_pbg_ht" data-id="concept_tm4_pbg_ht"><title>Java Security Manager</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"><span class="ph">Data                   Collector</span>     includes a Java Security Manager that is enabled by default. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Configuration/DCEnvironmentConfig.html#concept_hcb_4ks_3v" data-id="concept_hcb_4ks_3v"><title>Root Classloader</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can edit the <span class="ph">Data                   Collector</span>         environment configuration file to configure the path to JAR files to be added to the <span class="ph">Data                   Collector</span> root         classloader.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Configuration/RuntimeProperties.html#concept_fjx_g31_1s" data-id="concept_fjx_g31_1s"><title>Using Runtime Properties</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Configuration/RuntimeProperties.html#concept_dys_tp1_1s" data-id="concept_dys_tp1_1s"><title>Step 1. Define a Runtime Property</title><topicmeta></topicmeta></topic><topic href="Configuration/RuntimeProperties.html#concept_pdh_glg_1s" data-id="concept_pdh_glg_1s"><title>Step 2. Call the Runtime Property</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Use the <samp class="ph codeph">runtime:conf</samp> function to call a runtime property. You can use         runtime properties to represent any stage or pipeline property that allows the use of the         expression language. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Configuration/RuntimeResources.html#concept_bs4_5nm_2s" data-id="concept_bs4_5nm_2s"><title>Using Runtime Resources</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Configuration/RuntimeResources.html#concept_jh2_ysm_2s" data-id="concept_jh2_ysm_2s"><title>Step 1. Define Runtime Resources</title><topicmeta></topicmeta></topic><topic href="Configuration/RuntimeResources.html#concept_aky_bwm_2s" data-id="concept_aky_bwm_2s"><title>Step 2. Call the Runtime Resource</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Use the <samp class="ph codeph">runtime:loadResource</samp> function to call a runtime resource. You   can use runtime resources to represent sensitive information in any stage or pipeline property   that allows the use of the expression language. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Configuration/ExternalLibs.html#concept_pdv_qlw_ft" data-id="concept_pdv_qlw_ft"><title>Install External Libraries </title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Configuration/ExternalLibs.html#concept_hhl_nxz_bz" data-id="concept_hhl_nxz_bz"><title>Step 1. Set Up an External Directory</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Before you install external libraries, set up a local directory external to the <span class="ph">Data                   Collector</span>         installation directory for the libraries. Use an external directory to enable use of the         libraries after <span class="ph">Data                   Collector</span>         upgrades.</p>
</shortdesc><topicmeta></topicmeta><topic href="Configuration/ExternalLibs.html#task_zhz_5s5_bz" data-id="task_zhz_5s5_bz"><title>Setting Up for RPM and Tarball</title><topicmeta></topicmeta></topic><topic href="Configuration/ExternalLibs.html#task_yhv_1pn_25" data-id="task_yhv_1pn_25"><title>Setting Up for Cloudera Manager</title><topicmeta></topicmeta></topic></topic><topic href="Configuration/ExternalLibs.html#task_jng_dkt_bz" data-id="task_jng_dkt_bz"><title>Step 2. Install External Libraries</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">After you've set up the external directory, use the Package Manager within <span class="ph">Data                   Collector</span> to         install external libraries.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Configuration/CustomStageLibraries.html#concept_pmc_jk1_1x" data-id="concept_pmc_jk1_1x"><title>Custom Stage Libraries</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Configuration/CustomStageLibraries.html#task_hyk_sk1_1x" data-id="task_hyk_sk1_1x"><title>Storing Custom Libraries in an External Directory</title><topicmeta></topicmeta></topic></topic><topic href="Configuration/Vault-Overview.html#concept_bmq_gl1_mw" data-id="concept_bmq_gl1_mw"><title>Accessing Hashicorp Vault Secrets</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Configuration/Vault-Overview.html#concept_c4b_5bb_mw" data-id="concept_c4b_5bb_mw"><title>Step 1. Configure Vault Properties</title><topicmeta></topicmeta></topic><topic href="Configuration/Vault-Overview.html#concept_ecm_vkb_mw" data-id="concept_ecm_vkb_mw"><title>Step 2. Authorize Data Collector in Vault</title><topicmeta></topicmeta></topic><topic href="Configuration/Vault-Overview.html#concept_h54_skb_mw" data-id="concept_h54_skb_mw"><title>Step 3. Call Vault from the Pipeline</title><topicmeta></topicmeta></topic></topic><topic href="Configuration/JMXMetrics-EnableExternalTools.html#concept_jdj_4rg_1t" data-id="concept_jdj_4rg_1t"><title>Enabling External JMX Tools</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Configuration/JMXMetrics-EnableExternalTools.html#concept_oz2_lkt_nv" data-id="concept_oz2_lkt_nv"><title>Viewing JMX Metrics in External Tools</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can view the <span class="ph">Data                   Collector</span> JMX         metrics in external tools. The <span class="ph">Data                   Collector</span> JMX         metric names all begin with "sdc.pipeline."</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Configuration/JMXMetrics-EnableExternalTools.html#concept_llw_2st_nv" data-id="concept_llw_2st_nv"><title>Custom Metrics</title><topicmeta></topicmeta></topic></topic></topic><topic href="Upgrade/Upgrade_title.html" data-id="concept_ejk_f1f_5v"><title>Upgrade</title><topicmeta></topicmeta><topic href="Upgrade/Upgrade.html#concept_a2n_3fk_5v" data-id="concept_a2n_3fk_5v"><title>Upgrade</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/Tarball.html#concept_ryn_4fk_5v" data-id="concept_ryn_4fk_5v"><title>Upgrade an Installation from the Tarball</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Upgrade/Tarball.html#task_uzq_gwl_5v" data-id="task_uzq_gwl_5v"><title>Step 1. Shut Down the Previous Version</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Stop all pipelines and then shut down the previous version of <span class="ph">Data                   Collector</span>.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/Tarball.html#concept_bwg_r1h_1z" data-id="concept_bwg_r1h_1z"><title>Step 2. Back Up the Previous Version</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Before you install the new version, create a backup of the files in the previous         version by copying and renaming the configuration, data, log, and resource directories. That         way, you can continue to run the previous version if needed.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/Tarball.html#concept_bfv_jyl_5v" data-id="concept_bfv_jyl_5v"><title>Step 3. Install the New Version</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The instructions that you use to install the new version depend on whether you start <span class="ph">Data                   Collector</span>         manually or as a service.</p>
</shortdesc><topicmeta></topicmeta><topic href="Upgrade/Tarball.html#task_lxz_qyl_5v" data-id="task_lxz_qyl_5v"><title>Installing from the Tarball (Manual Start)</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Install the new version of the tarball.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/Tarball.html#task_hsl_ccm_5v" data-id="task_hsl_ccm_5v"><title>Installing from the Tarball (Service Start)</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Install the new version of the tarball. Installing the full <span class="ph">Data                   Collector</span> as a         service requires sudo privileges on the root directory. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Upgrade/Tarball.html#task_wzl_hst_xv" data-id="task_wzl_hst_xv"><title>Step 4. Update the Environment Configuration File</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Update the environment configuration file so that the new version of <span class="ph">Data                   Collector</span> uses a         new configuration directory but the same working data, log, and resource directories as the         previous version. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/Tarball.html#task_orr_vcg_2y" data-id="task_orr_vcg_2y"><title>Step 5. Update the Configuration Files</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">A new <span class="ph">Data                   Collector</span>         version can include new properties and configuration files required for <span class="ph">Data                   Collector</span> to         start or function properly. In the previous step, we updated the environment configuration         file so that the new version of <span class="ph">Data                   Collector</span> uses         the new configuration files stored in the <samp class="ph codeph">$SDC_CONF</samp> directory. In this         step, we’ll compare the previous and new versions of the configuration files, and update the         new files as needed with the same customized property values.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/Tarball.html#concept_zyd_ngr_5v" data-id="concept_zyd_ngr_5v"><title>Step 6. Install Additional Libraries for the Core Installation</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">If you upgraded a core installation of <span class="ph">Data                   Collector</span>,         install the individual stage libraries that the upgraded pipelines require. Use the Package         Manager or the <samp class="ph codeph">stagelibs</samp> command to install additional stage         libraries.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/Tarball.html#concept_uct_wfr_5v" data-id="concept_uct_wfr_5v"><title>Step 7. Start the New Version of Data Collector</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Start the new version of <span class="ph">Data                   Collector</span>.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Upgrade/RPM.html#concept_ws4_vq5_xv" data-id="concept_ws4_vq5_xv"><title>Upgrade an Installation from the RPM Package</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Upgrade/RPM.html#task_zk4_tr5_xv" data-id="task_zk4_tr5_xv"><title>Step 1. Shut Down the Previous Version</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Stop all pipelines and then shut down the previous version of <span class="ph">Data                   Collector</span>.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/RPM.html#concept_nzl_hkb_mw" data-id="concept_nzl_hkb_mw"><title>Step 2. Back Up the Previous Version</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Before you install the new version, create a backup of the files in the previous         version by copying and renaming the data, log, and resource directories. You’ll also need to         create a backup of the environment configuration file,             <samp class="ph codeph">$SDC_DIST/libexec/sdcd-env.sh</samp>, so that the file is not overwritten when         you install the new version. That way, you can continue to run the previous version if         needed. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/RPM.html#task_ofc_2zl_5v" data-id="task_ofc_2zl_5v"><title>Step 3. Install the New Version</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Install the new version of the RPM package. Installing the full <span class="ph">Data                   Collector</span> as a         service requires sudo privileges on the root directory.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/RPM.html#task_krt_sj5_xv" data-id="task_krt_sj5_xv"><title>Step 4. Update the Environment Configuration File</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Each RPM installation uses the same default values as the previous version for all of         the directory environment variables. If the previous version used the default values, the         new version is configured to use the same working directories.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/RPM.html#task_lkl_wk5_xv" data-id="task_lkl_wk5_xv"><title>Step 5. Update the Configuration Files</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">A new <span class="ph">Data                   Collector</span>         version can include new properties and configuration files required for <span class="ph">Data                   Collector</span> to         start or function properly. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/RPM.html#concept_pch_vnr_bx" data-id="concept_pch_vnr_bx"><title>Step 6. Install Additional Libraries for the Core Installation</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">If you installed the core RPM package, install the individual stage libraries that the         upgraded pipelines require. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/RPM.html#concept_r3f_xyl_1z" data-id="concept_r3f_xyl_1z"><title>Step 7. Uninstall Previous Libraries</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Uninstall all stage libraries used by the previous Data Collector version.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/RPM.html#concept_n35_s55_xv" data-id="concept_n35_s55_xv"><title>Step 8. Start the New Version of Data Collector</title><topicmeta></topicmeta></topic></topic><topic href="Upgrade/CMUpgrade.html#concept_c45_chv_xv" data-id="concept_c45_chv_xv"><title>Upgrade an Installation with Cloudera Manager</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Upgrade/CMUpgrade.html#task_q3b_zfc_rx" data-id="task_q3b_zfc_rx"><title>Step 1. Stop All Pipelines</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">In <span class="ph">Data                   Collector</span>, stop         all running pipelines.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/CMUpgrade.html#task_rrx_m3v_xv" data-id="task_rrx_m3v_xv"><title>Step 2. Install the StreamSets Custom Service Descriptor</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Install the new StreamSets custom service descriptor file (CSD), and then restart         Cloudera Manager.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/CMUpgrade.html#task_cgv_2jv_xv" data-id="task_cgv_2jv_xv"><title>Step 3. Manually Install the Parcel and Checksum Files (Optional)</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can manually install the StreamSets parcel and related checksum files. Manually         install the files when the Cloudera Manager Server does not have internet         access.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/CMUpgrade.html#task_mdr_phr_5v" data-id="task_mdr_phr_5v"><title>Step 4. Distribute and Activate the New StreamSets Parcel</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">After you add the StreamSets repository to Cloudera Manager, you can download and         distribute the new StreamSets parcel across the cluster. Stop the StreamSets service and         deactivate the previous parcel before you activate the new parcel.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Upgrade/PostUpgrade.html#concept_zll_vn5_zw" data-id="concept_zll_vn5_zw"><title>Post Upgrade Tasks</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Upgrade/PostUpgrade.html#concept_zbn_fpw_xy" data-id="concept_zbn_fpw_xy"><title>Configure Pipeline Permissions</title><topicmeta></topicmeta></topic><topic href="Upgrade/PostUpgrade.html#concept_id5_lkk_yy" data-id="concept_id5_lkk_yy"><title>Enable Users to Access Data Collector Logs</title><topicmeta></topicmeta></topic><topic href="Upgrade/PostUpgrade.html#task_afy_k12_ry" data-id="task_afy_k12_ry"><title>Update Elasticsearch Pipelines</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"><span class="ph">Data                   Collector</span>         version 2.3.0.0 includes an enhanced Elasticsearch destination that uses the Elasticsearch         HTTP API. To upgrade pipelines that use the Elasticsearch destination, you must verify that         Java 8 is installed and review the value of the Default Operation property.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/PostUpgrade.html#concept_epj_gqd_rx" data-id="concept_epj_gqd_rx"><title>Update Kudu Pipelines</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"><span class="ph">Data                   Collector</span>         version 2.2.0.0 provides support for Apache Kudu version 1.0.x and no longer supports         earlier Kudu versions. To upgrade pipelines that contain a Kudu destination, upgrade your         Kudu cluster and then add a stage alias for the earlier Kudu version to the <span class="ph">Data                   Collector</span>         configuration file, <samp class="ph codeph">$SDC_CONF/sdc.properties</samp>. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Upgrade/PostUpgrade.html#concept_yyv_v45_zw" data-id="concept_yyv_v45_zw"><title>Update Vault Pipelines</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Due to a known issue in <span class="ph">Data                   Collector</span>         version 1.5.0.0, you can use Vault functions to call Vault secrets from within any pipeline         or stage property. If you are upgrading from version 1.5.0.0, update Vault pipelines as         needed.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Upgrade/Upgrade-ExternalSystems.html#task_ijh_wtw_xy" data-id="task_ijh_wtw_xy"><title>Working with Upgraded External Systems</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Upgrade/Upgrade-ExternalSystems.html#concept_spt_33c_yy" data-id="concept_spt_33c_yy"><title>Working with an Upgraded MapR System</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">If you upgrade MapR, you must complete additional steps to continue using existing         pipelines that connected to the previous MapR version.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Upgrade/UpgradeTroubleshooting.html#concept_dgz_p45_gy" data-id="concept_dgz_p45_gy"><title>Troubleshooting an Upgrade</title><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Design/PipelineDesign_title.html" data-id="concept_qsw_cjy_bt"><title>Pipeline Concepts and Design</title><topicmeta></topicmeta><topic href="Pipeline_Design/What_isa_Pipeline.html" data-id="concept_isl_w44_kq"><title>What is a Pipeline?</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Design/DatainMotion.html#concept_y1r_zky_bt" data-id="concept_y1r_zky_bt"><title>Data in Motion</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Pipeline_Design/DatainMotion.html#concept_njg_4mx_4y" data-id="concept_njg_4mx_4y"><title>Single and Multithreaded Pipelines</title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/DatainMotion.html#concept_ffz_hhw_kq" data-id="concept_ffz_hhw_kq"><title>Delivery Guarantee</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you configure a pipeline, you define how you want data to be treated: Do you want     to prevent the loss of data or the duplication of data?</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Design/DesigningDataFlow.html#concept_ad4_gpy_bt" data-id="concept_ad4_gpy_bt"><title>Designing the Data Flow</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Pipeline_Design/DesigningDataFlow.html#concept_ub2_zdl_br" data-id="concept_ub2_zdl_br"><title>Branching Streams</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you connect a stage to multiple stages, all data passes to all connected stages.       You can configure required fields for a stage to discard records before they enter the stage,       but by default all records are passed.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Design/DesigningDataFlow.html#concept_w3y_cry_5q" data-id="concept_w3y_cry_5q"><title>Merging Streams</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can merge streams of data in a pipeline by connecting two or more stages to the same   downstream stage. When you merge streams of data, <span class="ph">Data                   Collector</span> channels the   data from all streams to the same stage, but does not perform a join of records in the stream. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Design/DroppingUnwantedRecords.html#concept_ejl_lpy_bt" data-id="concept_ejl_lpy_bt"><title>Dropping Unwanted Records</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Pipeline_Design/DroppingUnwantedRecords.html#concept_dnj_bkm_vq" data-id="concept_dnj_bkm_vq"><title>Required Fields</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">A required field is a field that must exist in a record to allow it into the stage for         processing. When a record does not include a required field, the record is diverted to the         pipeline for error handling. You can define required fields for any processor and most         destination stages. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Design/DroppingUnwantedRecords.html#concept_msl_yd4_fs" data-id="concept_msl_yd4_fs"><title>Preconditions</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Preconditions are conditions that a record must satisfy to enter the stage for         processing. Like required fields, if a record does not meet a precondition, it is diverted         to the pipeline for error handling. You can define preconditions for any processor and most         destination stages. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Design/ErrorHandling.html#concept_pm4_txm_vq" data-id="concept_pm4_txm_vq"><title>Error Record Handling</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Pipeline_Design/ErrorHandling.html#concept_kgc_l4y_5r" data-id="concept_kgc_l4y_5r"><title>Pipeline Error Record Handling</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Pipeline error record handling determines how <span class="ph">Data                   Collector</span> processes     error records that stages send to the pipeline for error handling. It also handles records     deliberately dropped from the pipeline such as records without required fields.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Design/ErrorHandling.html#concept_atr_j4y_5r" data-id="concept_atr_j4y_5r"><title>Stage Error Record Handling</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Most stages include error record handling options. When an error occurs when processing     a record, <span class="ph">Data                   Collector</span>     processes records based on the On Record Error property for the stage.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Design/ErrorHandling.html#concept_y4z_n4y_5r" data-id="concept_y4z_n4y_5r"><title>Example</title><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Design/RecordHeaderAttributes.html#concept_wn2_jcz_dz" data-id="concept_wn2_jcz_dz"><title>Record Header Attributes</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Pipeline_Design/RecordHeaderAttributes.html#concept_itf_55z_dz" data-id="concept_itf_55z_dz"><title>Internal Attributes</title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/RecordHeaderAttributes.html#concept_rd2_ghz_dz" data-id="concept_rd2_ghz_dz"><title>Creating and Updating Header Attributes</title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/RecordHeaderAttributes.html#concept_t1l_xwf_2z" data-id="concept_t1l_xwf_2z"><title>Viewing Attributes in Data Preview</title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/RecordHeaderAttributes.html#concept_ih1_3f1_2z" data-id="concept_ih1_3f1_2z"><title>Attribute-Generating Stages</title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/RecordHeaderAttributes.html#concept_lmn_gdc_1w" data-id="concept_lmn_gdc_1w"><title>Record Header Attributes for Record-Based Writes</title><topicmeta></topicmeta><topic href="Pipeline_Design/RecordHeaderAttributes.html#concept_th5_3zj_mw" data-id="concept_th5_3zj_mw"><title>Generating Attributes for Record-Based Writes</title><topicmeta></topicmeta></topic></topic></topic><topic href="Pipeline_Design/FieldAttributes.html" data-id="concept_xfm_wtp_1z"><title>Field Attributes</title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/CDC-Overview.html#concept_apw_l2c_ty" data-id="concept_apw_l2c_ty"><title>Processing Changed Data</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Pipeline_Design/CDC-Overview.html#concept_np1_wpc_ty" data-id="concept_np1_wpc_ty"><title>CRUD Operation Header Attribute</title><topicmeta></topicmeta><topic href="Pipeline_Design/CDC-Overview.html#concept_vzg_5yd_5y" data-id="concept_vzg_5yd_5y"><title>Earlier Implementations</title><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Design/CDC-Overview.html#concept_iws_mhd_ty" data-id="concept_iws_mhd_ty"><title>CDC-Enabled Origins</title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/CDC-Overview.html#concept_lfb_phd_ty" data-id="concept_lfb_phd_ty"><title>CRUD-Enabled Stages </title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/CDC-Overview.html#concept_wj5_hy2_5y" data-id="concept_wj5_hy2_5y"><title>Processing the Record</title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/CDC-Overview.html#concept_y5y_5xd_5y" data-id="concept_y5y_5xd_5y"><title>Use Cases</title><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Design/DelimitedDataRootFieldTypes.html#concept_zcg_bm4_fs" data-id="concept_zcg_bm4_fs"><title>Delimited Data Root Field Type</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Design/Protobuf-Prerequisites.html" data-id="concept_uxh_nc4_45"><title>Protobuf Data Format Prerequisites</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Design/SDCRecordFormat.html" data-id="concept_qkk_mwk_br"><title>SDC Record Data Format</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Design/TextCDelim.html#concept_lg2_gcg_jx" data-id="concept_lg2_gcg_jx"><title>Text Data Format with Custom Delimiters</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Pipeline_Design/TextCDelim.html#concept_okt_kmg_jx" data-id="concept_okt_kmg_jx"><title>Processing XML Data with Custom Delimiters</title><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Design/WholeFile.html#concept_nfc_qkh_xw" data-id="concept_nfc_qkh_xw"><title>Whole File Data Format</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Pipeline_Design/WholeFile.html#concept_acf_1bm_zw" data-id="concept_acf_1bm_zw"><title>Basic Pipeline</title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/WholeFile.html#concept_kxr_kqh_xw" data-id="concept_kxr_kqh_xw"><title>Whole File Records</title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/WholeFile.html#concept_kgs_msy_yw" data-id="concept_kgs_msy_yw"><title>Additional Processors</title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/WholeFile.html#concept_prp_jzd_py" data-id="concept_prp_jzd_py"><title>Defining the Transfer Rate</title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/WholeFile.html#concept_a2s_4jw_1x" data-id="concept_a2s_4jw_1x"><title>Writing Whole Files</title><topicmeta></topicmeta><topic href="Pipeline_Design/WholeFile.html#concept_ttm_ywv_1x" data-id="concept_ttm_ywv_1x"><title>Access Permissions</title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/WholeFile.html#concept_ojv_sr4_vx" data-id="concept_ojv_sr4_vx"><title>Including Checksums in Events</title><topicmeta></topicmeta></topic></topic></topic><topic href="Pipeline_Design/XMLDFormat.html#concept_lty_42b_dy" data-id="concept_lty_42b_dy"><title>XML Data Format and Data Processing</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Pipeline_Design/XMLDFormat.html#concept_myp_dbk_dy" data-id="concept_myp_dbk_dy"><title>Creating Multiple Records with an XML Element</title><topicmeta></topicmeta><topic href="Pipeline_Design/XMLDFormat.html#concept_ilc_r3g_2y" data-id="concept_ilc_r3g_2y"><title>Using XML Elements with Namespaces</title><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Design/XMLDFormat.html#concept_zw2_mfk_dy" data-id="concept_zw2_mfk_dy"><title>Creating Multiple Records with an XPath Expression</title><topicmeta></topicmeta><topic href="Pipeline_Design/XMLDFormat.html#concept_mkk_3zj_dy" data-id="concept_mkk_3zj_dy"><title>Using XPath Expressions with Namespaces</title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/XMLDFormat.html#concept_tmc_4bc_dy" data-id="concept_tmc_4bc_dy"><title>Simplified XPath Syntax</title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/XMLDFormat.html#concept_prt_sst_gy" data-id="concept_prt_sst_gy"><title>Sample XPath Expressions</title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/XMLDFormat.html#concept_bnl_4fh_2y" data-id="concept_bnl_4fh_2y"><title>Predicates in XPath Expressions</title><topicmeta></topicmeta></topic><topic href="Pipeline_Design/XMLDFormat.html#concept_cgw_sc4_2y" data-id="concept_cgw_sc4_2y"><title>Predicate Examples</title><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Design/XMLDFormat.html#concept_tzk_1gk_dy" data-id="concept_tzk_1gk_dy"><title>Parsed XML</title><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Design/ControlCharacters.html" data-id="concept_hfs_dkm_js"><title>Control Character Removal</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Design/DevStages.html#concept_czx_ktn_ht" data-id="concept_czx_ktn_ht"><title>Development Stages</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Configuration/PipelineConfiguration_title.html#concept_qn1_wn4_kq" data-id="concept_qn1_wn4_kq"><title>Pipeline Configuration</title><topicmeta></topicmeta><topic href="Pipeline_Configuration/PipelineConfiguration_title.html#concept_izr_f2p_rq" data-id="concept_izr_f2p_rq"><title>Data Collector Console - Edit Mode</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Configuration/PipelineConfiguration_title.html#concept_cgm_ktz_2t" data-id="concept_cgm_ktz_2t"><title>Retrying the Pipeline</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Configuration/PipelineConfiguration_title.html#concept_twq_nhx_rr" data-id="concept_twq_nhx_rr"><title>Pipeline Memory</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Configuration/PipelineConfiguration_title.html#concept_erj_qg4_qv" data-id="concept_erj_qg4_qv"><title>Rate Limit</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Configuration/PipelineConfiguration_title.html#concept_rjh_ntz_qr" data-id="concept_rjh_ntz_qr"><title>Pipeline Constants</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Configuration/PipelineConfiguration_title.html#concept_azs_swf_jr" data-id="concept_azs_swf_jr"><title>Implicit and Explicit Validation</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Configuration/PipelineConfiguration_title.html#concept_ofb_1cm_xq" data-id="concept_ofb_1cm_xq"><title>Expression Configuration</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Pipeline_Configuration/PipelineConfiguration_title.html#concept_bkb_tcm_xq" data-id="concept_bkb_tcm_xq"><title>Basic Syntax</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Precede all expressions with a dollar sign and enclose them with curly brackets, as   follows: <samp class="ph codeph">${&lt;expression&gt;}</samp>.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Configuration/PipelineConfiguration_title.html#concept_kk2_mbm_xq" data-id="concept_kk2_mbm_xq"><title>Using Field Names in Expressions</title><topicmeta></topicmeta><topic href="Pipeline_Configuration/PipelineConfiguration_title.html#concept_xnp_453_ft" data-id="concept_xnp_453_ft"><title>Field Names with Special Characters</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can use quotation marks and the backslash character to handle special characters in   field names. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Configuration/PipelineConfiguration_title.html#concept_hjk_b4l_vq" data-id="concept_hjk_b4l_vq"><title>Referencing Field Names and Field Paths</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When a pipeline is valid for preview, you can generally select fields from a list. When                 a list is not available or when you are defining a new field name, you need to use                 the appropriate format for the field name.  </p>
</shortdesc><topicmeta></topicmeta><topic href="Pipeline_Configuration/PipelineConfiguration_title.html#concept_vqr_sqc_wr" data-id="concept_vqr_sqc_wr"><title>Wildcard Use for Arrays and Maps</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">In some processors, you can use the asterisk wildcard (*) as indices in an array or key     values in a map. Use a wildcard to help define the field paths for maps and arrays. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Configuration/PipelineConfiguration_title.html#concept_tns_krz_sr" data-id="concept_tns_krz_sr"><title>Expression Completion in Properties</title><topicmeta></topicmeta><topic href="Pipeline_Configuration/PipelineConfiguration_title.html#concept_fwj_yq5_tr" data-id="concept_fwj_yq5_tr"><title>Tips for Expression Completion</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Use the following information and tips when you invoke expression   completion:</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Configuration/PipelineConfiguration_title.html#concept_fmr_ggh_fr" data-id="concept_fmr_ggh_fr"><title>Data Type Coercion</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When an expression requires, the expression language attempts implicit data type   conversion - a.k.a. data type coercion. When coercion is not possible, <span class="ph">Data                   Collector</span> passes the   error records to the stage for error handling.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Configuration/PipelineConfiguration_title.html#task_xlv_jdw_kq" data-id="task_xlv_jdw_kq"><title>Configuring a Pipeline</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Origins/Origins_title.html" data-id="concept_yjl_nc5_jq"><title>Origins</title><topicmeta></topicmeta><topic href="Origins/Origins_overview.html#concept_hpr_twm_jq" data-id="concept_hpr_twm_jq"><title>Origins</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/Origins_overview.html#concept_rsz_cnw_qy" data-id="concept_rsz_cnw_qy"><title>Comparing HTTP Origins</title><topicmeta></topicmeta></topic><topic href="Origins/Origins_overview.html#concept_ypd_vgr_5q" data-id="concept_ypd_vgr_5q"><title>Batch Size and Wait Time</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">For origin stages, the batch size determines the maximum number of records sent through         the pipeline at one time. The batch wait time determines the time that the origin waits for         data before sending a batch. At the end of the wait time, it sends the batch regardless of         how many records the batch contains. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/Origins_overview.html#concept_uxr_g52_qs" data-id="concept_uxr_g52_qs"><title>File Compression Formats</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Origins that read files can read uncompressed, compressed files, archives, and     compressed archives. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/Origins_overview.html#task_jp5_ql1_tq" data-id="task_jp5_ql1_tq"><title>Previewing Raw Source Data</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can preview raw source data for Directory, File Tail, and Kafka Consumer origins.         Preview raw source data when reviewing the data might help with origin         configuration.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Origins/AmazonS3.html#concept_kvs_3hh_ht" data-id="concept_kvs_3hh_ht"><title>Amazon S3</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/AmazonS3.html#concept_uhy_ttg_vw" data-id="concept_uhy_ttg_vw"><title>AWS Credentials</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When <span class="ph">Data                   Collector</span> reads data from an Amazon S3 origin, it must pass credentials to Amazon Web         Services.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/AmazonS3.html#concept_elk_jr4_ht" data-id="concept_elk_jr4_ht"><title>Common Prefix, Prefix Pattern, and Wildcards</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The Amazon S3 origin appends the common prefix to the prefix pattern to define the         objects that the origin processes. You can specify an exact prefix pattern or you can use         Ant-style path patterns to read multiple objects recursively.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/AmazonS3.html#concept_inh_qjx_yw" data-id="concept_inh_qjx_yw"><title>Object Metadata in Record Header Attributes</title><topicmeta></topicmeta></topic><topic href="Origins/AmazonS3.html#concept_ltv_r3l_5q" data-id="concept_ltv_r3l_5q"><title>Read Order</title><topicmeta></topicmeta></topic><topic href="Origins/AmazonS3.html#concept_zp2_fqs_5r" data-id="concept_zp2_fqs_5r"><title>Buffer Limit and Error Handling</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The Amazon S3 origin uses a buffer to read objects into memory to produce records. The     size of the buffer determines the maximum size of the record that can be processed. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/AmazonS3.html#concept_ctg_xh4_sx" data-id="concept_ctg_xh4_sx"><title>Server Side Encryption</title><topicmeta></topicmeta></topic><topic href="Origins/AmazonS3.html#concept_gz5_dqw_yq" data-id="concept_gz5_dqw_yq"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Origins/AmazonS3.html#task_gfj_ssv_yq" data-id="task_gfj_ssv_yq"><title>Configuring an Amazon S3 Origin</title><topicmeta></topicmeta></topic></topic><topic href="Origins/Directory.html#concept_qcq_54n_jq" data-id="concept_qcq_54n_jq"><title>Directory</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/Directory.html#concept_xd5_5z4_4y" data-id="concept_xd5_5z4_4y"><title>File Name Pattern and Mode</title><topicmeta></topicmeta></topic><topic href="Origins/Directory.html#concept_b4d_fym_xv" data-id="concept_b4d_fym_xv"><title>Read Order</title><topicmeta></topicmeta></topic><topic href="Origins/Directory.html#concept_qpt_rg3_cy" data-id="concept_qpt_rg3_cy"><title>Reading from Subdirectories</title><topicmeta></topicmeta><topic href="Origins/Directory.html#concept_vg3_233_cy" data-id="concept_vg3_233_cy"><title>Post-Processing Subdirectories</title><topicmeta></topicmeta></topic></topic><topic href="Origins/Directory.html#concept_ltv_r3l_5q" data-id="concept_ltv_r3l_5q"><title>First File for Processing</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Configure a first file for processing when you want Directory to ignore one or                 more existing files in the directory.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/Directory.html#concept_p52_xj1_4v" data-id="concept_p52_xj1_4v"><title>Late Directory</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure Directory to read files in a late directory - a directory that         appears after the pipeline starts. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/Directory.html#concept_tlj_3g1_2z" data-id="concept_tlj_3g1_2z"><title>Record Header Attributes</title><topicmeta></topicmeta></topic><topic href="Origins/Directory.html#concept_ttg_vgn_qx" data-id="concept_ttg_vgn_qx"><title>Event Generation</title><topicmeta></topicmeta><topic href="Origins/Directory.html#concept_z2k_b3n_qx" data-id="concept_z2k_b3n_qx"><title>Event Records</title><topicmeta></topicmeta></topic></topic><topic href="Origins/Directory.html#concept_zp2_fqs_5r" data-id="concept_zp2_fqs_5r"><title>Buffer Limit and Error Handling</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The Directory origin passes each record to a buffer. The size of the buffer determines     the maximum size of the record that can be processed. Decrease the buffer limit when memory on     the <span class="ph">Data                   Collector</span>     machine is limited. Increase the buffer limit to process larger records when memory is     available. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/Directory.html#concept_gz5_dqw_yq" data-id="concept_gz5_dqw_yq"><title>Data Formats</title><topicmeta></topicmeta><topic href="Origins/Directory.html#concept_tr1_spd_sr" data-id="concept_tr1_spd_sr"><title>Log Formats</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you use an origin to read log data, you define the format of the log files to be   read. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Origins/Directory.html#task_gfj_ssv_yq" data-id="task_gfj_ssv_yq"><title>Configuring a Directory Origin</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Configure a Directory origin to read data from files in a directory. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Origins/FileTail.html#concept_n1y_qyp_5q" data-id="concept_n1y_qyp_5q"><title>File Tail</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/FileTail.html#concept_trt_thq_5r" data-id="concept_trt_thq_5r"><title>File Processing and Archived File Names</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">File Tail processes the active file and archived files based on how the source server   generates files. When you specify the naming convention for archived files, File Tail determines   the file generation method and processes the data accordingly.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/FileTail.html#concept_cyz_kr4_1s" data-id="concept_cyz_kr4_1s"><title>Multiple Paths and File Sets</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">File Tail can read sets of files in different directories. When File Tail processes         different sets of files, it merges all data in the pipeline. If you need to separate the         records later, you can use the tag record attribute.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/FileTail.html#concept_xcd_dxw_mv" data-id="concept_xcd_dxw_mv"><title>Late Directories</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure File Tail to read files in late directories - directories that appear         after the pipeline starts. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/FileTail.html#concept_d5j_vrx_fs" data-id="concept_d5j_vrx_fs"><title>Files Matching a Pattern - Pattern Constant</title><topicmeta></topicmeta></topic><topic href="Origins/FileTail.html#concept_tlj_3g1_2z" data-id="concept_tlj_3g1_2z"><title>Record Header Attributes</title><topicmeta></topicmeta><topic href="Origins/FileTail.html#concept_crd_tlx_fs" data-id="concept_crd_tlx_fs"><title>Defining and Using a Tag</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">A tag is an optional record header attribute that you can define for sets of files. In   the pipeline, you can use a function to return the value of the tag attribute. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Origins/FileTail.html#concept_mzk_w4v_js" data-id="concept_mzk_w4v_js"><title>Multiple Line Processing</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">File Tail can process log and text data that includes multiple lines. You might use   multiple line processing to include stack traces with log data, or to process MySQL multiline   logs. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/FileTail.html#concept_e53_gr4_1s" data-id="concept_e53_gr4_1s"><title>File Tail Output</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">File Tail provides data and related metadata through separate output streams. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/FileTail.html#concept_gwn_c32_px" data-id="concept_gwn_c32_px"><title>Event Generation</title><topicmeta></topicmeta><topic href="Origins/FileTail.html#concept_hwr_yn2_px" data-id="concept_hwr_yn2_px"><title>Event Records</title><topicmeta></topicmeta></topic></topic><topic href="Origins/FileTail.html#concept_pm4_b3q_5r" data-id="concept_pm4_b3q_5r"><title>Data Formats</title><topicmeta></topicmeta><topic href="Origins/FileTail.html#concept_tr1_spd_sr" data-id="concept_tr1_spd_sr"><title>Log Formats</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you use an origin to read log data, you define the format of the log files to be   read. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Origins/FileTail.html#task_unq_wdw_yq" data-id="task_unq_wdw_yq"><title>Configuring a File Tail Origin</title><topicmeta></topicmeta></topic></topic><topic href="Origins/HadoopFS-origin.html#concept_lw2_tnm_vs" data-id="concept_lw2_tnm_vs"><title>Hadoop FS</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/HadoopFS-origin.html#concept_xy5_4tm_vs" data-id="concept_xy5_4tm_vs"><title>Kerberos Authentication</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can use Kerberos authentication to connect to HDFS. When you use Kerberos   authentication, <span class="ph">Data                   Collector</span> uses the   Kerberos principal and keytab to connect to HDFS. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/HadoopFS-origin.html#concept_u4h_lwt_ls" data-id="concept_u4h_lwt_ls"><title>Using a Hadoop User</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure the Hadoop FS origin to use a Hadoop user to read data from HDFS. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/HadoopFS-origin.html#concept_xh5_y4d_br" data-id="concept_xh5_y4d_br"><title>Hadoop Properties and Configuration Files</title><topicmeta></topicmeta></topic><topic href="Origins/HadoopFS-origin.html#concept_jx4_zym_vs" data-id="concept_jx4_zym_vs"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Origins/HadoopFS-origin.html#task_hgl_vgn_vs" data-id="task_hgl_vgn_vs"><title>Configuring a Hadoop FS Origin</title><topicmeta></topicmeta></topic></topic><topic href="Origins/HTTPClient.html#concept_wk4_bjz_5r" data-id="concept_wk4_bjz_5r"><title>HTTP Client</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/HTTPClient.html#concept_erx_tjp_fs" data-id="concept_erx_tjp_fs"><title>Processing Mode</title><topicmeta></topicmeta></topic><topic href="Origins/HTTPClient.html#concept_edk_j5t_zw" data-id="concept_edk_j5t_zw"><title>Pagination</title><topicmeta></topicmeta><topic href="Origins/HTTPClient.html#concept_d3b_vn2_bx" data-id="concept_d3b_vn2_bx"><title>Result Field Path</title><topicmeta></topicmeta></topic></topic><topic href="Origins/HTTPClient.html#concept_zyc_53p_fs" data-id="concept_zyc_53p_fs"><title>HTTP Method</title><topicmeta></topicmeta></topic><topic href="Origins/HTTPClient.html#concept_c13_zz1_5y" data-id="concept_c13_zz1_5y"><title>OAuth 2 Authorization</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure the HTTP Client origin to use the OAuth 2 protocol to connect to an         HTTP service that uses basic, digest, or universal authentication, OAuth 2 client         credentials, OAuth 2 username and password, or OAuth 2 JSON Web Tokens (JWT).</p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/HTTPClient.html#task_r3n_ff2_5y" data-id="task_r3n_ff2_5y"><title>Example for Twitter</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">To use OAuth 2 authorization to read from Twitter, configure HTTP Client to use basic         authentication and the client credentials grant.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/HTTPClient.html#task_rb2_mf2_5y" data-id="task_rb2_mf2_5y"><title>Example for Microsoft Azure AD</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">To use OAuth 2 authorization to read from Microsoft Azure AD, configure HTTP Client         to use no authentication and the client credentials grant.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/HTTPClient.html#task_sjx_qf2_5y" data-id="task_sjx_qf2_5y"><title>Example for Google</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">To use OAuth 2 authorization to read from Google service accounts, configure HTTP         Client to use no authentication and the JSON Web Tokens grant.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Origins/HTTPClient.html#concept_mnv_s5r_35" data-id="concept_mnv_s5r_35"><title>Data Formats</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The HTTP Client origin processes data differently based on the data format. The origin         processes the following types of data: </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/HTTPClient.html#concept_ccn_jzt_zw" data-id="concept_ccn_jzt_zw"><title>Response Header Fields in Header Attributes</title><topicmeta></topicmeta></topic><topic href="Origins/HTTPClient.html#task_akl_rkz_5r" data-id="task_akl_rkz_5r"><title>Configuring an HTTP Client Origin</title><topicmeta></topicmeta></topic></topic><topic href="Origins/HTTPServer.html#concept_s2p_5hb_4y" data-id="concept_s2p_5hb_4y"><title>HTTP Server</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/HTTPServer.html#concept_hgb_br4_qy" data-id="concept_hgb_br4_qy"><title>Prerequisites</title><topicmeta></topicmeta></topic><topic href="Origins/HTTPServer.html#concept_ldf_chp_qy" data-id="concept_ldf_chp_qy"><title>Multithreaded Processing</title><topicmeta></topicmeta></topic><topic href="Origins/HTTPServer.html#concept_anf_ss4_qy" data-id="concept_anf_ss4_qy"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Origins/HTTPServer.html#task_pgw_b3b_4y" data-id="task_pgw_b3b_4y"><title>Configuring an HTTP Server Origin</title><topicmeta></topicmeta></topic></topic><topic href="Origins/HTTPtoKafka.html#concept_izh_mqd_dy" data-id="concept_izh_mqd_dy"><title>HTTP to Kafka</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/HTTPtoKafka.html#concept_uzn_ltp_4y" data-id="concept_uzn_ltp_4y"><title>Prerequisites</title><topicmeta></topicmeta></topic><topic href="Origins/HTTPtoKafka.html#concept_rph_34w_4y" data-id="concept_rph_34w_4y"><title>Pipeline Configuration</title><topicmeta></topicmeta></topic><topic href="Origins/HTTPtoKafka.html#concept_skw_zkg_qy" data-id="concept_skw_zkg_qy"><title>Kafka Maximum Message Size</title><topicmeta></topicmeta></topic><topic href="Origins/HTTPtoKafka.html#concept_y1b_pwv_4y" data-id="concept_y1b_pwv_4y"><title>Enabling Kafka Security</title><topicmeta></topicmeta><topic href="Origins/HTTPtoKafka.html#concept_rjs_twv_4y" data-id="concept_rjs_twv_4y"><title>Enabling SSL/TLS</title><topicmeta></topicmeta></topic><topic href="Origins/HTTPtoKafka.html#concept_qz3_ywv_4y" data-id="concept_qz3_ywv_4y"><title>Enabling Kerberos (SASL)</title><topicmeta></topicmeta></topic><topic href="Origins/HTTPtoKafka.html#concept_h4n_wzv_4y" data-id="concept_h4n_wzv_4y"><title>Enabling SSL/TLS and Kerberos</title><topicmeta></topicmeta></topic></topic><topic href="Origins/HTTPtoKafka.html#task_vgx_nqd_dy" data-id="task_vgx_nqd_dy"><title>Configuring an HTTP to Kafka Origin</title><topicmeta></topicmeta></topic></topic><topic href="Origins/MultiTableJDBCConsumer.html#concept_zp3_wnw_4y" data-id="concept_zp3_wnw_4y"><title>JDBC Multitable Consumer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/MultiTableJDBCConsumer.html#concept_zsr_31x_4y" data-id="concept_zsr_31x_4y"><title>Installing the JDBC Driver</title><topicmeta></topicmeta><topic href="Origins/MultiTableJDBCConsumer.html#concept_bnp_zhb_ty" data-id="concept_bnp_zhb_ty"><title>Working with a MySQL JDBC Driver</title><topicmeta></topicmeta></topic></topic><topic href="Origins/MultiTableJDBCConsumer.html#concept_n5t_zgx_4y" data-id="concept_n5t_zgx_4y"><title>Batch Strategy</title><topicmeta></topicmeta></topic><topic href="Origins/MultiTableJDBCConsumer.html#concept_rx3_3hx_4y" data-id="concept_rx3_3hx_4y"><title>Table Configuration</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you configure JDBC Multitable Consumer, you define a table configuration for each         group of tables that you want to read. A table configuration defines a group of tables from         the same schema, that have the same table name pattern, and that have proper primary keys or         have the same defined offset columns.</p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/MultiTableJDBCConsumer.html#concept_ank_41x_4y" data-id="concept_ank_41x_4y"><title>Table Name Pattern</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You define the group of tables that the JDBC Multitable Consumer origin reads by         defining a table name pattern for the table configuration. The origin reads all tables whose         names match the pattern. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/MultiTableJDBCConsumer.html#concept_yfx_mhx_4y" data-id="concept_yfx_mhx_4y"><title>Offset Column and Value</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The JDBC Multitable Consumer origin uses an offset column and initial offset value to         determine where to start reading data within the tables. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Origins/MultiTableJDBCConsumer.html#concept_nff_2hx_4y" data-id="concept_nff_2hx_4y"><title>Table Order Strategy</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can define the order that the origin uses to read the tables.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/MultiTableJDBCConsumer.html#concept_xrx_11y_4y" data-id="concept_xrx_11y_4y"><title>JDBC Header Attributes</title><topicmeta></topicmeta></topic><topic href="Origins/MultiTableJDBCConsumer.html#task_kst_m4w_4y" data-id="task_kst_m4w_4y"><title>Configuring a JDBC Multitable Consumer</title><topicmeta></topicmeta></topic></topic><topic href="Origins/JDBCConsumer.html#concept_qhf_hjr_bs" data-id="concept_qhf_hjr_bs"><title>JDBC Query Consumer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/JDBCConsumer.html#concept_aq1_lxp_fs" data-id="concept_aq1_lxp_fs"><title>Installing the JDBC Driver</title><topicmeta></topicmeta></topic><topic href="Origins/JDBCConsumer.html#concept_nxz_2kz_bs" data-id="concept_nxz_2kz_bs"><title>Offset Column and Offset Value</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">JDBC Query Consumer uses an offset column and initial offset value to determine where to         start reading data within a table. Include both the offset column and the offset value in         the WHERE clause of the SQL query. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/JDBCConsumer.html#concept_ets_gnr_bs" data-id="concept_ets_gnr_bs"><title>Full and Incremental Mode</title><topicmeta></topicmeta></topic><topic href="Origins/JDBCConsumer.html#concept_hcm_gdq_ds" data-id="concept_hcm_gdq_ds"><title>Recovery</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"> JDBC Query Consumer supports recovery after a deliberate or unexpected stop when it     performs incremental queries. Recovery is not supported for full queries.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/JDBCConsumer.html#concept_uj4_mxy_bs" data-id="concept_uj4_mxy_bs"><title>SQL Query</title><topicmeta></topicmeta><topic href="Origins/JDBCConsumer.html#concept_cbn_pbw_zw" data-id="concept_cbn_pbw_zw"><title>SQL Query for Incremental Mode</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you define the SQL query for incremental mode, JDBC Query Consumer requires a WHERE         and ORDER BY clause in the query. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/JDBCConsumer.html#concept_yh1_zbw_zw" data-id="concept_yh1_zbw_zw"><title>SQL Query for Full Mode</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can define any type of SQL query for full mode. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/JDBCConsumer.html#concept_fll_lvk_bx" data-id="concept_fll_lvk_bx"><title>Stored Procedures</title><topicmeta></topicmeta></topic></topic><topic href="Origins/JDBCConsumer.html#concept_egw_d4c_kw" data-id="concept_egw_d4c_kw"><title>JDBC Record Header Attributes </title><topicmeta></topicmeta><topic href="Origins/JDBCConsumer.html#concept_tvf_tgp_fx" data-id="concept_tvf_tgp_fx"><title>Header Attributes with the Drift Synchronization Solution</title><topicmeta></topicmeta></topic></topic><topic href="Origins/JDBCConsumer.html#concept_tyd_gbf_5y" data-id="concept_tyd_gbf_5y"><title>CDC for Microsoft SQL Server</title><topicmeta></topicmeta><topic href="Origins/JDBCConsumer.html#concept_bnh_hry_ty" data-id="concept_bnh_hry_ty"><title>CRUD Record Header Attribute</title><topicmeta></topicmeta></topic><topic href="Origins/JDBCConsumer.html#concept_e1j_jwv_ht" data-id="concept_e1j_jwv_ht"><title>Group Rows by Transaction</title><topicmeta></topicmeta></topic></topic><topic href="Origins/JDBCConsumer.html#task_ryz_tkr_bs" data-id="task_ryz_tkr_bs"><title>Configuring a JDBC Query Consumer</title><topicmeta></topicmeta></topic></topic><topic href="Origins/JMS.html#concept_rhh_4nj_dt" data-id="concept_rhh_4nj_dt"><title>JMS Consumer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/JMS.html#task_bbf_2gg_ht" data-id="task_bbf_2gg_ht"><title>Installing JMS Drivers</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Before you use the JMS Consumer, install the JMS drivers for the implementation that         you are using. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/JMS.html#concept_tzl_zzj_dt" data-id="concept_tzl_zzj_dt"><title>Data Formats</title><topicmeta></topicmeta><topic href="Origins/JMS.html#concept_tr1_spd_sr" data-id="concept_tr1_spd_sr"><title>Log Formats</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you use an origin to read log data, you define the format of the log files to be   read. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Origins/JMS.html#task_zp1_4ck_dt" data-id="task_zp1_4ck_dt"><title>Configuring a JMS Consumer Origin</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Configure a JMS Consumer origin to read JMS messages.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Origins/KConsumer.html#concept_msz_wnr_5q" data-id="concept_msz_wnr_5q"><title>Kafka Consumer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/KConsumer.html#concept_zlc_ppn_js" data-id="concept_zlc_ppn_js"><title>Initial and Subsequent Offsets</title><topicmeta></topicmeta></topic><topic href="Origins/KConsumer.html#concept_hdc_fvn_sx" data-id="concept_hdc_fvn_sx"><title>Processing All Unread Data</title><topicmeta></topicmeta></topic><topic href="Origins/KConsumer.html#concept_d5f_n2g_vq" data-id="concept_d5f_n2g_vq"><title>Additional Kafka Properties</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can add custom Kafka configuration properties to the Kafka Consumer.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/KConsumer.html#concept_tlj_3g1_2z" data-id="concept_tlj_3g1_2z"><title>Record Header Attributes</title><topicmeta></topicmeta></topic><topic href="Origins/KConsumer.html#concept_yg3_k31_t5" data-id="concept_yg3_k31_t5"><title>Enabling Security</title><topicmeta></topicmeta><topic href="Origins/KConsumer.html#concept_ann_l2b_t5" data-id="concept_ann_l2b_t5"><title>Enabling SSL/TLS</title><topicmeta></topicmeta></topic><topic href="Origins/KConsumer.html#concept_w4j_3vb_t5" data-id="concept_w4j_3vb_t5"><title>Enabling Kerberos (SASL)</title><topicmeta></topicmeta></topic><topic href="Origins/KConsumer.html#concept_qzq_jrk_55" data-id="concept_qzq_jrk_55"><title>Enabling SSL/TLS and Kerberos</title><topicmeta></topicmeta></topic></topic><topic href="Origins/KConsumer.html#concept_xgs_nlc_wr" data-id="concept_xgs_nlc_wr"><title>Data Formats</title><topicmeta></topicmeta><topic href="Origins/KConsumer.html#concept_tr1_spd_sr" data-id="concept_tr1_spd_sr"><title>Log Formats</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you use an origin to read log data, you define the format of the log files to be   read. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Origins/KConsumer.html#task_npx_xgf_vq" data-id="task_npx_xgf_vq"><title>Configuring a Kafka Consumer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Configure a Kafka Consumer to read data from a Kafka cluster. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Origins/KinConsumer.html#concept_anh_4y3_yr" data-id="concept_anh_4y3_yr"><title>Kinesis Consumer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/KinConsumer.html#concept_oxv_t5g_vw" data-id="concept_oxv_t5g_vw"><title>AWS Credentials</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When <span class="ph">Data                   Collector</span> reads data from a Kinesis Consumer origin, it must pass credentials to Amazon Web         Services.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/KinConsumer.html#concept_y55_dz4_yr" data-id="concept_y55_dz4_yr"><title>Read Interval</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure the read interval for the Kinesis Consumer. The read interval   determines how long Kinesis Consumer waits before requesting additional data from Kinesis shards.   By default, the Kinesis Consumer waits one second between requests. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/KinConsumer.html#concept_cwg_r2m_35" data-id="concept_cwg_r2m_35"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Origins/KinConsumer.html#task_p4b_vv4_yr" data-id="task_p4b_vv4_yr"><title>Configuring a Kinesis Consumer Origin</title><topicmeta></topicmeta></topic></topic><topic href="Origins/MapRDBJSON.html#concept_ywh_k15_3y" data-id="concept_ywh_k15_3y"><title>MapR DB JSON</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/MapRDBJSON.html#concept_xpd_fn5_sy" data-id="concept_xpd_fn5_sy"><title>ID Field</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When the origin converts a JSON document into a record, it includes the _id field of the         JSON document in the record. If needed, you can use the Field Remover processor in the         pipeline to remove the _id field.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/MapRDBJSON.html#task_hys_s15_3y" data-id="task_hys_s15_3y"><title>Configuring a MapR DB JSON Origin</title><topicmeta></topicmeta></topic></topic><topic href="Origins/MapRFS.html#concept_psz_db4_lx" data-id="concept_psz_db4_lx"><title>MapR FS</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/MapRFS.html#concept_kfv_rg4_lx" data-id="concept_kfv_rg4_lx"><title>Kerberos Authentication</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can use Kerberos authentication to connect to MapR. When you use Kerberos         authentication, <span class="ph">Data                   Collector</span> uses         the Kerberos principal and keytab to connect to MapR. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/MapRFS.html#concept_ymk_4h4_lx" data-id="concept_ymk_4h4_lx"><title>Using a Hadoop User</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure the MapR FS origin to use a Hadoop user to read files from MapR         FS.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/MapRFS.html#concept_ojx_k34_lx" data-id="concept_ojx_k34_lx"><title>Hadoop Properties and Configuration Files</title><topicmeta></topicmeta></topic><topic href="Origins/MapRFS.html#concept_bk4_dj4_lx" data-id="concept_bk4_dj4_lx"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Origins/MapRFS.html#task_h2p_mb4_lx" data-id="task_h2p_mb4_lx"><title>Configuring a MapR FS Origin</title><topicmeta></topicmeta></topic></topic><topic href="Origins/MapRStreamsCons.html#concept_cvy_xsf_2v" data-id="concept_cvy_xsf_2v"><title>MapR Streams Consumer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/MapRStreamsCons.html#concept_lzy_xlg_2v" data-id="concept_lzy_xlg_2v"><title>Additional Properties</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can add custom configuration properties to MapR Streams Consumer.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/MapRStreamsCons.html#concept_zb5_mkg_2v" data-id="concept_zb5_mkg_2v"><title>Data Formats</title><topicmeta></topicmeta><topic href="Origins/MapRStreamsCons.html#concept_tr1_spd_sr" data-id="concept_tr1_spd_sr"><title>Log Formats</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you use an origin to read log data, you define the format of the log files to be   read. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Origins/MapRStreamsCons.html#concept_ynx_vzg_2v" data-id="concept_ynx_vzg_2v"><title>Processing Available Data</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you start a pipeline for the first time, the MapR Streams Consumer becomes a new         consumer group for the topic. It reads only incoming data, processing data from all         partitions, and ignores any existing data in the topic by default. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/MapRStreamsCons.html#task_bfz_gch_2v" data-id="task_bfz_gch_2v"><title>Configuring a MapR Streams Consumer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Configure a MapR Streams Consumer to read messages from MapR Streams. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Origins/MongoDB.html#concept_bk4_2rs_ns" data-id="concept_bk4_2rs_ns"><title>MongoDB</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/MongoDB.html#concept_kx3_zrs_ns" data-id="concept_kx3_zrs_ns"><title>Offset Field and Initial Offset</title><topicmeta></topicmeta></topic><topic href="Origins/MongoDB.html#concept_oy2_1dt_ns" data-id="concept_oy2_1dt_ns"><title>Read Preference</title><topicmeta></topicmeta></topic><topic href="Origins/MongoDB.html#concept_x1x_2pn_sy" data-id="concept_x1x_2pn_sy"><title>BSON Timestamp</title><topicmeta></topicmeta></topic><topic href="Origins/MongoDB.html#task_zry_dg2_ww" data-id="task_zry_dg2_ww"><title>Enabling SSL/TLS</title><topicmeta></topicmeta></topic><topic href="Origins/MongoDB.html#task_mdf_2rs_ns" data-id="task_mdf_2rs_ns"><title>Configuring a MongoDB Origin</title><topicmeta></topicmeta></topic></topic><topic href="Origins/MongoDBOplog.html#concept_mjn_yqw_4y" data-id="concept_mjn_yqw_4y"><title>MongoDB Oplog</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/MongoDBOplog.html#concept_iry_ykm_sy" data-id="concept_iry_ykm_sy"><title>Oplog Timestamp and Ordinal</title><topicmeta></topicmeta></topic><topic href="Origins/MongoDBOplog.html#concept_cwt_gd3_sy" data-id="concept_cwt_gd3_sy"><title>Read Preference</title><topicmeta></topicmeta></topic><topic href="Origins/MongoDBOplog.html#concept_wc3_byl_5y" data-id="concept_wc3_byl_5y"><title>Generated Records</title><topicmeta></topicmeta><topic href="Origins/MongoDBOplog.html#concept_isy_thx_ty" data-id="concept_isy_thx_ty"><title>CRUD Operation and CDC Header Attributes</title><topicmeta></topicmeta></topic></topic><topic href="Origins/MongoDBOplog.html#task_tcy_gg3_sy" data-id="task_tcy_gg3_sy"><title>Enabling SSL/TLS</title><topicmeta></topicmeta></topic><topic href="Origins/MongoDBOplog.html#task_qj5_drw_4y" data-id="task_qj5_drw_4y"><title>Configuring a MongoDB Oplog Origin</title><topicmeta></topicmeta></topic></topic><topic href="Origins/MySQLBinaryLog.html#concept_kqg_1yh_xx" data-id="concept_kqg_1yh_xx"><title>MySQL Binary Log</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/MySQLBinaryLog.html#concept_wps_52k_qy" data-id="concept_wps_52k_qy"><title>Installing the JDBC Driver</title><topicmeta></topicmeta></topic><topic href="Origins/MySQLBinaryLog.html#concept_emp_1tl_dy" data-id="concept_emp_1tl_dy"><title>Initial Offset</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure the origin to start reading the binary log file from the beginning of         the file or from an initial offset in the file.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/MySQLBinaryLog.html#concept_rfd_15l_dy" data-id="concept_rfd_15l_dy"><title>Generated Records</title><topicmeta></topicmeta><topic href="Origins/MySQLBinaryLog.html#concept_ety_5hg_5y" data-id="concept_ety_5hg_5y"><title>Processing Generated Records</title><topicmeta></topicmeta></topic></topic><topic href="Origins/MySQLBinaryLog.html#concept_lgb_nvl_dy" data-id="concept_lgb_nvl_dy"><title>Tables to Include or Ignore</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The binary log file captures all changes made to the MySQL database. If you want the         MySQL Binary Log origin to capture changes from a subset of tables, you can configure the         origin to include changes from specific tables or to ignore changes from specific         tables.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/MySQLBinaryLog.html#task_qbt_kyh_xx" data-id="task_qbt_kyh_xx"><title>Configuring a MySQL Binary Log Origin</title><topicmeta></topicmeta></topic></topic><topic href="Origins/Omniture.html#concept_dsr_xmw_1s" data-id="concept_dsr_xmw_1s"><title>Omniture</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/Omniture.html#task_of4_wpw_1s" data-id="task_of4_wpw_1s"><title>Configuring an Omniture Origin</title><topicmeta></topicmeta></topic></topic><topic href="Origins/OracleCDC.html#concept_rs5_hjj_tw" data-id="concept_rs5_hjj_tw"><title>Oracle CDC Client</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/OracleCDC.html#concept_eq5_wh2_dx" data-id="concept_eq5_wh2_dx"><title>LogMiner Dictionary Source</title><topicmeta></topicmeta></topic><topic href="Origins/OracleCDC.html#concept_xwg_33w_cx" data-id="concept_xwg_33w_cx"><title>Oracle CDC Client Prerequisites</title><topicmeta></topicmeta><topic href="Origins/OracleCDC.html#concept_gt5_xb2_3y" data-id="concept_gt5_xb2_3y"><title>Task 1. Enable LogMiner</title><topicmeta></topicmeta></topic><topic href="Origins/OracleCDC.html#concept_gvh_3c2_3y" data-id="concept_gvh_3c2_3y"><title>Task 2. Enable Supplemental Logging</title><topicmeta></topicmeta></topic><topic href="Origins/OracleCDC.html#concept_jnz_bd2_3y" data-id="concept_jnz_bd2_3y"><title>Task 3. Create a User Account</title><topicmeta></topicmeta></topic><topic href="Origins/OracleCDC.html#concept_ypm_fv1_vy" data-id="concept_ypm_fv1_vy"><title>Task 4. Extract a Log Miner Dictionary (Redo Logs)</title><topicmeta></topicmeta></topic><topic href="Origins/OracleCDC.html#concept_jqt_qd2_3y" data-id="concept_jqt_qd2_3y"><title>Task 5. Install the Driver</title><topicmeta></topicmeta></topic></topic><topic href="Origins/OracleCDC.html#concept_zrc_pyj_dx" data-id="concept_zrc_pyj_dx"><title>Initial Change</title><topicmeta></topicmeta></topic><topic href="Origins/OracleCDC.html#concept_vfw_bjz_ty" data-id="concept_vfw_bjz_ty"><title>Generated Records</title><topicmeta></topicmeta><topic href="Origins/OracleCDC.html#concept_x4h_m42_5y" data-id="concept_x4h_m42_5y"><title>CRUD Operation Header Attributes</title><topicmeta></topicmeta></topic><topic href="Origins/OracleCDC.html#concept_nn1_lxd_dx" data-id="concept_nn1_lxd_dx"><title>CDC Header Attributes</title><topicmeta></topicmeta></topic></topic><topic href="Origins/OracleCDC.html#concept_h2t_hx1_vy" data-id="concept_h2t_hx1_vy"><title>Event Generation</title><topicmeta></topicmeta><topic href="Origins/OracleCDC.html#concept_cbz_sz1_vy" data-id="concept_cbz_sz1_vy"><title>Event Records</title><topicmeta></topicmeta></topic></topic><topic href="Origins/OracleCDC.html#concept_q4t_b32_dx" data-id="concept_q4t_b32_dx"><title>Working with the Drift Synchronization Solution</title><topicmeta></topicmeta></topic><topic href="Origins/OracleCDC.html#concept_idl_bl3_jx" data-id="concept_idl_bl3_jx"><title>Data Preview with Oracle CDC Client</title><topicmeta></topicmeta></topic><topic href="Origins/OracleCDC.html#task_ehh_mjj_tw" data-id="task_ehh_mjj_tw"><title>Configuring an Oracle CDC Client</title><topicmeta></topicmeta></topic></topic><topic href="Origins/RabbitMQ.html#concept_dyg_lq1_h5" data-id="concept_dyg_lq1_h5"><title>RabbitMQ Consumer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/RabbitMQ.html#concept_z2d_mgr_k5" data-id="concept_z2d_mgr_k5"><title>Queue</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">RabbitMQ Consumer reads messages from a specified queue. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/RabbitMQ.html#concept_nhr_5tk_k5" data-id="concept_nhr_5tk_k5"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Origins/RabbitMQ.html#task_hrz_mq1_h5" data-id="task_hrz_mq1_h5"><title>Configuring a RabbitMQ Consumer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Configure a RabbitMQ Consumer to read messages from a RabbitMQ queue. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Origins/Redis.html#concept_plr_t3v_jw" data-id="concept_plr_t3v_jw"><title>Redis Consumer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/Redis.html#concept_kww_cmw_jw" data-id="concept_kww_cmw_jw"><title>Channels and Patterns</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can specify channels and patterns to define the data that the Redis Consumer origin         processes.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/Redis.html#concept_w54_kpv_jw" data-id="concept_w54_kpv_jw"><title>Data Formats </title><topicmeta></topicmeta><topic href="Origins/Redis.html#concept_tr1_spd_sr" data-id="concept_tr1_spd_sr"><title>Log Formats</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you use an origin to read log data, you define the format of the log files to be   read. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Origins/Redis.html#task_dtz_npv_jw" data-id="task_dtz_npv_jw"><title>Configuring a Redis Consumer</title><topicmeta></topicmeta></topic></topic><topic href="Origins/Salesforce.html#concept_odf_vr3_rx" data-id="concept_odf_vr3_rx"><title>Salesforce</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/Salesforce.html#concept_djn_x4c_tx" data-id="concept_djn_x4c_tx"><title>Query Existing Data</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The Salesforce origin can execute a query to read existing data from Salesforce. Use the         Salesforce Object Query Language (SOQL) to write the query.</p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/Salesforce.html#concept_vdt_dxc_tx" data-id="concept_vdt_dxc_tx"><title>SOQL Query</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you configure the Salesforce origin to query existing data, you define the SOQL         query that the origin uses to return data from Salesforce. The Salesforce origin requires a         WHERE and ORDER BY clause in the query. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/Salesforce.html#concept_n5z_hgh_tx" data-id="concept_n5z_hgh_tx"><title>Example</title><topicmeta></topicmeta></topic></topic><topic href="Origins/Salesforce.html#concept_owv_nj5_2z" data-id="concept_owv_nj5_2z"><title>Repeat Query</title><topicmeta></topicmeta></topic><topic href="Origins/Salesforce.html#concept_nnd_y4c_tx" data-id="concept_nnd_y4c_tx"><title>Subscribe to Notifications</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The Salesforce origin can subscribe to the Force.com Streaming API to receive         notifications for changes to Salesforce data.</p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/Salesforce.html#concept_ec1_qlq_tx" data-id="concept_ec1_qlq_tx"><title>Notification Record Format</title><topicmeta></topicmeta></topic></topic><topic href="Origins/Salesforce.html#concept_m13_xrc_tx" data-id="concept_m13_xrc_tx"><title>Reading Custom Objects or Fields</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">If the origin reads custom Salesforce objects or fields, you might want to use a Field         Renamer in the pipeline to rename the custom fields.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/Salesforce.html#concept_psx_1wg_cy" data-id="concept_psx_1wg_cy"><title>Salesforce Header Attributes</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The Salesforce origin generates Salesforce record header attributes that provide         additional information about each record, such as the source objects for the record. The         origin receives these details from Salesforce.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/Salesforce.html#concept_yns_y2m_5y" data-id="concept_yns_y2m_5y"><title>CRUD Operation Header Attribute</title><topicmeta></topicmeta></topic><topic href="Origins/Salesforce.html#task_ssp_krd_dy" data-id="task_ssp_krd_dy"><title>Changing the API Version</title><topicmeta></topicmeta></topic><topic href="Origins/Salesforce.html#task_h1n_bs3_rx" data-id="task_h1n_bs3_rx"><title>Configuring a Salesforce Origin</title><topicmeta></topicmeta></topic></topic><topic href="Origins/SDC_RPCorigin.html#concept_agb_5c1_ct" data-id="concept_agb_5c1_ct"><title>SDC RPC </title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/SDC_RPCorigin.html#task_lxh_1w2_ct" data-id="task_lxh_1w2_ct"><title>Configuring an SDC RPC Origin</title><topicmeta></topicmeta></topic></topic><topic href="Origins/SDCRPCtoKafka.html#concept_tdk_slk_pw" data-id="concept_tdk_slk_pw"><title>SDC RPC to Kafka</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/SDCRPCtoKafka.html#concept_mzz_g4l_pw" data-id="concept_mzz_g4l_pw"><title>Pipeline Configuration</title><topicmeta></topicmeta></topic><topic href="Origins/SDCRPCtoKafka.html#concept_p3b_5ms_pw" data-id="concept_p3b_5ms_pw"><title>Concurrent Requests</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can specify the maximum number of requests the SDC RPC to Kafka origin handles at         one time. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/SDCRPCtoKafka.html#concept_ezk_btx_pw" data-id="concept_ezk_btx_pw"><title>Batch Request Size, Kafka Message Size, and Kafka Configuration</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Configure the SDC RPC to Kafka maximum batch request size and Kafka message size         properties in relationship to each other and to the maximum message size configured in         Kafka.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/SDCRPCtoKafka.html#concept_vhc_jgc_rw" data-id="concept_vhc_jgc_rw"><title>Additional Kafka Properties</title><topicmeta></topicmeta></topic><topic href="Origins/SDCRPCtoKafka.html#concept_vhx_2jc_rw" data-id="concept_vhx_2jc_rw"><title>Enabling Kafka Security</title><topicmeta></topicmeta><topic href="Origins/SDCRPCtoKafka.html#concept_xsb_5xc_rw" data-id="concept_xsb_5xc_rw"><title>Enabling SSL/TLS</title><topicmeta></topicmeta></topic><topic href="Origins/SDCRPCtoKafka.html#concept_fyp_vcd_rw" data-id="concept_fyp_vcd_rw"><title>Enabling Kerberos (SASL)</title><topicmeta></topicmeta></topic><topic href="Origins/SDCRPCtoKafka.html#concept_hx4_3yd_rw" data-id="concept_hx4_3yd_rw"><title>Enabling SSL/TLS and Kerberos</title><topicmeta></topicmeta></topic></topic><topic href="Origins/SDCRPCtoKafka.html#task_il5_gtl_pw" data-id="task_il5_gtl_pw"><title>Configuring an SDC RPC to Kafka Origin</title><topicmeta></topicmeta></topic></topic><topic href="Origins/SFTP.html#concept_ic5_bzd_5v" data-id="concept_ic5_bzd_5v"><title>SFTP/FTP Client</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/SFTP.html#concept_qmp_kmq_1y" data-id="concept_qmp_kmq_1y"><title>Read Order</title><topicmeta></topicmeta></topic><topic href="Origins/SFTP.html#concept_vnj_njp_yv" data-id="concept_vnj_njp_yv"><title>Credentials</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">If the remote server requires authentication, configure the authentication method that         the origin must use to log in to the remote server.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/SFTP.html#concept_jcx_ggs_wv" data-id="concept_jcx_ggs_wv"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Origins/SFTP.html#task_lfx_fzd_5v" data-id="task_lfx_fzd_5v"><title>Configuring an SFTP/FTP Client Origin</title><topicmeta></topicmeta></topic></topic><topic href="Origins/UDP.html#concept_rst_2y5_1s" data-id="concept_rst_2y5_1s"><title>UDP Source</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/UDP.html#task_kgn_rcv_1s" data-id="task_kgn_rcv_1s"><title>Configuring a UDP Source</title><topicmeta></topicmeta></topic></topic><topic href="Origins/UDPtoKafka.html#concept_jzq_jcz_pw" data-id="concept_jzq_jcz_pw"><title>UDP to Kafka</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Origins/UDPtoKafka.html#concept_flq_twg_qw" data-id="concept_flq_twg_qw"><title>Pipeline Configuration</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you use a UDP to Kafka origin in a pipeline, connect the origin to a Trash         destination. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Origins/UDPtoKafka.html#concept_owg_1hc_rw" data-id="concept_owg_1hc_rw"><title>Additional Kafka Properties</title><topicmeta></topicmeta></topic><topic href="Origins/UDPtoKafka.html#concept_kn3_tjc_rw" data-id="concept_kn3_tjc_rw"><title>Enabling Kafka Security</title><topicmeta></topicmeta><topic href="Origins/UDPtoKafka.html#concept_wb5_sxc_rw" data-id="concept_wb5_sxc_rw"><title>Enabling SSL/TLS</title><topicmeta></topicmeta></topic><topic href="Origins/UDPtoKafka.html#concept_xyx_mtd_rw" data-id="concept_xyx_mtd_rw"><title>Enabling Kerberos (SASL)</title><topicmeta></topicmeta></topic><topic href="Origins/UDPtoKafka.html#concept_xgk_4yd_rw" data-id="concept_xgk_4yd_rw"><title>Enabling SSL/TLS and Kerberos</title><topicmeta></topicmeta></topic></topic><topic href="Origins/UDPtoKafka.html#task_tvh_bhz_pw" data-id="task_tvh_bhz_pw"><title>Configuring a UDP to Kafka Origin</title><topicmeta></topicmeta></topic></topic></topic><topic href="Processors/Processors_title.html" data-id="concept_yjl_nc5_jq"><title>Processors</title><topicmeta></topicmeta><topic href="Processors/Processors_overview.html#concept_hpr_twm_jq" data-id="concept_hpr_twm_jq"><title>Processors</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/Base64Decoder.html#concept_ujj_spy_kv" data-id="concept_ujj_spy_kv"><title>Base64 Field Decoder</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/Base64Decoder.html#task_pnn_5py_kv" data-id="task_pnn_5py_kv"><title>Configuring a Base64 Field Decoder</title><topicmeta></topicmeta></topic></topic><topic href="Processors/Base64Encoder.html#concept_wtr_mpy_kv" data-id="concept_wtr_mpy_kv"><title>Base64 Field Encoder</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/Base64Encoder.html#task_ekg_ppy_kv" data-id="task_ekg_ppy_kv"><title>Configuring a Base64 Field Encoder</title><topicmeta></topicmeta></topic></topic><topic href="Processors/Expression.html#concept_zm2_pp3_wq" data-id="concept_zm2_pp3_wq"><title>Expression Evaluator</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/Expression.html#concept_pzk_fz4_yq" data-id="concept_pzk_fz4_yq"><title>Output Fields and Attributes</title><topicmeta></topicmeta></topic><topic href="Processors/Expression.html#concept_qf3_mfq_f5" data-id="concept_qf3_mfq_f5"><title>Record Header Attribute Expressions</title><topicmeta></topicmeta></topic><topic href="Processors/Expression.html#concept_mb2_fsp_1z" data-id="concept_mb2_fsp_1z"><title>Field Attribute Expressions</title><topicmeta></topicmeta></topic><topic href="Processors/Expression.html#task_x2h_tv4_yq" data-id="task_x2h_tv4_yq"><title>Configuring an Expression Evaluator</title><topicmeta></topicmeta></topic></topic><topic href="Processors/FieldFlattener.html#concept_njn_3kk_fx" data-id="concept_njn_3kk_fx"><title>Field Flattener</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/FieldFlattener.html#concept_k4x_rz1_hx" data-id="concept_k4x_rz1_hx"><title>Flatten the Entire Record</title><topicmeta></topicmeta></topic><topic href="Processors/FieldFlattener.html#concept_vpx_zc1_xx" data-id="concept_vpx_zc1_xx"><title>Flatten Specific Fields</title><topicmeta></topicmeta></topic><topic href="Processors/FieldFlattener.html#task_xdv_kkk_fx" data-id="task_xdv_kkk_fx"><title>Configuring a Field Flattener</title><topicmeta></topicmeta></topic></topic><topic href="Processors/FieldHasher.html#concept_ivv_c3k_wq" data-id="concept_ivv_c3k_wq"><title>Field Hasher</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/FieldHasher.html#concept_ssq_5jb_mv" data-id="concept_ssq_5jb_mv"><title>Hash Methods</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Field Hasher provides several methods to hash data. When you hash a field more than         once, Field Hasher uses the existing hash when generating the next hash. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/FieldHasher.html#concept_qvs_z4g_4v" data-id="concept_qvs_z4g_4v"><title>List, Map, and List-Map Fields</title><topicmeta></topicmeta></topic><topic href="Processors/FieldHasher.html#task_xjd_dlk_wq" data-id="task_xjd_dlk_wq"><title>Configuring a Field Hasher</title><topicmeta></topicmeta></topic></topic><topic href="Processors/FieldMasker.html#concept_hjc_t4k_wq" data-id="concept_hjc_t4k_wq"><title>Field Masker</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/FieldMasker.html#concept_vwp_gh4_wq" data-id="concept_vwp_gh4_wq"><title>Mask Types</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can use the following mask types to mask data: </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/FieldMasker.html#task_vgg_z44_wq" data-id="task_vgg_z44_wq"><title>Configuring a Field Masker</title><topicmeta></topicmeta></topic></topic><topic href="Processors/FieldMerger.html#concept_pgm_tsl_gt" data-id="concept_pgm_tsl_gt"><title>Field Merger</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/FieldMerger.html#task_ghx_5vl_gt" data-id="task_ghx_5vl_gt"><title>Configuring a Field Merger</title><topicmeta></topicmeta></topic></topic><topic href="Processors/ListPivoter.html#concept_ekg_313_qw" data-id="concept_ekg_313_qw"><title>Field Pivoter</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/ListPivoter.html#concept_efn_wgw_tw" data-id="concept_efn_wgw_tw"><title>Generated Records</title><topicmeta></topicmeta></topic><topic href="Processors/ListPivoter.html#task_dn1_k13_qw" data-id="task_dn1_k13_qw"><title>Configuring a Field Pivoter</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Configure a Field Pivoter to pivot data in a list, map, or list-map field and         generate a record for each item in the field.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Processors/FieldRemover.html#concept_jdd_blr_wq" data-id="concept_jdd_blr_wq"><title>Field Remover</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/FieldRemover.html#task_c1j_btr_wq" data-id="task_c1j_btr_wq"><title>Configuring a Field Remover</title><topicmeta></topicmeta></topic></topic><topic href="Processors/FieldRenamer.html#concept_vyv_zsg_ht" data-id="concept_vyv_zsg_ht"><title>Field Renamer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/FieldRenamer.html#concept_ogb_bqf_lw" data-id="concept_ogb_bqf_lw"><title>Renaming Sets of Fields</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can use regular expressions, or <dfn class="term">regex</dfn>, to rename sets of fields. You         can use regex to define the set of source fields to rename. You can also use regex to define         the target field names. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/FieldRenamer.html#task_y5g_4hh_ht" data-id="task_y5g_4hh_ht"><title>Configuring a Field Renamer</title><topicmeta></topicmeta></topic></topic><topic href="Processors/FieldSplitter.html#concept_vlj_vph_yq" data-id="concept_vlj_vph_yq"><title>Field Splitter</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/FieldSplitter.html#concept_ilb_m3t_3x" data-id="concept_ilb_m3t_3x"><title>Not Enough Splits</title><topicmeta></topicmeta></topic><topic href="Processors/FieldSplitter.html#concept_ysb_5st_3x" data-id="concept_ysb_5st_3x"><title>Too Many Splits</title><topicmeta></topicmeta></topic><topic href="Processors/FieldSplitter.html#concept_axv_hkt_3x" data-id="concept_axv_hkt_3x"><title>Example</title><topicmeta></topicmeta></topic><topic href="Processors/FieldSplitter.html#task_av1_5g3_yq" data-id="task_av1_5g3_yq"><title>Configuring a Field Splitter</title><topicmeta></topicmeta></topic></topic><topic href="Processors/FieldTypeConverter.html#concept_is3_zkp_wq" data-id="concept_is3_zkp_wq"><title>Field Type Converter</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/FieldTypeConverter.html#concept_ixz_s5q_wq" data-id="concept_ixz_s5q_wq"><title>Valid Type Conversions</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The following table lists the data types that can be converted to another data type.   List, Map, and List-Map data types cannot be converted.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/FieldTypeConverter.html#concept_sym_c4g_xx" data-id="concept_sym_c4g_xx"><title>Changing the Scale of Decimal Fields</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can use the Field Type Converter to change the scale of decimal fields. For example,         you might have a decimal field with the value 12345.6789115, and you'd like to decrease the         scale to 4 so that the value is 12345.6789. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/FieldTypeConverter.html#task_g23_2tq_wq" data-id="task_g23_2tq_wq"><title>Configuring a Field Type Converter</title><topicmeta></topicmeta></topic></topic><topic href="Processors/FieldZip.html#concept_o3b_t1k_yx" data-id="concept_o3b_t1k_yx"><title>Field Zip</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/FieldZip.html#concept_ifv_3h1_hy" data-id="concept_ifv_3h1_hy"><title>Merging List Data</title><topicmeta></topicmeta></topic><topic href="Processors/FieldZip.html#concept_gf1_sz2_3y" data-id="concept_gf1_sz2_3y"><title>Merging List-Map Data</title><topicmeta></topicmeta></topic><topic href="Processors/FieldZip.html#concept_bmt_s41_hy" data-id="concept_bmt_s41_hy"><title>Pivoting Merged Lists</title><topicmeta></topicmeta></topic><topic href="Processors/FieldZip.html#task_nqj_51k_yx" data-id="task_nqj_51k_yx"><title>Configuring a Field Zip Processor</title><topicmeta></topicmeta></topic></topic><topic href="Processors/GeoIP.html#concept_fch_fc3_ms" data-id="concept_fch_fc3_ms"><title>Geo IP</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/GeoIP.html#concept_clx_bng_hx" data-id="concept_clx_bng_hx"><title>Supported Databases</title><topicmeta></topicmeta></topic><topic href="Processors/GeoIP.html#concept_kg2_21s_ns" data-id="concept_kg2_21s_ns"><title>Database File Location</title><topicmeta></topicmeta></topic><topic href="Processors/GeoIP.html#concept_ewg_mgh_hx" data-id="concept_ewg_mgh_hx"><title> GeoIP Field Types</title><topicmeta></topicmeta><topic href="Processors/GeoIP.html#concept_pmp_b1y_hx" data-id="concept_pmp_b1y_hx"><title>Full JSON Field Types</title><topicmeta></topicmeta></topic></topic><topic href="Processors/GeoIP.html#task_wpz_nhs_ns" data-id="task_wpz_nhs_ns"><title>Configuring a Geo IP Processor</title><topicmeta></topicmeta></topic></topic><topic href="Processors/Groovy.html#concept_ldh_sct_gv" data-id="concept_ldh_sct_gv"><title>Groovy Evaluator</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/Groovy.html#concept_ljq_z2t_gv" data-id="concept_ljq_z2t_gv"><title>Processing Mode</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can choose the processing mode to use with the Groovy Evaluator. You can use the   same script in each processing mode. However, you should include error handling in the script   before you run in batch mode.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/Groovy.html#concept_hzt_zjt_gv" data-id="concept_hzt_zjt_gv"><title>Groovy Scripting Objects</title><topicmeta></topicmeta></topic><topic href="Processors/Groovy.html#concept_rmp_xlt_gv" data-id="concept_rmp_xlt_gv"><title>Processing List-Map Data</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">In scripts that process list-map data, treat the data as maps. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/Groovy.html#concept_u13_flh_tw" data-id="concept_u13_flh_tw"><title>Type Handling</title><topicmeta></topicmeta></topic><topic href="Processors/Groovy.html#concept_qcz_ssq_1y" data-id="concept_qcz_ssq_1y"><title>Event Generation</title><topicmeta></topicmeta></topic><topic href="Processors/Groovy.html#concept_uw4_kqw_1y" data-id="concept_uw4_kqw_1y"><title>Working with Record Header Attributes</title><topicmeta></topicmeta><topic href="Processors/Groovy.html#concept_jsz_qdy_1y" data-id="concept_jsz_qdy_1y"><title>Viewing Record Header Attributes</title><topicmeta></topicmeta></topic></topic><topic href="Processors/Groovy.html#concept_t35_rsy_mx" data-id="concept_t35_rsy_mx"><title>Accessing Whole File Format Records</title><topicmeta></topicmeta></topic><topic href="Processors/Groovy.html#concept_vjg_wpt_bz" data-id="concept_vjg_wpt_bz"><title>Calling External Java Code</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can call external Java code from the Groovy Evaluator. Simply install the external         Java library to make it available to the Groovy Evaluator. Then, call the external Java code         from the Groovy script that you develop for the processor. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/Groovy.html#task_otr_swr_nx" data-id="task_otr_swr_nx"><title>Granting Permissions on Groovy Scripts</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">If <span class="ph">Data                   Collector</span> is         using the Java Security Manager and the Groovy code needs to access network resources, you         must update the Data Collector security policy to include Groovy scripts. The Java Security         Manager is enabled by default.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/Groovy.html#task_asl_bpt_gv" data-id="task_asl_bpt_gv"><title>Configuring a Groovy Evaluator</title><topicmeta></topicmeta></topic></topic><topic href="Processors/HBaseLookup.html#concept_mnj_zhq_bw" data-id="concept_mnj_zhq_bw"><title>HBase Lookup</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/HBaseLookup.html#concept_txl_x4s_bw" data-id="concept_txl_x4s_bw"><title>Lookup Key</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you define the lookup key, you specify the row and optionally the column and         timestamp to look up in HBase. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/HBaseLookup.html#concept_xvz_zjy_bw" data-id="concept_xvz_zjy_bw"><title>Lookup Cache</title><topicmeta></topicmeta></topic><topic href="Processors/HBaseLookup.html#concept_nqg_lcy_bw" data-id="concept_nqg_lcy_bw"><title>Kerberos Authentication</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can use Kerberos authentication to connect to HBase. When you use Kerberos         authentication, <span class="ph">Data                   Collector</span> uses         the Kerberos principal and keytab to connect to HBase. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/HBaseLookup.html#concept_bzv_cdy_bw" data-id="concept_bzv_cdy_bw"><title>Using an HBase User</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure the processor to use an HBase user to look up data in HBase. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/HBaseLookup.html#concept_nks_rdy_bw" data-id="concept_nks_rdy_bw"><title>HDFS Properties and Configuration File</title><topicmeta></topicmeta></topic><topic href="Processors/HBaseLookup.html#task_z25_b3q_bw" data-id="task_z25_b3q_bw"><title>Configuring an HBase Lookup</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Configure an HBase Lookup processor to perform key-value lookups in         HBase.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Processors/HiveMetadata.html#concept_rz5_nft_zv" data-id="concept_rz5_nft_zv"><title>Hive Metadata</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/HiveMetadata.html#concept_avd_qym_fw" data-id="concept_avd_qym_fw"><title>Output Streams</title><topicmeta></topicmeta></topic><topic href="Processors/HiveMetadata.html#concept_g3p_sss_dw" data-id="concept_g3p_sss_dw"><title>Metadata Records and Record Header Attributes</title><topicmeta></topicmeta></topic><topic href="Processors/HiveMetadata.html#concept_zbk_jk3_fw" data-id="concept_zbk_jk3_fw"><title> Database, Table, and Partition Expressions</title><topicmeta></topicmeta><topic href="Processors/HiveMetadata.html#concept_vt5_z5l_nx" data-id="concept_vt5_z5l_nx"><title>Hive Names and Supported Characters</title><topicmeta></topicmeta></topic></topic><topic href="Processors/HiveMetadata.html#concept_mrh_hrp_fx" data-id="concept_mrh_hrp_fx"><title>Decimal Field Expressions</title><topicmeta></topicmeta></topic><topic href="Processors/HiveMetadata.html#concept_pg1_1fl_3w" data-id="concept_pg1_1fl_3w"><title>Time Basis</title><topicmeta></topicmeta></topic><topic href="Processors/HiveMetadata.html#concept_utk_3bt_dw" data-id="concept_utk_3bt_dw"><title>Cache</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The Hive Metadata processor queries Hive for information and caches the results. When         possible, it uses the cache for record comparison to avoid unnecessary Hive queries. </p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/HiveMetadata.html#concept_ovn_kdt_dw" data-id="concept_ovn_kdt_dw"><title>Cache Size and Evictions</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure the maximum size of the cache. When the cache reaches the specified         limit, it uses the LRU eviction policy, which removes the least recently used data to allow         for new entries to be written to the cache. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Processors/HiveMetadata.html#concept_fdq_ngd_3w" data-id="concept_fdq_ngd_3w"><title>Kerberos Authentication</title><topicmeta></topicmeta></topic><topic href="Processors/HiveMetadata.html#concept_d2h_y1s_dw" data-id="concept_d2h_y1s_dw"><title>Hive Properties and Configuration Files</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You must configure Hive Metadata to use Hive and Hadoop configuration files and         individual properties.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/HiveMetadata.html#task_hpg_pft_zv" data-id="task_hpg_pft_zv"><title>Configuring a Hive Metadata Processor</title><topicmeta></topicmeta></topic></topic><topic href="Processors/HTTPClient.html#concept_ghx_ypr_fw" data-id="concept_ghx_ypr_fw"><title>HTTP Client</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/HTTPClient.html#concept_t4k_2hh_jw" data-id="concept_t4k_2hh_jw"><title>HTTP Method</title><topicmeta></topicmeta><topic href="Processors/HTTPClient.html#concept_dc2_qwn_jw" data-id="concept_dc2_qwn_jw"><title>Expression Method</title><topicmeta></topicmeta></topic></topic><topic href="Processors/HTTPClient.html#concept_d3m_yrn_jw" data-id="concept_d3m_yrn_jw"><title>Parallel Requests</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The HTTP Client processor sends multiple requests at a time. To preserve record order,         the processor waits until all requests for the entire batch are completed before processing         the next batch.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/HTTPClient.html#concept_ekz_wrz_zw" data-id="concept_ekz_wrz_zw"><title>Response Header Fields</title><topicmeta></topicmeta></topic><topic href="Processors/HTTPClient.html#concept_s4p_15f_5y" data-id="concept_s4p_15f_5y"><title>OAuth 2 Authorization</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure the HTTP Client processor to use the OAuth 2 protocol to connect to an         HTTP service that uses basic, digest, or universal authentication, OAuth 2 client         credentials, OAuth 2 username and password, or OAuth 2 JSON Web Tokens (JWT).</p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/HTTPClient.html#task_ekx_svf_5y" data-id="task_ekx_svf_5y"><title>Example for Twitter</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">To use OAuth 2 authorization to read from Twitter, configure HTTP Client to use basic         authentication and the client credentials grant.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/HTTPClient.html#task_pkq_dcg_5y" data-id="task_pkq_dcg_5y"><title>Example for Microsoft Azure AD</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">To use OAuth 2 authorization to read from Microsoft Azure AD, configure HTTP Client         to use no authentication and the client credentials grant.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/HTTPClient.html#task_ig3_tkg_5y" data-id="task_ig3_tkg_5y"><title>Example for Google</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">To use OAuth 2 authorization to read from Google service accounts, configure HTTP         Client to use no authentication and the JSON Web Tokens grant.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Processors/HTTPClient.html#concept_jrj_hmh_jw" data-id="concept_jrj_hmh_jw"><title>Data Formats</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The HTTP Client processor writes the server response to the specified field in the         record. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/HTTPClient.html#task_z54_1qr_fw" data-id="task_z54_1qr_fw"><title>Configuring HTTP Client Processor</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Configure an HTTP Client processor to perform requests against a resource         URL.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Processors/JavaScript.html#concept_n2p_jgf_lr" data-id="concept_n2p_jgf_lr"><title>JavaScript Evaluator</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/JavaScript.html#concept_zsj_jxt_lv" data-id="concept_zsj_jxt_lv"><title>Processing Mode</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can choose the processing mode to use with the JavaScript Evaluator. You can use the         same script in each processing mode. However, you should include error handling in the         script before you run in batch mode.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/JavaScript.html#concept_mqn_5vk_sr" data-id="concept_mqn_5vk_sr"><title>JavaScript Scripting Objects</title><topicmeta></topicmeta></topic><topic href="Processors/JavaScript.html#concept_a1r_5qj_b5" data-id="concept_a1r_5qj_b5"><title>Processing List-Map Data</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">In scripts that process list-map data, treat the data as maps. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/JavaScript.html#concept_szj_slw_tr" data-id="concept_szj_slw_tr"><title>Type Handling</title><topicmeta></topicmeta></topic><topic href="Processors/JavaScript.html#concept_mkv_wgh_cy" data-id="concept_mkv_wgh_cy"><title>Event Generation</title><topicmeta></topicmeta></topic><topic href="Processors/JavaScript.html#concept_sh1_khh_cy" data-id="concept_sh1_khh_cy"><title>Working with Record Header Attributes</title><topicmeta></topicmeta><topic href="Processors/JavaScript.html#concept_zvs_whh_cy" data-id="concept_zvs_whh_cy"><title>Viewing Record Header Attributes</title><topicmeta></topicmeta></topic></topic><topic href="Processors/JavaScript.html#concept_bfr_h5y_mx" data-id="concept_bfr_h5y_mx"><title>Accessing Whole File Format Records</title><topicmeta></topicmeta></topic><topic href="Processors/JavaScript.html#concept_csq_4vt_bz" data-id="concept_csq_4vt_bz"><title>Calling External Java Code</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can call external Java code from the JavaScript Evaluator. Simply install the         external Java library to make it available to the JavaScript Evaluator. Then, call the         external Java code from the script that you develop for the processor. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/JavaScript.html#task_mzc_1by_nr" data-id="task_mzc_1by_nr"><title>Configuring a JavaScript Evaluator</title><topicmeta></topicmeta></topic></topic><topic href="Processors/JDBCLookup.html#concept_ysc_ccy_hw" data-id="concept_ysc_ccy_hw"><title>JDBC Lookup</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/JDBCLookup.html#concept_nw3_t3p_tw" data-id="concept_nw3_t3p_tw"><title>Installing the JDBC Driver</title><topicmeta></topicmeta></topic><topic href="Processors/JDBCLookup.html#concept_jt5_kx2_px" data-id="concept_jt5_kx2_px"><title>Lookup Cache</title><topicmeta></topicmeta></topic><topic href="Processors/JDBCLookup.html#task_kbr_2cy_hw" data-id="task_kbr_2cy_hw"><title>Configuring a JDBC Lookup</title><topicmeta></topicmeta></topic></topic><topic href="Processors/JDBCTee.html#concept_qbx_lcy_hw" data-id="concept_qbx_lcy_hw"><title>JDBC Tee</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/JDBCTee.html#concept_h35_xwq_tw" data-id="concept_h35_xwq_tw"><title>Installing the JDBC Driver</title><topicmeta></topicmeta></topic><topic href="Processors/JDBCTee.html#concept_qfd_tpm_5y" data-id="concept_qfd_tpm_5y"><title>Define the CRUD Operation</title><topicmeta></topicmeta></topic><topic href="Processors/JDBCTee.html#task_qpj_ncy_hw" data-id="task_qpj_ncy_hw"><title>Configuring a JDBC Tee</title><topicmeta></topicmeta></topic></topic><topic href="Processors/JSONParser.html#concept_bs1_4t3_yq" data-id="concept_bs1_4t3_yq"><title>JSON Parser</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/JSONParser.html#task_kwz_lg2_zq" data-id="task_kwz_lg2_zq"><title>Configuring a JSON Parser</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Configure a JSON Parser to parse a JSON object in a String field. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Processors/Jython.html#concept_a1h_lkf_lr" data-id="concept_a1h_lkf_lr"><title>Jython Evaluator</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/Jython.html#concept_j1t_ntc_pr" data-id="concept_j1t_ntc_pr"><title>Processing Mode</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can choose the processing mode to use with the Jython Evaluator. You can use the     same script in each processing mode. However, you should include error handling in the script     before you run in batch mode.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/Jython.html#concept_mqn_5vk_sr" data-id="concept_mqn_5vk_sr"><title>Jython Scripting Objects</title><topicmeta></topicmeta></topic><topic href="Processors/Jython.html#concept_a1r_5qj_b5" data-id="concept_a1r_5qj_b5"><title>Processing List-Map Data</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">In scripts that process list-map data, treat the data as maps. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/Jython.html#concept_szj_slw_tr" data-id="concept_szj_slw_tr"><title>Type Handling</title><topicmeta></topicmeta></topic><topic href="Processors/Jython.html#concept_zhd_chh_cy" data-id="concept_zhd_chh_cy"><title>Event Generation</title><topicmeta></topicmeta></topic><topic href="Processors/Jython.html#concept_s2k_qhh_cy" data-id="concept_s2k_qhh_cy"><title>Working with Record Header Attributes</title><topicmeta></topicmeta><topic href="Processors/Jython.html#concept_gdp_c3h_cy" data-id="concept_gdp_c3h_cy"><title>Viewing Record Header Attributes</title><topicmeta></topicmeta></topic></topic><topic href="Processors/Jython.html#concept_jrt_s5y_mx" data-id="concept_jrt_s5y_mx"><title>Accessing Whole File Format Records</title><topicmeta></topicmeta></topic><topic href="Processors/Jython.html#concept_lmz_pwt_bz" data-id="concept_lmz_pwt_bz"><title>Calling External Java Code</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can call external Java code from the Jython Evaluator. Simply install the external         Java library to make it available to the Jython Evaluator. Then, call the external Java code         from the Jython script that you develop for the processor. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/Jython.html#task_fty_jwx_nr" data-id="task_fty_jwx_nr"><title>Configuring a Jython Evaluator</title><topicmeta></topicmeta></topic></topic><topic href="Processors/LogParser.html#concept_ulm_qdq_fs" data-id="concept_ulm_qdq_fs"><title>Log Parser</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/LogParser.html#concept_tr1_spd_sr" data-id="concept_tr1_spd_sr"><title>Log Formats</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you use Log Parser to parse log data, you define the format of the log files to be   read. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/LogParser.html#task_jm1_b4w_fs" data-id="task_jm1_b4w_fs"><title>Configuring a Log Parser</title><topicmeta></topicmeta></topic></topic><topic href="Processors/RDeduplicator.html#concept_z3m_v52_zq" data-id="concept_z3m_v52_zq"><title>Record Deduplicator</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/RDeduplicator.html#concept_swx_lbf_zq" data-id="concept_swx_lbf_zq"><title>Comparison Window</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The Record Deduplicator caches record information for comparison until it reaches a   specified number of records. Then, it discards the information in the cache and starts over. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/RDeduplicator.html#task_ikr_c2f_zq" data-id="task_ikr_c2f_zq"><title>Configuring a Record Deduplicator</title><topicmeta></topicmeta></topic></topic><topic href="Processors/RedisLookup.html#concept_ng3_lpr_pv" data-id="concept_ng3_lpr_pv"><title>Redis Lookup</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/RedisLookup.html#concept_qs3_zz4_zv" data-id="concept_qs3_zz4_zv"><title>Data Types</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you define the key to look up in Redis, you specify the data type of the Redis         value. The Redis Lookup processor converts the Redis data type to a <span class="ph">Data                   Collector</span> data         type.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/RedisLookup.html#concept_zcg_21p_zv" data-id="concept_zcg_21p_zv"><title>Lookup Cache</title><topicmeta></topicmeta></topic><topic href="Processors/RedisLookup.html#task_gpv_npr_pv" data-id="task_gpv_npr_pv"><title>Configuring a Redis Lookup Processor</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Configure a Redis Lookup processor to perform key-value lookups in Redis.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Processors/SalesforceLookup.html#concept_k23_3rk_yx" data-id="concept_k23_3rk_yx"><title>Salesforce Lookup</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/SalesforceLookup.html#concept_s1h_1mk_fy" data-id="concept_s1h_1mk_fy"><title>Lookup Cache</title><topicmeta></topicmeta></topic><topic href="Processors/SalesforceLookup.html#task_rjz_lck_fy" data-id="task_rjz_lck_fy"><title>Changing the API Version</title><topicmeta></topicmeta></topic><topic href="Processors/SalesforceLookup.html#task_fhn_yrk_yx" data-id="task_fhn_yrk_yx"><title>Configuring a Salesforce Lookup</title><topicmeta></topicmeta></topic></topic><topic href="Processors/Spark.html#concept_cpx_1lm_zx" data-id="concept_cpx_1lm_zx"><title>Spark Evaluator</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/Spark.html#concept_lfl_dvd_1y" data-id="concept_lfl_dvd_1y"><title>Developing the Spark Application</title><topicmeta></topicmeta></topic><topic href="Processors/Spark.html#task_dr2_gvd_1y" data-id="task_dr2_gvd_1y"><title>Installing the Application</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Install the Spark application JAR file as an external library for <span class="ph">Data                   Collector</span>. If         your custom Spark application depends on external libraries other than the         streamsets-datacollector-api, streamsets-datacollector-spark-api, and spark-core libraries,         install those libraries in the same location as well. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/Spark.html#task_g1p_gqn_zx" data-id="task_g1p_gqn_zx"><title>Configuring a Spark Evaluator</title><topicmeta></topicmeta></topic></topic><topic href="Processors/StaticLookup.html#concept_aqz_t4r_pv" data-id="concept_aqz_t4r_pv"><title>Static Lookup</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/StaticLookup.html#task_xk1_z4r_pv" data-id="task_xk1_z4r_pv"><title>Configuring a Static Lookup Processor</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Configure a Static Lookup processor to perform key-value lookups in         memory.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Processors/StreamSelector.html#concept_tqv_t5r_wq" data-id="concept_tqv_t5r_wq"><title>Stream Selector</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/StreamSelector.html#concept_xr4_zt3_3r" data-id="concept_xr4_zt3_3r"><title>Default Stream</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The default stream captures records that do not match user-defined conditions. Use the   default stream to manage unmatched records. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/StreamSelector.html#concept_oy4_tbf_cr" data-id="concept_oy4_tbf_cr"><title>Sample Conditions for Streams</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">A condition defines the data that passes to the associated stream. All records that meet   the condition pass to the stream. Use the expression language to define conditions. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Processors/StreamSelector.html#task_iss_2zx_wq" data-id="task_iss_2zx_wq"><title>Configuring the Stream Selector</title><topicmeta></topicmeta></topic></topic><topic href="Processors/ValueReplacer.html#concept_o5k_dmf_zq" data-id="concept_o5k_dmf_zq"><title>Value Replacer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/ValueReplacer.html#concept_vx3_byr_3x" data-id="concept_vx3_byr_3x"><title>Processing Order</title><topicmeta></topicmeta></topic><topic href="Processors/ValueReplacer.html#concept_ppg_ztk_3y" data-id="concept_ppg_ztk_3y"><title>Replacing Values with Nulls</title><topicmeta></topicmeta></topic><topic href="Processors/ValueReplacer.html#concept_gqv_1sk_3y" data-id="concept_gqv_1sk_3y"><title>Replacing Values with Constants</title><topicmeta></topicmeta><topic href="Processors/ValueReplacer.html#concept_tbv_kbs_3x" data-id="concept_tbv_kbs_3x"><title>Data Types for Conditional Replacement</title><topicmeta></topicmeta></topic></topic><topic href="Processors/ValueReplacer.html#task_ihq_ymf_zq" data-id="task_ihq_ymf_zq"><title>Configuring a Value Replacer</title><topicmeta></topicmeta></topic></topic><topic href="Processors/XMLFlattener.html#concept_ck4_255_sv" data-id="concept_ck4_255_sv"><title>XML Flattener</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/XMLFlattener.html#concept_eqj_vgw_vv" data-id="concept_eqj_vgw_vv"><title>Generated Records</title><topicmeta></topicmeta></topic><topic href="Processors/XMLFlattener.html#task_pmb_l55_sv" data-id="task_pmb_l55_sv"><title>Configuring an XML Flattener</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Configure an XML Flattener to flatten XML data embedded in a string         field.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Processors/XMLParser.html#concept_dtt_q5q_k5" data-id="concept_dtt_q5q_k5"><title>XML Parser</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Processors/XMLParser.html#task_txd_55q_k5" data-id="task_txd_55q_k5"><title>Configuring an XML Parser</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Configure an XML Parser to parse XML data in a string field.</p>
</shortdesc><topicmeta></topicmeta></topic></topic></topic><topic href="Destinations/Destinations-title.html" data-id="concept_agj_cfj_br"><title>Destinations</title><topicmeta></topicmeta><topic href="Destinations/Destinations_overview.html#concept_hpr_twm_jq" data-id="concept_hpr_twm_jq"><title>Destinations</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/AmazonS3.html#concept_avx_bnq_rt" data-id="concept_avx_bnq_rt"><title>Amazon S3</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/AmazonS3.html#concept_bmp_zlg_vw" data-id="concept_bmp_zlg_vw"><title>AWS Credentials</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When <span class="ph">Data                   Collector</span> writes data to an Amazon S3 destination, it must pass credentials to Amazon Web Services. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/AmazonS3.html#concept_lkp_jd3_yv" data-id="concept_lkp_jd3_yv"><title>Object Names</title><topicmeta></topicmeta><topic href="Destinations/AmazonS3.html#concept_iqn_1k4_jx" data-id="concept_iqn_1k4_jx"><title>Names for Whole Files</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/AmazonS3.html#concept_qw5_gtq_yv" data-id="concept_qw5_gtq_yv"><title>Partition Prefix</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can use a partition prefix to organize objects by partitions. You can use the         partition prefix to write to existing partitions or to create new partitions as needed. When         a partition specified in the partition prefix does not exist, Amazon S3 creates the         partition.</p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/AmazonS3.html#concept_qtb_njg_vw" data-id="concept_qtb_njg_vw"><title>Time Basis and Time-Based Partition Prefixes</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The time basis is the time used by the Amazon S3 destination to write records to a         time-based partition prefix. When a partition prefix has no time component, you can ignore         the time basis property.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Destinations/AmazonS3.html#concept_aqq_tt2_px" data-id="concept_aqq_tt2_px"><title>Event Generation</title><topicmeta></topicmeta><topic href="Destinations/AmazonS3.html#concept_nly_sw2_px" data-id="concept_nly_sw2_px"><title>Event Records</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/AmazonS3.html#concept_adm_kn1_mw" data-id="concept_adm_kn1_mw"><title>Server-Side Encryption</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure the destination to use Amazon Web Services server-side encryption         (SSE) to protect data written to Amazon S3. When configured for server-side encryption, the         destination passes required server-side encryption configuration values to Amazon S3. Amazon         S3 uses the values to encrypt the data as it is written to Amazon S3.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/AmazonS3.html#concept_k2z_ncx_rt" data-id="concept_k2z_ncx_rt"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Destinations/AmazonS3.html#task_pxb_j3r_rt" data-id="task_pxb_j3r_rt"><title>Configuring an Amazon S3 Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/DataLakeStore.html#concept_jzm_kf4_zx" data-id="concept_jzm_kf4_zx"><title>Azure Data Lake Store</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/DataLakeStore.html#concept_tsr_ml4_zx" data-id="concept_tsr_ml4_zx"><title>Prerequisites</title><topicmeta></topicmeta><topic href="Destinations/DataLakeStore.html#concept_j2m_jdh_1y" data-id="concept_j2m_jdh_1y"><title>Step 1. Create a <span xmlns="http://www.w3.org/1999/xhtml" class="ph">Data Collector</span> Web Application</title><topicmeta></topicmeta></topic><topic href="Destinations/DataLakeStore.html#concept_xv4_b2h_1y" data-id="concept_xv4_b2h_1y"><title>Step 2. Retrieve Information from Azure </title><topicmeta></topicmeta></topic><topic href="Destinations/DataLakeStore.html#concept_dgz_yfh_1y" data-id="concept_dgz_yfh_1y"><title>Step 3. Grant Execute Permission</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/DataLakeStore.html#concept_gr4_qww_zx" data-id="concept_gr4_qww_zx"><title>Directory Templates</title><topicmeta></topicmeta></topic><topic href="Destinations/DataLakeStore.html#concept_ff4_cxw_zx" data-id="concept_ff4_cxw_zx"><title>Time Basis</title><topicmeta></topicmeta></topic><topic href="Destinations/DataLakeStore.html#concept_wsz_qj4_zx" data-id="concept_wsz_qj4_zx"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Destinations/DataLakeStore.html#task_jfl_nf4_zx" data-id="task_jfl_nf4_zx"><title>Configuring an Azure Data Lake Store Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/Cassandra.html#concept_hfy_mfd_sr" data-id="concept_hfy_mfd_sr"><title>Cassandra</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/Cassandra.html#concept_bdg_bt3_ms" data-id="concept_bdg_bt3_ms"><title>Cassandra Data Types</title><topicmeta></topicmeta></topic><topic href="Destinations/Cassandra.html#task_t1d_z3l_sr" data-id="task_t1d_z3l_sr"><title>Configuring a Cassandra Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/Elasticsearch.html#concept_u5t_vpv_4r" data-id="concept_u5t_vpv_4r"><title>Elasticsearch</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/Elasticsearch.html#concept_dd3_vhk_r5" data-id="concept_dd3_vhk_r5"><title>Time Basis and Time-Based Indexes</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The time basis is the time used by the Elasticsearch destination to write records to         time-based indexes. When indexes have no time component, you can ignore the time basis         property.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/Elasticsearch.html#concept_yr2_1tf_z5" data-id="concept_yr2_1tf_z5"><title>Document IDs</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When appropriate, you can specify an expression that defines the document ID. When you         do not specify an expression, Elasticsearch generates IDs for each document.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/Elasticsearch.html#concept_w2r_ktb_ry" data-id="concept_w2r_ktb_ry"><title>Define the CRUD Operation</title><topicmeta></topicmeta></topic><topic href="Destinations/Elasticsearch.html#task_uns_gtv_4r" data-id="task_uns_gtv_4r"><title>Configuring an Elasticsearch Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/Flume.html#concept_pzn_hl4_yr" data-id="concept_pzn_hl4_yr"><title>Flume</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/Flume.html#concept_dbh_2xp_yr" data-id="concept_dbh_2xp_yr"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Destinations/Flume.html#task_vft_g5p_yr" data-id="task_vft_g5p_yr"><title>Configuring a Flume Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/Bigtable.html#concept_pl5_tmq_tx" data-id="concept_pl5_tmq_tx"><title>Google Bigtable</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/Bigtable.html#concept_f5v_11l_1y" data-id="concept_f5v_11l_1y"><title>Prerequisites</title><topicmeta></topicmeta><topic href="Destinations/Bigtable.html#task_jcl_z1l_1y" data-id="task_jcl_z1l_1y"><title>Install the BoringSSL Library</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The Google Bigtable destination requires the BoringSSL library. You must download and         install the external library so that the Google Bigtable destination can access         it.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/Bigtable.html#concept_n4v_qdl_1y" data-id="concept_n4v_qdl_1y"><title>Configure the Google Application Default Credentials</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Configure the Google Application Default Credentials that the Google Bigtable         destination uses to connect to Google Cloud Bigtable. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Destinations/Bigtable.html#concept_asz_2gl_1y" data-id="concept_asz_2gl_1y"><title>Row Key</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Each Google Cloud Bigtable table has one index, the row key. When you configure the         Google Bigtable destination, you define which field or fields in the record to use as the         row key. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/Bigtable.html#concept_gph_lm4_cy" data-id="concept_gph_lm4_cy"><title>Cloud Bigtable Data Types</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you map record fields to Google Cloud Bigtable columns, you specify whether the         Cloud Bigtable storage type is text or binary. The destination converts the data types of         the record fields to the Cloud Bigtable storage types. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/Bigtable.html#concept_sbp_vz4_1y" data-id="concept_sbp_vz4_1y"><title>Column Family and Field Mappings</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you configure the Google Bigtable destination, you map record fields to Google         Cloud Bigtable columns. You define the Cloud Bigtable columns to write to by defining the         column family and column qualifier.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/Bigtable.html#concept_vwy_334_1y" data-id="concept_vwy_334_1y"><title>Time Basis</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The time basis determines the timestamp value added for each column written to Google         Cloud Bigtable. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/Bigtable.html#task_op4_zmq_tx" data-id="task_op4_zmq_tx"><title>Configuring a Google Bigtable Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/HadoopFS-destination.html#concept_awl_4km_zq" data-id="concept_awl_4km_zq"><title>Hadoop FS</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/HadoopFS-destination.html#concept_cvc_skd_br" data-id="concept_cvc_skd_br"><title>Directory Templates</title><topicmeta></topicmeta></topic><topic href="Destinations/HadoopFS-destination.html#concept_gkz_smd_br" data-id="concept_gkz_smd_br"><title>Time Basis</title><topicmeta></topicmeta></topic><topic href="Destinations/HadoopFS-destination.html#concept_xgm_g4d_br" data-id="concept_xgm_g4d_br"><title>Late Records and Late Record Handling </title><topicmeta></topicmeta></topic><topic href="Destinations/HadoopFS-destination.html#concept_qjs_dw3_tv" data-id="concept_qjs_dw3_tv"><title>Timeout to Close Idle Files</title><topicmeta></topicmeta></topic><topic href="Destinations/HadoopFS-destination.html#concept_uv2_vfb_vy" data-id="concept_uv2_vfb_vy"><title>Recovery</title><topicmeta></topicmeta></topic><topic href="Destinations/HadoopFS-destination.html#concept_lww_3b3_kr" data-id="concept_lww_3b3_kr"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Destinations/HadoopFS-destination.html#concept_n42_z2f_sw" data-id="concept_n42_z2f_sw"><title>Writing to Azure HDInsight</title><topicmeta></topicmeta></topic><topic href="Destinations/HadoopFS-destination.html#concept_bvb_rxj_px" data-id="concept_bvb_rxj_px"><title>Event Generation</title><topicmeta></topicmeta><topic href="Destinations/HadoopFS-destination.html#concept_dmx_1ln_qx" data-id="concept_dmx_1ln_qx"><title>Event Records</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/HadoopFS-destination.html#concept_xy5_4tm_vs" data-id="concept_xy5_4tm_vs"><title>Kerberos Authentication</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can use Kerberos authentication to connect to HDFS. When you use Kerberos     authentication, <span class="ph">Data                   Collector</span> uses the     Kerberos principal and keytab to connect to HDFS. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/HadoopFS-destination.html#concept_u4h_lwt_ls" data-id="concept_u4h_lwt_ls"><title>Using an HDFS User</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure the Hadoop FS destination to use an HDFS user to write data to HDFS. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/HadoopFS-destination.html#concept_xh5_y4d_br" data-id="concept_xh5_y4d_br"><title>HDFS Properties and Configuration Files</title><topicmeta></topicmeta></topic><topic href="Destinations/HadoopFS-destination.html#task_m2m_skm_zq" data-id="task_m2m_skm_zq"><title>Configuring a Hadoop FS Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/HBase.html#concept_wsz_5t5_vr" data-id="concept_wsz_5t5_vr"><title>HBase</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/HBase.html#concept_vn5_cr5_4v" data-id="concept_vn5_cr5_4v"><title>Field Mappings</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you configure the HBase destination, you map fields from records to HBase         columns.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/HBase.html#concept_xy5_4tm_vs" data-id="concept_xy5_4tm_vs"><title>Kerberos Authentication</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can use Kerberos authentication to connect to HBase. When you use Kerberos   authentication, <span class="ph">Data                   Collector</span> uses the   Kerberos principal and keytab to connect to HBase. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/HBase.html#concept_gbt_fpt_ls" data-id="concept_gbt_fpt_ls"><title>Using an HBase User</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure the destination to use an HBase user to write data to HBase. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/HBase.html#concept_t4g_vc2_wv" data-id="concept_t4g_vc2_wv"><title>Time Basis</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The time basis determines the timestamp value added for each column written to HBase. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/HBase.html#concept_tjp_v5l_zq" data-id="concept_tjp_v5l_zq"><title>HDFS Properties and Configuration File</title><topicmeta></topicmeta></topic><topic href="Destinations/HBase.html#task_pyq_qx5_vr" data-id="task_pyq_qx5_vr"><title>Configuring an HBase Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/HiveMetastore.html#concept_gcr_z2t_zv" data-id="concept_gcr_z2t_zv"><title>Hive Metastore</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/HiveMetastore.html#concept_f23_cqy_dw" data-id="concept_f23_cqy_dw"><title>Metadata Processing</title><topicmeta></topicmeta></topic><topic href="Destinations/HiveMetastore.html#concept_wyr_5jv_hw" data-id="concept_wyr_5jv_hw"><title>Hive Table Generation</title><topicmeta></topicmeta></topic><topic href="Destinations/HiveMetastore.html#concept_f4y_spy_dw" data-id="concept_f4y_spy_dw"><title>Cache</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The Hive Metastore destination queries Hive for information and caches the results. When         possible, it uses the cache to avoid unnecessary Hive queries.</p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/HiveMetastore.html#concept_ovn_kdt_dw" data-id="concept_ovn_kdt_dw"><title>Cache Size and Evictions</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure the maximum size of the cache. When the cache reaches the specified         limit, it uses the LRU eviction policy, which removes the least recently used data to allow         for new entries to be written to the cache. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Destinations/HiveMetastore.html#concept_drg_lwc_rx" data-id="concept_drg_lwc_rx"><title>Event Generation</title><topicmeta></topicmeta><topic href="Destinations/HiveMetastore.html#concept_x4p_fyc_rx" data-id="concept_x4p_fyc_rx"><title>Event Records</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/HiveMetastore.html#concept_wsq_dgd_3w" data-id="concept_wsq_dgd_3w"><title>Kerberos Authentication</title><topicmeta></topicmeta></topic><topic href="Destinations/HiveMetastore.html#concept_smb_rdz_dw" data-id="concept_smb_rdz_dw"><title>Hive Properties and Configuration Files</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You must configure Hive Metastore to use Hive and Hadoop configuration files and         individual properties.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/HiveMetastore.html#task_a4n_1ft_zv" data-id="task_a4n_1ft_zv"><title>Configuring a Hive Metastore Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/Hive.html#concept_kvs_3hh_ht" data-id="concept_kvs_3hh_ht"><title>Hive Streaming</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/Hive.html#concept_xh5_y4d_br" data-id="concept_xh5_y4d_br"><title>Hive Properties and Configuration Files</title><topicmeta></topicmeta></topic><topic href="Destinations/Hive.html#task_cx3_lhh_ht" data-id="task_cx3_lhh_ht"><title>Configuring a Hive Streaming Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/InfluxDB.html#concept_inf_db_sr" data-id="concept_inf_db_sr"><title>InfluxDB</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/InfluxDB.html#task_fgx_vcc_fv" data-id="task_fgx_vcc_fv"><title>Configuring an InfluxDB Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/JDBCProducer.html#concept_kvs_3hh_ht" data-id="concept_kvs_3hh_ht"><title>JDBC Producer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/JDBCProducer.html#concept_aq1_lxp_fs" data-id="concept_aq1_lxp_fs"><title>Installing the JDBC Driver</title><topicmeta></topicmeta></topic><topic href="Destinations/JDBCProducer.html#concept_plv_jpn_5y" data-id="concept_plv_jpn_5y"><title>Define the CRUD Operation</title><topicmeta></topicmeta></topic><topic href="Destinations/JDBCProducer.html#task_cx3_lhh_ht" data-id="task_cx3_lhh_ht"><title>Configuring a JDBC Producer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Configure the JDBC Producer to use JDBC to write data to a database         table.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Destinations/KProducer.html#concept_oq2_5jl_zq" data-id="concept_oq2_5jl_zq"><title>Kafka Producer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/KProducer.html#concept_a2p_t4l_zq" data-id="concept_a2p_t4l_zq"><title>Broker List</title><topicmeta></topicmeta></topic><topic href="Destinations/KProducer.html#concept_ok1_cwr_xr" data-id="concept_ok1_cwr_xr"><title>Runtime Topic Resolution</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Kafka Producer can write a record to the topic based on an expression. When Kafka   Producer evaluates a record, it calculates the expression based on record values and writes the   record to the resulting topic. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/KProducer.html#concept_qpm_xp4_4r" data-id="concept_qpm_xp4_4r"><title>Partition Strategy</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The partition strategy determines how to write data to Kafka partitions. You can use a     partition strategy to balance the work load or to write data semantically.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/KProducer.html#concept_wnp_gfc_rw" data-id="concept_wnp_gfc_rw"><title>Additional Kafka Properties</title><topicmeta></topicmeta></topic><topic href="Destinations/KProducer.html#concept_znr_b3c_rw" data-id="concept_znr_b3c_rw"><title>Enabling Security</title><topicmeta></topicmeta><topic href="Destinations/KProducer.html#concept_czm_55c_rw" data-id="concept_czm_55c_rw"><title>Enabling SSL/TLS</title><topicmeta></topicmeta></topic><topic href="Destinations/KProducer.html#concept_vtc_rvc_rw" data-id="concept_vtc_rvc_rw"><title>Enabling Kerberos (SASL)</title><topicmeta></topicmeta></topic><topic href="Destinations/KProducer.html#concept_ksm_svc_rw" data-id="concept_ksm_svc_rw"><title>Enabling SSL/TLS and Kerberos</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/KProducer.html#concept_lww_3b3_kr" data-id="concept_lww_3b3_kr"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Destinations/KProducer.html#task_q4d_4yl_zq" data-id="task_q4d_4yl_zq"><title>Configuring a Kafka Producer</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/KinFirehose.html#concept_bjv_dpk_kv" data-id="concept_bjv_dpk_kv"><title>Kinesis Firehose</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/KinFirehose.html#concept_b14_24g_vw" data-id="concept_b14_24g_vw"><title>AWS Credentials</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When <span class="ph">Data                   Collector</span> writes data to a Kinesis Firehose destination, it must pass credentials to Amazon Web         Services.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/KinFirehose.html#concept_fm4_txq_kv" data-id="concept_fm4_txq_kv"><title>Delivery Stream</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The Kinesis Firehose destination writes data to an existing delivery stream in Amazon         Kinesis Firehose. Before using the Kinesis Firehose destination, use the AWS Management         Console to create a delivery stream to an Amazon S3 bucket or Amazon Redshift         table.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/KinFirehose.html#concept_wrk_rzp_kv" data-id="concept_wrk_rzp_kv"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Destinations/KinFirehose.html#task_rpf_qbq_kv" data-id="task_rpf_qbq_kv"><title>Configuring a Kinesis Firehose Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/KinProducer.html#concept_swk_h1j_yr" data-id="concept_swk_h1j_yr"><title>Kinesis Producer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/KinProducer.html#concept_bpp_54g_vw" data-id="concept_bpp_54g_vw"><title>AWS Credentials</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When <span class="ph">Data                   Collector</span> writes data to a Kinesis Producer destination, it must pass credentials to Amazon Web         Services. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/KinProducer.html#concept_x33_b5c_r5" data-id="concept_x33_b5c_r5"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Destinations/KinProducer.html#task_q2j_ml4_yr" data-id="task_q2j_ml4_yr"><title>Configuring a Kinesis Producer Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/Kudu.html#concept_chy_xxg_4v" data-id="concept_chy_xxg_4v"><title>Kudu </title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/Kudu.html#concept_dvg_vvj_wx" data-id="concept_dvg_vvj_wx"><title>Define the CRUD Operation</title><topicmeta></topicmeta></topic><topic href="Destinations/Kudu.html#task_c4x_tmh_4v" data-id="task_c4x_tmh_4v"><title>Configuring a Kudu Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/LocalFS.html#concept_zvc_bv5_1r" data-id="concept_zvc_bv5_1r"><title>Local FS</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/LocalFS.html#concept_cvc_skd_br" data-id="concept_cvc_skd_br"><title>Directory Templates</title><topicmeta></topicmeta></topic><topic href="Destinations/LocalFS.html#concept_gkz_smd_br" data-id="concept_gkz_smd_br"><title>Time Basis</title><topicmeta></topicmeta></topic><topic href="Destinations/LocalFS.html#concept_xgm_g4d_br" data-id="concept_xgm_g4d_br"><title>Late Records and Late Record Handling </title><topicmeta></topicmeta></topic><topic href="Destinations/LocalFS.html#concept_gp5_wcp_vv" data-id="concept_gp5_wcp_vv"><title>Timeout to Close Idle Files</title><topicmeta></topicmeta></topic><topic href="Destinations/LocalFS.html#concept_s5n_ggc_vy" data-id="concept_s5n_ggc_vy"><title>Recovery</title><topicmeta></topicmeta></topic><topic href="Destinations/LocalFS.html#concept_in1_fcm_px" data-id="concept_in1_fcm_px"><title>Event Generation</title><topicmeta></topicmeta><topic href="Destinations/LocalFS.html#concept_tyc_scc_rx" data-id="concept_tyc_scc_rx"><title>Event Records</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/LocalFS.html#concept_lww_3b3_kr" data-id="concept_lww_3b3_kr"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Destinations/LocalFS.html#task_e33_3v5_1r" data-id="task_e33_3v5_1r"><title>Configuring a Local FS Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/MapRDB.html#concept_vxg_w2z_yv" data-id="concept_vxg_w2z_yv"><title>MapR DB</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/MapRDB.html#concept_tr1_143_1w" data-id="concept_tr1_143_1w"><title>Field Mappings</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you configure the MapR DB destination, you map fields from records to MapR DB         columns.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/MapRDB.html#concept_qxm_hq3_1w" data-id="concept_qxm_hq3_1w"><title>Time Basis</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The time basis determines the timestamp value added for each column written to MapR DB. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/MapRDB.html#concept_fvq_r43_1w" data-id="concept_fvq_r43_1w"><title>Kerberos Authentication</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can use Kerberos authentication to connect to MapR DB. When you use Kerberos         authentication, <span class="ph">Data                   Collector</span> uses         the Kerberos principal and keytab to connect to MapR DB.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/MapRDB.html#concept_hv2_4p3_1w" data-id="concept_hv2_4p3_1w"><title>Using an HBase User</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure the MapR DB destination to use an HBase user to write data to MapR DB. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/MapRDB.html#concept_fth_vq3_1w" data-id="concept_fth_vq3_1w"><title>HDFS Properties and Configuration File</title><topicmeta></topicmeta></topic><topic href="Destinations/MapRDB.html#task_pgk_p2z_yv" data-id="task_pgk_p2z_yv"><title>Configuring a MapR DB Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/MapRDBJSON.html#concept_i4h_2kj_dy" data-id="concept_i4h_2kj_dy"><title>MapR DB JSON</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/MapRDBJSON.html#concept_mrg_nx3_4y" data-id="concept_mrg_nx3_4y"><title>Row Key</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">MapR DB uses a row key to uniquely identify each row in a JSON table. The row key is         defined by the _id field of the JSON document stored in the row.</p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/MapRDBJSON.html#concept_etz_vd3_qy" data-id="concept_etz_vd3_qy"><title>Row Key Data Types</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You configure the MapR DB JSON destination to process row keys as string or binary         data. If necessary, the MapR DB JSON destination converts the data type of the row key field         and then writes the converted value to the _id field in the JSON document.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Destinations/MapRDBJSON.html#task_wq3_wkj_dy" data-id="task_wq3_wkj_dy"><title>Configuring a MapR DB JSON Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/MapRFS.html#concept_spv_xlc_fv" data-id="concept_spv_xlc_fv"><title>MapR FS </title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/MapRFS.html#concept_rwm_yqc_fv" data-id="concept_rwm_yqc_fv"><title>Directory Templates</title><topicmeta></topicmeta></topic><topic href="Destinations/MapRFS.html#concept_zwq_1dj_fv" data-id="concept_zwq_1dj_fv"><title>Time Basis</title><topicmeta></topicmeta></topic><topic href="Destinations/MapRFS.html#concept_xby_tdj_fv" data-id="concept_xby_tdj_fv"><title>Late Records and Late Record Handling</title><topicmeta></topicmeta></topic><topic href="Destinations/MapRFS.html#concept_opt_fdp_vv" data-id="concept_opt_fdp_vv"><title>Timeout to Close Idle Files</title><topicmeta></topicmeta></topic><topic href="Destinations/MapRFS.html#concept_vvr_ngc_vy" data-id="concept_vvr_ngc_vy"><title>Recovery</title><topicmeta></topicmeta></topic><topic href="Destinations/MapRFS.html#concept_bqd_3qb_rx" data-id="concept_bqd_3qb_rx"><title>Event Generation</title><topicmeta></topicmeta><topic href="Destinations/MapRFS.html#concept_z15_qcc_rx" data-id="concept_z15_qcc_rx"><title>Event Records</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/MapRFS.html#concept_yr4_tqc_fv" data-id="concept_yr4_tqc_fv"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Destinations/MapRFS.html#concept_ch4_zpc_fv" data-id="concept_ch4_zpc_fv"><title>Kerberos Authentication</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can use Kerberos authentication to connect to MapR. When you use Kerberos         authentication, the <span class="ph">Data                   Collector</span> uses         the Kerberos principal and keytab to connect to MapR. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/MapRFS.html#concept_kls_lqc_fv" data-id="concept_kls_lqc_fv"><title>Using an HDFS User</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure the MapR FS destination to use an HDFS user to write data to MapR         FS.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/MapRFS.html#concept_ovb_f2j_fv" data-id="concept_ovb_f2j_fv"><title>HDFS Properties and Configuration Files</title><topicmeta></topicmeta></topic><topic href="Destinations/MapRFS.html#task_spl_1fj_fv" data-id="task_spl_1fj_fv"><title>Configuring a MapR FS Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/MapRStreamsProd.html#concept_cfj_qbn_2v" data-id="concept_cfj_qbn_2v"><title>MapR Streams Producer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/MapRStreamsProd.html#concept_izv_vcn_2v" data-id="concept_izv_vcn_2v"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Destinations/MapRStreamsProd.html#concept_bh4_k24_2v" data-id="concept_bh4_k24_2v"><title>Runtime Topic Resolution</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">MapR Streams Producer can write a record to the topic based on an expression. When         MapR Streams Producer evaluates a record, it calculates the expression based on record         values and writes the record to the resulting topic. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/MapRStreamsProd.html#concept_wln_nf4_2v" data-id="concept_wln_nf4_2v"><title>Partition Strategy</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The partition strategy determines how to write data to partitions. You can use a         partition strategy to balance the work load or to write data semantically.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/MapRStreamsProd.html#concept_lzy_xlg_2v" data-id="concept_lzy_xlg_2v"><title>Additional Properties</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can add custom configuration properties to MapR Streams Producer.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/MapRStreamsProd.html#task_tbh_nbn_2v" data-id="task_tbh_nbn_2v"><title>Configuring a MapR Streams Producer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The MapR Streams Producer destination writes messages to MapR Streams.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Destinations/MongoDB.html#concept_eth_k5n_4v" data-id="concept_eth_k5n_4v"><title>MongoDB</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/MongoDB.html#concept_bkc_m24_4v" data-id="concept_bkc_m24_4v"><title>Define the CRUD Operation </title><topicmeta></topicmeta></topic><topic href="Destinations/MongoDB.html#task_d5l_qh2_ww" data-id="task_d5l_qh2_ww"><title>Enabling SSL/TLS</title><topicmeta></topicmeta></topic><topic href="Destinations/MongoDB.html#task_mrc_k5n_4v" data-id="task_mrc_k5n_4v"><title>Configuring a MongoDB Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/RabbitMQ.html#concept_pxj_rvy_dv" data-id="concept_pxj_rvy_dv"><title>RabbitMQ Producer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/RabbitMQ.html#concept_jdx_chy_fv" data-id="concept_jdx_chy_fv"><title>Data Formats</title><topicmeta></topicmeta></topic><topic href="Destinations/RabbitMQ.html#task_rwy_wn5_2v" data-id="task_rwy_wn5_2v"><title>Configuring a RabbitMQ Producer</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/Redis.html#concept_ktc_gw2_gw" data-id="concept_ktc_gw2_gw"><title>Redis</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/Redis.html#concept_ing_cvm_jw" data-id="concept_ing_cvm_jw"><title>Mode</title><topicmeta></topicmeta><topic href="Destinations/Redis.html#concept_ozv_24h_jw" data-id="concept_ozv_24h_jw"><title>Data Types for Batch Mode</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you configure the destination for batch mode, you select the incoming fields to use         as the Redis key and value. You also select the data type of the Redis value. If needed, the         Redis destination converts the <span class="ph">Data                   Collector</span> data         type of the incoming value field to the selected Redis data type. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/Redis.html#concept_xl3_3ql_3w" data-id="concept_xl3_3ql_3w"><title>Data Formats for Publish Mode</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/Redis.html#task_mzk_lw2_gw" data-id="task_mzk_lw2_gw"><title>Configuring a Redis Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/Salesforce.html#concept_rlb_rt3_rx" data-id="concept_rlb_rt3_rx"><title>Salesforce</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/Salesforce.html#task_es3_25d_dy" data-id="task_es3_25d_dy"><title>Changing the API Version</title><topicmeta></topicmeta></topic><topic href="Destinations/Salesforce.html#task_ncv_153_rx" data-id="task_ncv_153_rx"><title>Configuring a Salesforce Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/SDC_RPCdest.html#concept_lfk_hx2_ct" data-id="concept_lfk_hx2_ct"><title>SDC RPC</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/SDC_RPCdest.html#concept_icz_wzw_dt" data-id="concept_icz_wzw_dt"><title>RPC Connections</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">In an SDC RPC destination, the RPC connections define where the destination passes data. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/SDC_RPCdest.html#concept_zdq_rdj_r5" data-id="concept_zdq_rdj_r5"><title>Disabling Compression</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The SDC RPC destination compresses data by default when passing data to an SDC RPC         origin. When necessary, you can disable compression in the destination.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/SDC_RPCdest.html#task_nbl_r2x_dt" data-id="task_nbl_r2x_dt"><title>Configuring an SDC RPC Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/Solr.html#concept_z2g_q1r_wr" data-id="concept_z2g_q1r_wr"><title>Solr</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/Solr.html#concept_z4y_bgr_wr" data-id="concept_z4y_bgr_wr"><title>Index Mode</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The index mode determines how the Solr destination indexes records when writing to Solr.   Index mode also determines how the destination handles errors. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/Solr.html#concept_npl_fss_zw" data-id="concept_npl_fss_zw"><title>Kerberos Authentication</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can use Kerberos authentication to connect to a Solr node or cluster. When you use         Kerberos authentication, <span class="ph">Data                   Collector</span> uses         the Kerberos principal and keytab to connect to Solr. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/Solr.html#task_ld1_phr_wr" data-id="task_ld1_phr_wr"><title>Configuring a Solr Destination</title><topicmeta></topicmeta></topic></topic><topic href="Destinations/ToError.html" data-id="concept_ryn_v3z_lr"><title>To Error </title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/Trash.html#concept_htf_ydj_wq" data-id="concept_htf_ydj_wq"><title>Trash</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/WaveAnalytics.html#concept_hlx_r53_rx" data-id="concept_hlx_r53_rx"><title>Wave Analytics</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Destinations/WaveAnalytics.html#concept_d4h_2lj_tx" data-id="concept_d4h_2lj_tx"><title>Dataflow</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The Wave Analytics destination typically creates multiple datasets, based on the         configured dataset wait time. You can optionally configure the destination to use a Wave         Analytics dataflow to combine multiple datasets together. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Destinations/WaveAnalytics.html#task_mdt_dv3_rx" data-id="task_mdt_dv3_rx"><title>Configuring a Wave Analytics Destination</title><topicmeta></topicmeta></topic></topic></topic><topic href="Executors/Executors-title.html" data-id="concept_umc_1lk_fx"><title>Executors</title><topicmeta></topicmeta><topic href="Executors/Executors-overview.html#concept_stt_2lk_fx" data-id="concept_stt_2lk_fx"><title>Executors</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Executors/HDFSMetadata.html#concept_wgj_slk_fx" data-id="concept_wgj_slk_fx"><title>HDFS File Metadata Executor</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Executors/HDFSMetadata.html#concept_ggb_d1l_rx" data-id="concept_ggb_d1l_rx"><title>Related Event Generating Stages</title><topicmeta></topicmeta></topic><topic href="Executors/HDFSMetadata.html#concept_fmb_rbj_rx" data-id="concept_fmb_rbj_rx"><title>Input File</title><topicmeta></topicmeta></topic><topic href="Executors/HDFSMetadata.html#concept_uwh_vck_rx" data-id="concept_uwh_vck_rx"><title>Changing the File Name or Location</title><topicmeta></topicmeta></topic><topic href="Executors/HDFSMetadata.html#concept_zr1_5ck_rx" data-id="concept_zr1_5ck_rx"><title>Defining the Owner, Group, Permissions, and ACLs</title><topicmeta></topicmeta></topic><topic href="Executors/HDFSMetadata.html#concept_vhl_mfj_rx" data-id="concept_vhl_mfj_rx"><title>Event Generation</title><topicmeta></topicmeta><topic href="Executors/HDFSMetadata.html#concept_omr_3tk_rx" data-id="concept_omr_3tk_rx"><title>Event Records</title><topicmeta></topicmeta></topic></topic><topic href="Executors/HDFSMetadata.html#concept_wjp_3hs_rx" data-id="concept_wjp_3hs_rx"><title>Kerberos Authentication</title><topicmeta></topicmeta></topic><topic href="Executors/HDFSMetadata.html#concept_egg_c3s_rx" data-id="concept_egg_c3s_rx"><title>HDFS Properties and Configuration Files</title><topicmeta></topicmeta></topic><topic href="Executors/HDFSMetadata.html#task_m3v_5lk_fx" data-id="task_m3v_5lk_fx"><title>Configuring an HDFS File Metadata Executor</title><topicmeta></topicmeta></topic></topic><topic href="Executors/HiveQuery.html#concept_kjw_llk_fx" data-id="concept_kjw_llk_fx"><title>Hive Query Executor</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Executors/HiveQuery.html#concept_zld_35h_vx" data-id="concept_zld_35h_vx"><title>Related Event Generating Stages</title><topicmeta></topicmeta></topic><topic href="Executors/HiveQuery.html#concept_jzl_yrr_mx" data-id="concept_jzl_yrr_mx"><title>Hive and Impala Queries</title><topicmeta></topicmeta></topic><topic href="Executors/HiveQuery.html#concept_hqg_nzh_vx" data-id="concept_hqg_nzh_vx"><title>Impala Queries for the Drift Synchronization Solution for Hive</title><topicmeta></topicmeta></topic><topic href="Executors/HiveQuery.html#concept_arl_xx3_my" data-id="concept_arl_xx3_my"><title>Event Generation</title><topicmeta></topicmeta><topic href="Executors/HiveQuery.html#concept_iwg_r2p_my" data-id="concept_iwg_r2p_my"><title>Event Records</title><topicmeta></topicmeta></topic></topic><topic href="Executors/HiveQuery.html#task_mgm_4lk_fx" data-id="task_mgm_4lk_fx"><title>Configuring a Hive Query Executor</title><topicmeta></topicmeta></topic></topic><topic href="Executors/JDBCQuery.html#concept_j3r_gcv_sx" data-id="concept_j3r_gcv_sx"><title>JDBC Query Executor</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Executors/JDBCQuery.html#concept_y32_vt4_tx" data-id="concept_y32_vt4_tx"><title>Installing the JDBC Driver</title><topicmeta></topicmeta></topic><topic href="Executors/JDBCQuery.html#task_ym2_3cv_sx" data-id="task_ym2_3cv_sx"><title>Configuring a JDBC Query Executor</title><topicmeta></topicmeta></topic></topic><topic href="Executors/MapReduce.html#concept_bj2_zlk_fx" data-id="concept_bj2_zlk_fx"><title>MapReduce Executor</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Executors/MapReduce.html#concept_yjr_q1m_zx" data-id="concept_yjr_q1m_zx"><title>Prerequisites</title><topicmeta></topicmeta></topic><topic href="Executors/MapReduce.html#concept_gdt_v5d_nx" data-id="concept_gdt_v5d_nx"><title>Related Event Generating Stages</title><topicmeta></topicmeta></topic><topic href="Executors/MapReduce.html#concept_jqk_g4y_mx" data-id="concept_jqk_g4y_mx"><title>MapReduce Jobs</title><topicmeta></topicmeta><topic href="Executors/MapReduce.html#concept_cnx_hqy_mx" data-id="concept_cnx_hqy_mx"><title>Avro to Parquet Job</title><topicmeta></topicmeta></topic></topic><topic href="Executors/MapReduce.html#concept_e1s_sm5_sx" data-id="concept_e1s_sm5_sx"><title>Event Generation</title><topicmeta></topicmeta><topic href="Executors/MapReduce.html#concept_vjr_cn5_sx" data-id="concept_vjr_cn5_sx"><title>Event Records</title><topicmeta></topicmeta></topic></topic><topic href="Executors/MapReduce.html#concept_kry_p3y_mx" data-id="concept_kry_p3y_mx"><title>Kerberos Authentication</title><topicmeta></topicmeta></topic><topic href="Executors/MapReduce.html#concept_akp_p3m_zx" data-id="concept_akp_p3m_zx"><title>Using a MapReduce User</title><topicmeta></topicmeta></topic><topic href="Executors/MapReduce.html#task_olh_bmk_fx" data-id="task_olh_bmk_fx"><title>Configuring a MapReduce Executor</title><topicmeta></topicmeta></topic></topic></topic><topic href="DPM/DPM_title.html" data-id="concept_ugp_kwf_xw"><title>Dataflow Performance Manager</title><topicmeta></topicmeta><topic href="DPM/DPM.html#concept_l45_qwf_xw" data-id="concept_l45_qwf_xw"><title>Meet Dataflow Performance Manager</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="DPM/DPM.html#concept_knb_cjq_dx" data-id="concept_knb_cjq_dx"><title>Design the Complete Data Architecture</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">As a data architect - the person responsible for defining how data is stored, consumed,         and managed by different systems - you design the complete flow of data through multiple         systems. You might architect the high-level design in a design document or diagram. Then,         you work with your team to develop <span class="ph">Data                   Collector</span>         pipelines that meet those dataflow needs.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/DPM.html#concept_ung_wbs_bx" data-id="concept_ung_wbs_bx"><title>Manage the Pipeline Repository</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">As a data engineer - the person responsible for making sure that data flows smoothly         between systems - you use a development <span class="ph">Data                   Collector</span>         instance to develop the pipelines needed to implement the designed data architecture. When         the pipelines are complete, you publish the pipelines to the pipeline repository in <span class="ph">DPM</span>. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/DPM.html#concept_inh_ccs_bx" data-id="concept_inh_ccs_bx"><title>Manage the Orchestration of Jobs</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">In <span class="ph">DPM</span>,         pipelines are the design of the dataflow. Jobs are the execution of the         dataflow.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/DPM.html#concept_t34_2ds_bx" data-id="concept_t34_2ds_bx"><title>Map Jobs into a Topology</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">In <span class="ph">Data                   Collector</span>, you can monitor and view the details of a single pipeline. However, you typically run         multiple intermediary pipelines, all of which work together to create a complete         dataflow.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/DPM.html#concept_sx5_zds_bx" data-id="concept_sx5_zds_bx"><title>Measure Dataflow Quality</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"><span class="ph">DPM</span>         provides the same level of detailed monitoring for topologies and jobs that you are         accustomed to seeing for pipelines within <span class="ph">Data                   Collector</span>. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/DPM.html#concept_xvp_x2x_fz" data-id="concept_xvp_x2x_fz"><title>Master Dataflow Operations</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">As a DevOps or site reliability engineer, you can master your day-to-day operations by         defining data SLAs (service level agreements) to ensure that incoming data meets business         requirements for availability and accuracy.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="DPM/WorkingWithDPM.html#concept_evb_3bs_bx" data-id="concept_evb_3bs_bx"><title>Working with DPM</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/OrgUserAccount.html#concept_lry_34g_xw" data-id="concept_lry_34g_xw"><title>Request a DPM Organization and User Account</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/RegisterSDCwithDPM.html#concept_kc4_xyf_xw" data-id="concept_kc4_xyf_xw"><title>Register Data Collector with DPM</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="DPM/RegisterSDCwithDPM.html#concept_w11_n1q_rx" data-id="concept_w11_n1q_rx"><title>Registration Prerequisites</title><topicmeta></topicmeta></topic><topic href="DPM/RegisterSDCwithDPM.html#task_a4y_v1g_xw" data-id="task_a4y_v1g_xw"><title>Registering from Data Collector</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can register a <span class="ph">Data                   Collector</span> with             <span class="ph">DPM</span>         from the <span class="ph">Data                   Collector</span> console.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/RegisterSDCwithDPM.html#concept_js4_2z1_cx" data-id="concept_js4_2z1_cx"><title>Registering from the Command Line Interface</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can register a <span class="ph">Data                   Collector</span> with             <span class="ph">DPM</span>         from the <span class="ph">Data                   Collector</span> command line interface. The <span class="ph">Data                   Collector</span> must         be running before you can use the command line interface.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/RegisterSDCwithDPM.html#task_oxx_y5m_xw" data-id="task_oxx_y5m_xw"><title>Registering from Cloudera Manager</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">If you installed <span class="ph">Data                   Collector</span>         through Cloudera Manager, you must use Cloudera Manager to register the <span class="ph">Data                   Collector</span> with             <span class="ph">DPM</span>.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/RegisterSDCwithDPM.html#concept_t2f_m1g_jx" data-id="concept_t2f_m1g_jx"><title>Disconnected Mode</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">After a <span class="ph">Data                   Collector</span> is         registered with <span class="ph">DPM</span>, the             <span class="ph">Data                   Collector</span>         communicates with <span class="ph">DPM</span> at         regular intervals - around every 30 seconds or less. If a <span class="ph">Data                   Collector</span> cannot         connect to <span class="ph">DPM</span>, due to         a network or system outage, then the <span class="ph">Data                   Collector</span> uses         the <span class="ph">DPM</span>         disconnected mode.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/RegisterSDCwithDPM.html#concept_dmr_df5_5y" data-id="concept_dmr_df5_5y"><title>Using an HTTP or HTTPS Proxy Server</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure each registered <span class="ph">Data                   Collector</span> to use         an authenticated HTTP or HTTPS proxy server for outbound requests made to <span class="ph">DPM</span>. Define         the proxy properties in the SDC_JAVA_OPTS environment variable in the <span class="ph">Data                   Collector</span>         environment configuration file. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/RegisterSDCwithDPM.html#concept_a42_stw_2z" data-id="concept_a42_stw_2z"><title>Using a Publicly Accessible URL</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">If you register a <span class="ph">Data                   Collector</span> that         is installed on a cloud-computing platform such as Amazon Elastic Compute Cloud (EC2),         configure the <span class="ph">Data                   Collector</span> to use         a publicly accessible URL.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/RegisterSDCwithDPM.html#concept_xzz_rnr_yy" data-id="concept_xzz_rnr_yy"><title>Transfer Permissions to DPM Users</title><topicmeta></topicmeta></topic></topic><topic href="DPM/AggregatedStatistics.html#concept_h2q_mb5_xw" data-id="concept_h2q_mb5_xw"><title>Aggregated Statistics for Pipelines</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="DPM/AggregatedStatistics.html#concept_c53_pzp_yy" data-id="concept_c53_pzp_yy"><title>Write Statistics to SDC RPC</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you write statistics to SDC RPC, <span class="ph">Data                   Collector</span>         effectively adds an SDC RPC destination to the pipeline that you are configuring. The system         pipeline is a pipeline with a Dev SDC RPC with Buffering origin that reads the statistics         passed from the SDC RPC destination, and then aggregates and sends the statistics to <span class="ph">DPM</span>. </p>
</shortdesc><topicmeta></topicmeta><topic href="DPM/AggregatedStatistics.html#concept_e1d_nzr_yy" data-id="concept_e1d_nzr_yy"><title>Best Practices for SDC RPC</title><topicmeta></topicmeta></topic></topic><topic href="DPM/AggregatedStatistics.html#concept_wmv_cbb_fx" data-id="concept_wmv_cbb_fx"><title>Write Statistics to Kafka</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you write statistics to a Kafka cluster, <span class="ph">Data                   Collector</span>         effectively adds a Kafka Producer destination to the pipeline that you are configuring. The         system pipeline reads the statistics from Kafka, and then aggregates and sends the         statistics to <span class="ph">DPM</span>. </p>
</shortdesc><topicmeta></topicmeta><topic href="DPM/AggregatedStatistics.html#concept_wph_j2b_fx" data-id="concept_wph_j2b_fx"><title>Partition Strategy</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The partition strategy determines how to write statistics to Kafka partitions. You can         use a partition strategy to balance the work load or to write data semantically.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/AggregatedStatistics.html#concept_bmq_ff5_xw" data-id="concept_bmq_ff5_xw"><title>Best Practices for a Kafka Cluster</title><topicmeta></topicmeta></topic></topic><topic href="DPM/AggregatedStatistics.html#concept_em4_2bb_fx" data-id="concept_em4_2bb_fx"><title>Write Statistics to Kinesis Streams</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"> When you write statistics to Amazon Kinesis Streams, <span class="ph">Data                   Collector</span>         effectively adds a Kinesis Producer destination to the pipeline that you are configuring.         The system pipeline reads the statistics from Kinesis Streams, and then aggregates and sends         the statistics to <span class="ph">DPM</span>. </p>
</shortdesc><topicmeta></topicmeta><topic href="DPM/AggregatedStatistics.html#concept_m3j_2kb_fx" data-id="concept_m3j_2kb_fx"><title>AWS Credentials</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When the pipeline writes aggregated statistics to Amazon Kinesis Streams, it must pass         credentials to Amazon Web Services. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/AggregatedStatistics.html#concept_fdy_5f5_xw" data-id="concept_fdy_5f5_xw"><title>Best Practices for Kinesis Streams</title><topicmeta></topicmeta></topic></topic><topic href="DPM/AggregatedStatistics.html#task_lcd_ng5_xw" data-id="task_lcd_ng5_xw"><title>Configuring a Pipeline to Aggregate Statistics</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure a pipeline to aggregate statistics after the Data Collector has         been registered with DPM.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="DPM/PipelineManagement.html#concept_eq5_qjd_fx" data-id="concept_eq5_qjd_fx"><title>Pipeline Management with DPM</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="DPM/PipelineManagement.html#concept_cqr_v3d_fx" data-id="concept_cqr_v3d_fx"><title>Pipeline Types</title><topicmeta></topicmeta><topic href="DPM/PipelineManagement.html#concept_ssy_ns3_hx" data-id="concept_ssy_ns3_hx"><title>Viewing Pipeline Types in Data Collector</title><topicmeta></topicmeta></topic></topic><topic href="DPM/PipelineManagement.html#task_rxy_xqc_fx" data-id="task_rxy_xqc_fx"><title>Publishing Pipelines to DPM</title><topicmeta></topicmeta></topic><topic href="DPM/PipelineManagement.html#task_hjv_fbd_fx" data-id="task_hjv_fbd_fx"><title>Viewing Pipeline Commit History</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can view the commit history of any pipeline that has been published to <span class="ph">DPM</span>. If the         pipeline has been committed multiple times, you can get an older version of the pipeline and         then continue editing the older version.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/PipelineManagement.html#task_ydw_r42_fx" data-id="task_ydw_r42_fx"><title>Downloading Published Pipelines from DPM</title><topicmeta></topicmeta></topic><topic href="DPM/PipelineManagement.html#task_emc_p42_fx" data-id="task_emc_p42_fx"><title>Exporting Pipelines for DPM</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">If you develop pipelines in a <span class="ph">Data                   Collector</span> that         is not registered with <span class="ph">DPM</span>, you         can export the pipelines and then import the pipelines into <span class="ph">DPM</span>. When a             <span class="ph">Data                   Collector</span> is         registered with <span class="ph">DPM</span>, it's         simplest to publish the pipelines directly to <span class="ph">DPM</span>.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="DPM/DPMConfiguration.html#concept_hrn_zz3_fx" data-id="concept_hrn_zz3_fx"><title>DPM Configuration</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/UnregisterSDCwithDPM.html#concept_ldb_sr5_cx" data-id="concept_ldb_sr5_cx"><title>Unregister Data Collector from DPM</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="DPM/UnregisterSDCwithDPM.html#task_iz4_vv5_cx" data-id="task_iz4_vv5_cx"><title>Unregistering from Data Collector</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can unregister a <span class="ph">Data                   Collector</span> from             <span class="ph">DPM</span>         using the <span class="ph">Data                   Collector</span>         console.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="DPM/UnregisterSDCwithDPM.html#concept_r4v_fwf_nx" data-id="concept_r4v_fwf_nx"><title>Unregistering from the Command Line Interface</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can unregister a <span class="ph">Data                   Collector</span> from             <span class="ph">DPM</span>         using the <span class="ph">Data                   Collector</span>         command line interface. </p>
</shortdesc><topicmeta></topicmeta></topic></topic></topic><topic href="Event_Handling/EventFramework-Title.html#concept_xxd_f5r_kx" data-id="concept_xxd_f5r_kx"><title>Event Framework</title><topicmeta></topicmeta><topic href="Event_Handling/EventFramework-Title.html#concept_cph_5h4_lx" data-id="concept_cph_5h4_lx"><title>Event Framework Overview</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Event_Handling/EventFramework-Title.html#concept_zrl_mhn_lx" data-id="concept_zrl_mhn_lx"><title>Event Generation Stages</title><topicmeta></topicmeta></topic><topic href="Event_Handling/EventFramework-Title.html#concept_rxg_shn_lx" data-id="concept_rxg_shn_lx"><title>Executors</title><topicmeta></topicmeta></topic><topic href="Event_Handling/EventFramework-Title.html#concept_scs_3hh_tx" data-id="concept_scs_3hh_tx"><title>Logical Pairings</title><topicmeta></topicmeta></topic></topic><topic href="Event_Handling/EventFramework-Title.html#concept_sjr_nrx_4x" data-id="concept_sjr_nrx_4x"><title>Event Streams</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Event_Handling/EventFramework-Title.html#concept_ivh_xy2_zx" data-id="concept_ivh_xy2_zx"><title>Task Execution Streams</title><topicmeta></topicmeta></topic><topic href="Event_Handling/EventFramework-Title.html#concept_bfd_31f_zx" data-id="concept_bfd_31f_zx"><title>Event Storage Streams</title><topicmeta></topicmeta></topic></topic><topic href="Event_Handling/EventFramework-Title.html#concept_gvh_5wm_xx" data-id="concept_gvh_5wm_xx"><title>Event Records</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Event_Handling/EventFramework-Title.html#concept_zft_rdq_tx" data-id="concept_zft_rdq_tx"><title>Event Record Header Attributes</title><topicmeta></topicmeta></topic></topic><topic href="Event_Handling/EventFramework-Title.html#concept_jkm_rnz_kx" data-id="concept_jkm_rnz_kx"><title>Case Study: Parquet Conversion</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Event_Handling/EventFramework-Title.html#concept_szz_xwm_lx" data-id="concept_szz_xwm_lx"><title>Case Study: Impala Metadata Updates for DDS for Hive</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Event_Handling/EventFramework-Title.html#concept_d1q_xl4_lx" data-id="concept_d1q_xl4_lx"><title>Case Study: Output File Management</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Event_Handling/EventFramework-Title.html#concept_ocb_nnl_px" data-id="concept_ocb_nnl_px"><title>Case Study: Event Storage </title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Event_Handling/EventFramework-Title.html#concept_awx_xlq_cy" data-id="concept_awx_xlq_cy"><title>Event Records in Data Preview, Monitor, and Snapshot</title><topicmeta></topicmeta><topic href="Event_Handling/EventFramework-Title.html#concept_hfy_ryv_cy" data-id="concept_hfy_ryv_cy"><title>Event Records in Data Preview and Snapshot</title><topicmeta></topicmeta></topic><topic href="Event_Handling/EventFramework-Title.html#concept_zwr_kzv_cy" data-id="concept_zwr_kzv_cy"><title>Event Records in Monitor Mode</title><topicmeta></topicmeta></topic></topic><topic href="Event_Handling/EventFramework-Title.html#concept_azz_tq4_lx" data-id="concept_azz_tq4_lx"><title>Event Framework Summary</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Hive_Drift_Solution/HiveDriftSolution_title.html#concept_fjj_zcf_2w" data-id="concept_fjj_zcf_2w"><title>Drift Synchronization Solution (a.k.a. Hive Drift Solution)</title><topicmeta></topicmeta><topic href="Hive_Drift_Solution/HiveDriftSolution_title.html#concept_phk_bdf_2w" data-id="concept_phk_bdf_2w"><title>Drift Synchronization Solution for Hive</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Hive_Drift_Solution/HiveDriftSolution_title.html#concept_u2t_fgy_1x" data-id="concept_u2t_fgy_1x"><title>Impala Support</title><topicmeta></topicmeta></topic><topic href="Hive_Drift_Solution/HiveDriftSolution_title.html#concept_s3v_21p_hx" data-id="concept_s3v_21p_hx"><title>Flatten Records</title><topicmeta></topicmeta></topic></topic><topic href="Hive_Drift_Solution/HiveDriftSolution_title.html#concept_zzs_fkg_2w" data-id="concept_zzs_fkg_2w"><title>Basic Implementation</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Hive_Drift_Solution/HiveDriftSolution_title.html#concept_y5w_dj3_fw" data-id="concept_y5w_dj3_fw"><title>Implementation Steps</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Hive_Drift_Solution/HiveDriftSolution_title.html#concept_a1w_kkn_fw" data-id="concept_a1w_kkn_fw"><title>Case Study</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Hive_Drift_Solution/HiveDriftSolution_title.html#concept_fzk_mmn_fw" data-id="concept_fzk_mmn_fw"><title>The Hive Metadata Processor</title><topicmeta></topicmeta></topic><topic href="Hive_Drift_Solution/HiveDriftSolution_title.html#concept_vh3_s4n_fw" data-id="concept_vh3_s4n_fw"><title>The Hive Metastore Destination</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Now to process the metadata records - and to create and update tables in Hive - you need         the Hive Metastore destination.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Hive_Drift_Solution/HiveDriftSolution_title.html#concept_jzr_ypn_fw" data-id="concept_jzr_ypn_fw"><title>The Hadoop FS Destination</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The Hadoop FS destination can write data to HDFS using record header attributes. If you         wanted, you could use the MapR FS destination to write to MapR FS instead. Record header         attributes contain the write details that the Hive Metadata processor generates and adds to         records. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Hive_Drift_Solution/HiveDriftSolution_title.html#concept_jlr_zlk_gw" data-id="concept_jlr_zlk_gw"><title>Processing Data</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Now what happens when you start the pipeline?</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Hive_Drift_Solution/HiveDriftSolution_title.html#concept_ry2_qkm_hw" data-id="concept_ry2_qkm_hw"><title>Hive Data Types</title><topicmeta></topicmeta></topic></topic><topic href="Multithreaded_Pipelines/MultithreadedPipelines.html#concept_wwq_gxc_py" data-id="concept_wwq_gxc_py"><title>Multithreaded Pipelines</title><topicmeta></topicmeta><topic href="Multithreaded_Pipelines/MultithreadedPipelines.html#concept_zpp_2xc_py" data-id="concept_zpp_2xc_py"><title>Multithreaded Pipeline Overview</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Multithreaded_Pipelines/MultithreadedPipelines.html#concept_xl3_ncd_py" data-id="concept_xl3_ncd_py"><title>How It Works</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Multithreaded_Pipelines/MultithreadedPipelines.html#concept_wcz_tpd_py" data-id="concept_wcz_tpd_py"><title>Origins for Multithreaded Pipelines</title><topicmeta></topicmeta></topic><topic href="Multithreaded_Pipelines/MultithreadedPipelines.html#concept_np1_pkz_ry" data-id="concept_np1_pkz_ry"><title>Processor Caching</title><topicmeta></topicmeta></topic><topic href="Multithreaded_Pipelines/MultithreadedPipelines.html#concept_tdn_vwy_ry" data-id="concept_tdn_vwy_ry"><title>Monitoring</title><topicmeta></topicmeta></topic></topic><topic href="Multithreaded_Pipelines/MultithreadedPipelines.html#concept_z25_ltd_ry" data-id="concept_z25_ltd_ry"><title>Resource Usage</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Multithreaded_Pipelines/MultithreadedPipelines.html#concept_sfp_1nd_py" data-id="concept_sfp_1nd_py"><title>Multithreaded Pipeline Summary</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="RPC_Pipelines/SDC_RPCpipelines_title.html#concept_wr1_ktz_bt" data-id="concept_wr1_ktz_bt"><title>SDC RPC Pipelines</title><topicmeta></topicmeta><topic href="RPC_Pipelines/SDC_RPCpipelines_title.html#concept_lnh_z3z_bt" data-id="concept_lnh_z3z_bt"><title>SDC RPC Pipeline Overview</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="RPC_Pipelines/SDC_RPCpipelines_title.html#concept_vmj_3ff_ct" data-id="concept_vmj_3ff_ct"><title>Pipeline Types</title><topicmeta></topicmeta></topic></topic><topic href="RPC_Pipelines/SDC_RPCpipelines_title.html#concept_a4w_5tf_ct" data-id="concept_a4w_5tf_ct"><title>Deployment Architecture</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="RPC_Pipelines/SDC_RPCpipelines_title.html#concept_drd_wqb_dt" data-id="concept_drd_wqb_dt"><title>Configuring the Delivery Guarantee</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="RPC_Pipelines/SDC_RPCpipelines_title.html#concept_dgf_kkc_dt" data-id="concept_dgf_kkc_dt"><title>Defining the RPC ID</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="RPC_Pipelines/SDC_RPCpipelines_title.html#concept_mrm_qhf_2t" data-id="concept_mrm_qhf_2t"><title>Enabling Encryption</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="RPC_Pipelines/SDC_RPCpipelines_title.html#concept_mhl_1jc_dt" data-id="concept_mhl_1jc_dt"><title>Configuration Guidelines for SDC RPC Pipelines</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Cluster_Mode/ClusterPipelines_title.html#concept_fpz_5r4_vs" data-id="concept_fpz_5r4_vs"><title>Cluster Pipelines</title><topicmeta></topicmeta><topic href="Cluster_Mode/ClusterPipelines_title.html#concept_hmh_kfn_1s" data-id="concept_hmh_kfn_1s"><title>Cluster Pipeline Overview</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Cluster_Mode/ClusterPipelines_title.html#concept_rjc_4m5_lx" data-id="concept_rjc_4m5_lx"><title>Cluster Batch and Streaming Execution Modes</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"><span class="ph">Data                   Collector</span>         can run a cluster pipeline using the cluster batch or the cluster streaming execution         mode.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Cluster_Mode/ClusterPipelines_title.html#concept_rmd_hgp_cw" data-id="concept_rmd_hgp_cw"><title>HTTP Protocols</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure Data Collector to use HTTP or HTTPS when you run cluster pipelines. By         default Data Collector uses HTTP.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Cluster_Mode/ClusterPipelines_title.html#concept_cs4_lcg_j5" data-id="concept_cs4_lcg_j5"><title>Checkpoint Storage for Streaming Pipelines</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When the <span class="ph">Data                   Collector</span> runs a         cluster streaming pipeline, on either Mesos or YARN, the <span class="ph">Data                   Collector</span>         generates and stores checkpoint metadata. The checkpoint metadata provides the offset for         the origin.</p>
</shortdesc><topicmeta></topicmeta><topic href="Cluster_Mode/ClusterPipelines_title.html#task_gxz_h1q_k5" data-id="task_gxz_h1q_k5"><title>Configuring the Location for Mesos</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you run a cluster pipeline on Mesos, the <span class="ph">Data                   Collector</span> can         write checkpoint information to either HDFS or Amazon S3. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Cluster_Mode/ClusterPipelines_title.html#concept_xxz_nft_ls" data-id="concept_xxz_nft_ls"><title>Error Handling Limitations</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Cluster_Mode/ClusterPipelines_title.html#concept_fk4_gd4_1s" data-id="concept_fk4_gd4_1s"><title>Monitoring and Snapshot</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Cluster_Mode/ClusterPipelines_title.html#task_gmd_msw_yr" data-id="task_gmd_msw_yr"><title>Kafka Requirements</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Cluster_Mode/ClusterPipelines_title.html#task_hhk_bfv_cy" data-id="task_hhk_bfv_cy"><title>Configuring Cluster YARN Streaming for Kafka</title><topicmeta></topicmeta></topic><topic href="Cluster_Mode/ClusterPipelines_title.html#task_kf1_fgv_cy" data-id="task_kf1_fgv_cy"><title>Configuring Cluster Mesos Streaming for Kafka</title><topicmeta></topicmeta></topic></topic><topic href="Cluster_Mode/ClusterPipelines_title.html#concept_kry_gn5_lx" data-id="concept_kry_gn5_lx"><title>MapR Requirements</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Cluster_Mode/ClusterPipelines_title.html#task_n2l_z45_lx" data-id="task_n2l_z45_lx"><title>Configuring Cluster Batch Mode for MapR</title><topicmeta></topicmeta></topic><topic href="Cluster_Mode/ClusterPipelines_title.html#task_i3h_q3w_hx" data-id="task_i3h_q3w_hx"><title>Configuring Cluster Streaming Mode for MapR</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Complete the following steps to configure a cluster pipeline to read from MapR in         cluster streaming mode.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Cluster_Mode/ClusterPipelines_title.html#task_akz_w5b_ws" data-id="task_akz_w5b_ws"><title>HDFS Requirements</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Data_Preview/DataPreview_Title.html#concept_jjk_23z_sq" data-id="concept_jjk_23z_sq"><title>Data Preview</title><topicmeta></topicmeta><topic href="Data_Preview/DataPreview_Title.html#concept_jtn_s3m_lq" data-id="concept_jtn_s3m_lq"><title>Data Preview Overview</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Data_Preview/DataPreview_Title.html#concept_ksb_hjj_br" data-id="concept_ksb_hjj_br"><title>Data Preview Availability</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can preview complete and incomplete pipelines. The Data Preview icon becomes active   when data preview is available.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Data_Preview/DataPreview_Title.html#concept_rry_fkc_pr" data-id="concept_rry_fkc_pr"><title>Source Data for Data Preview</title><topicmeta></topicmeta></topic><topic href="Data_Preview/DataPreview_Title.html#concept_zjn_3tr_xr" data-id="concept_zjn_3tr_xr"><title>Writing to Destinations</title><topicmeta></topicmeta></topic><topic href="Data_Preview/DataPreview_Title.html#concept_sg4_bfm_zw" data-id="concept_sg4_bfm_zw"><title>Notes</title><topicmeta></topicmeta></topic></topic><topic href="Data_Preview/DataPreview_Title.html#concept_l4q_pbl_sq" data-id="concept_l4q_pbl_sq"><title>Data Collector Console - Preview Mode</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Data_Preview/DataPreview_Title.html#concept_qqc_s3h_tq" data-id="concept_qqc_s3h_tq"><title>Preview Codes</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">In preview mode, the <span class="ph">Data                   Collector</span> console uses   different colors to represent different types of data. The console uses other codes and formatting   to highlight changed fields.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Data_Preview/DataPreview_Title.html#task_cxd_p25_qq" data-id="task_cxd_p25_qq"><title>Previewing a Single Stage</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Data_Preview/DataPreview_Title.html#task_svd_dvz_sq" data-id="task_svd_dvz_sq"><title>Previewing Multiple Stages</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Data_Preview/DataPreview_Title.html#task_nyy_13l_5s" data-id="task_nyy_13l_5s"><title>Editing Preview Data</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Data_Preview/DataPreview_Title.html#task_dyy_k3l_5s" data-id="task_dyy_k3l_5s"><title>Editing Properties</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Alerts/RulesAlerts_title.html#concept_pgk_brx_rr" data-id="concept_pgk_brx_rr"><title>Rules and Alerts</title><topicmeta></topicmeta><topic href="Alerts/RulesAlerts_title.html#concept_ugl_nlh_q5" data-id="concept_ugl_nlh_q5"><title>Rules and Alerts Overview</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Alerts/RulesAlerts_title.html#concept_abj_nsk_zq" data-id="concept_abj_nsk_zq"><title>Metric Rules and Alerts</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Alerts/RulesAlerts_title.html#concept_aq1_5lf_qv" data-id="concept_aq1_5lf_qv"><title>Default Metric Rules</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"><span class="ph">Data                   Collector</span>         provides a set of default metric rules that you can edit and enable for any         pipeline.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Alerts/RulesAlerts_title.html#concept_y4d_tcw_1r" data-id="concept_y4d_tcw_1r"><title>Metric Types</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can use different metric types when you create a metric rule. The metric type         determines which statistic triggers the alert. </p>
</shortdesc><topicmeta></topicmeta><topic href="Alerts/RulesAlerts_title.html#concept_ky2_g4f_qv" data-id="concept_ky2_g4f_qv"><title>Gauge</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The gauge metric type provides alerts based on the number of input, output, or error         records for the last processed batch. It also provides alerts on the age of the current         batch, the amount of time a stage takes to process a batch, or the time that <span class="ph">Data                   Collector</span> last         received a record from the origin.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Alerts/RulesAlerts_title.html#concept_ov2_vvf_qv" data-id="concept_ov2_vvf_qv"><title>Counter</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The counter metric type provides alerts based on the number of input, output, or error         records for the pipeline or for a stage in the pipeline.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Alerts/RulesAlerts_title.html#concept_e3p_pxf_qv" data-id="concept_e3p_pxf_qv"><title>Histogram</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The histogram metric type provides alerts based on a histogram of different record types         and stage errors for the pipeline or for a stage in the pipeline.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Alerts/RulesAlerts_title.html#concept_d3x_d2g_qv" data-id="concept_d3x_d2g_qv"><title>Meter</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The meter metric type provides alerts based on rates of different record types and stage         errors for pipelines or for a stage in the pipeline. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Alerts/RulesAlerts_title.html#concept_j5r_xhg_qv" data-id="concept_j5r_xhg_qv"><title>Timer</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The timer metric type provides alerts based on batch processing timers for the pipeline         or for a stage in the pipeline.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Alerts/RulesAlerts_title.html#concept_qyv_1tf_qv" data-id="concept_qyv_1tf_qv"><title>Metric Conditions</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you configure a metric rule, you configure the condition that defines the threshold         at which the metric rule triggers an alert. Use the expression language to configure the         condition. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Alerts/RulesAlerts_title.html#task_hcf_11k_br" data-id="task_hcf_11k_br"><title>Configuring a Metric Rule and Alert</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Create a custom metric rule to receive alerts when a real-time statistic reaches a         certain threshold. You can create metric rules and alerts when you configure or monitor a         pipeline. You can edit or delete metric rules when they are not enabled. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Alerts/RulesAlerts_title.html#concept_tpm_rsk_zq" data-id="concept_tpm_rsk_zq"><title>Data Rules and Alerts</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Alerts/RulesAlerts_title.html#task_utt_p2k_br" data-id="task_utt_p2k_br"><title>Configuring a Data Rule and Alert</title><topicmeta></topicmeta></topic><topic href="Alerts/RulesAlerts_title.html#task_sx1_4qv_q5" data-id="task_sx1_4qv_q5"><title>Viewing Data Rule Metrics and Sample Data</title><topicmeta></topicmeta></topic></topic><topic href="Alerts/RulesAlerts_title.html#concept_wbz_mkk_p5" data-id="concept_wbz_mkk_p5"><title>Data Drift Rules and Alerts</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Alerts/RulesAlerts_title.html#concept_rj4_y4g_q5" data-id="concept_rj4_y4g_q5"><title>Data Drift Alert Triggers</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Data drift alerts trigger when a change of the specified type occurs from record to         record. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Alerts/RulesAlerts_title.html#task_dyk_ptm_q5" data-id="task_dyk_ptm_q5"><title>Configuring Data Drift Rules and Alerts</title><topicmeta></topicmeta></topic></topic><topic href="Alerts/RulesAlerts_title.html#task_f3v_1hw_1r" data-id="task_f3v_1hw_1r"><title>Configuring Email for Alerts</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Monitoring/PipelineMonitoring_title.html#concept_asx_fdz_sq" data-id="concept_asx_fdz_sq"><title>Pipeline Monitoring</title><topicmeta></topicmeta><topic href="Pipeline_Monitoring/PipelineMonitoring_title.html#concept_hsp_tnt_lq" data-id="concept_hsp_tnt_lq"><title>Pipeline Monitoring Overview</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Monitoring/PipelineMonitoring_title.html#concept_t1c_mf4_tq" data-id="concept_t1c_mf4_tq"><title>Data Collector Console - Monitor Mode</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Monitoring/PipelineMonitoring_title.html#task_pkh_j23_tq" data-id="task_pkh_j23_tq"><title>Viewing Pipeline and Stage Statistics</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Monitoring/PipelineMonitoring_title.html#concept_pd3_crv_yr" data-id="concept_pd3_crv_yr"><title>Monitoring Errors</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Pipeline_Monitoring/PipelineMonitoring_title.html#concept_aw5_zss_zr" data-id="concept_aw5_zss_zr"><title>Stage-Related Errors</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can view the errors related to each stage. Stage-related errors include the error   records that the stage produces and other errors encountered by the stage.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Monitoring/PipelineMonitoring_title.html#concept_tyr_2zx_rr" data-id="concept_tyr_2zx_rr"><title>Snapshots</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Pipeline_Monitoring/PipelineMonitoring_title.html#task_wvz_rfp_tq" data-id="task_wvz_rfp_tq"><title>Capturing and Viewing a Snapshot</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Monitoring/PipelineMonitoring_title.html#task_p12_gbw_rr" data-id="task_p12_gbw_rr"><title>Viewing the Run History</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Pipeline_Monitoring/PipelineMonitoring_title.html#task_cj2_xbw_rr" data-id="task_cj2_xbw_rr"><title>Viewing a Run Summary</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can view a run summary for each run of the pipeline when you view the pipeline         history. </p>
</shortdesc><topicmeta></topicmeta></topic></topic></topic><topic href="Pipeline_Maintenance/PipelineMaintenance_title.html#concept_o3l_dtr_5q" data-id="concept_o3l_dtr_5q"><title>Pipeline Maintenance</title><topicmeta></topicmeta><topic href="Pipeline_Maintenance/PipelineMaintenance_title.html#concept_wc5_ysp_1w" data-id="concept_wc5_ysp_1w"><title>Data Collector Console - All Pipelines on the Home Page</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Maintenance/PipelineMaintenance_title.html#task_wpy_1xr_5q" data-id="task_wpy_1xr_5q"><title>Starting Pipelines</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Pipeline_Maintenance/PipelineMaintenance_title.html#task_hdg_j1s_5q" data-id="task_hdg_j1s_5q"><title>Resetting the Origin</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">You can reset the origin when you want the <span class="ph">Data                   Collector</span> to         process all available data instead of processing data from the last-saved offset. Reset the         origin when the pipeline is not running. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Maintenance/PipelineMaintenance_title.html#task_ylb_f1s_5q" data-id="task_ylb_f1s_5q"><title>Stopping Pipelines</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Maintenance/PipelineMaintenance_title.html#task_fdf_hrr_5q" data-id="task_fdf_hrr_5q"><title>Importing Pipelines</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Maintenance/PipelineMaintenance_title.html#concept_jrg_1vy_wy" data-id="concept_jrg_1vy_wy"><title>Sharing Pipelines</title><topicmeta></topicmeta><topic href="Pipeline_Maintenance/PipelineMaintenance_title.html#task_elc_qn1_xy" data-id="task_elc_qn1_xy"><title>Sharing a Pipeline</title><topicmeta></topicmeta></topic><topic href="Pipeline_Maintenance/PipelineMaintenance_title.html#task_mz1_rn1_xy" data-id="task_mz1_rn1_xy"><title>Changing the Pipeline Owner</title><topicmeta></topicmeta></topic></topic><topic href="Pipeline_Maintenance/PipelineMaintenance_title.html#concept_obz_cml_wx" data-id="concept_obz_cml_wx"><title>Adding Labels to Pipelines</title><topicmeta></topicmeta></topic><topic href="Pipeline_Maintenance/PipelineMaintenance_title.html#task_dtz_4tr_5q" data-id="task_dtz_4tr_5q"><title>Exporting Pipelines</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Maintenance/PipelineMaintenance_title.html#task_nhf_bvr_5q" data-id="task_nhf_bvr_5q"><title>Duplicating a Pipeline</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Pipeline_Maintenance/PipelineMaintenance_title.html#task_a35_pwr_5q" data-id="task_a35_pwr_5q"><title>Deleting Pipelines</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Administration/Administration_title.html#concept_yms_ftm_sq" data-id="concept_yms_ftm_sq"><title>Administration</title><topicmeta></topicmeta><topic href="Administration/Administration_title.html#task_jyk_vgk_br" data-id="task_jyk_vgk_br"><title>Viewing Data Collector Configuration Properties</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Administration/Administration_title.html#concept_gwn_wf4_yr" data-id="concept_gwn_wf4_yr"><title>Viewing Data Collector Directories</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Administration/Administration_title.html#task_wvx_4hk_br" data-id="task_wvx_4hk_br"><title>Viewing JVM Metrics</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Administration/Administration_title.html#task_gbm_s3k_br" data-id="task_gbm_s3k_br"><title>Viewing Data Collector Logs</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Administration/Administration_title.html#task_lkv_g2f_wy" data-id="task_lkv_g2f_wy"><title>Modifying the Log Level</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">If the <span class="ph">Data                   Collector</span> logs         do not provide enough troubleshooting information, you can modify the log level to display         messages at another severity level. </p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Administration/Administration_title.html#task_uvg_bjk_br" data-id="task_uvg_bjk_br"><title>Shutting Down Data Collector</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Administration/Administration_title.html#task_pjr_5h4_4v" data-id="task_pjr_5h4_4v"><title>Restarting Data Collector</title><topicmeta></topicmeta></topic><topic href="Administration/Administration_title.html#concept_lxg_qlr_my" data-id="concept_lxg_qlr_my"><title>Viewing Users and Groups</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">If you use file-based authentication, you can view all user accounts granted access to         this <span class="ph">Data                   Collector</span>         instance, including the roles and groups assigned to each user.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Administration/Administration_title.html#concept_dlh_p15_2r" data-id="concept_dlh_p15_2r"><title>REST Response</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Administration/Administration_title.html#task_cyb_rpw_wr" data-id="task_cyb_rpw_wr"><title>Viewing REST Response Data</title><topicmeta></topicmeta></topic><topic href="Administration/Administration_title.html#task_ywb_qrt_xt" data-id="task_ywb_qrt_xt"><title>Disabling the REST Response Menu</title><topicmeta></topicmeta></topic></topic><topic href="Administration/Administration_title.html#concept_ywx_d5x_pt" data-id="concept_ywx_d5x_pt"><title>Command Line Interface</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Administration/Administration_title.html#concept_zrc_qch_xw" data-id="concept_zrc_qch_xw"><title>Java Configuration Options for the Cli Command</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Use the SDC_CLI_JAVA_OPTS environment variable to modify Java configuration options for         the <samp class="ph codeph">cli</samp> command.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Administration/Administration_title.html#concept_kpw_mdt_qt" data-id="concept_kpw_mdt_qt"><title>Using the Cli Command</title><topicmeta></topicmeta></topic><topic href="Administration/Administration_title.html#concept_okz_qdq_yt" data-id="concept_okz_qdq_yt"><title>Help Command</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Use the help command to view additional information for the specified         command.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Administration/Administration_title.html#concept_msh_k2q_yt" data-id="concept_msh_k2q_yt"><title>Manager Command</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The <samp class="ph codeph">manager</samp> command provides arguments to start and stop a pipeline,         view the status of all pipelines, and reset the origin for a pipeline.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Administration/Administration_title.html#concept_xc2_vyw_yt" data-id="concept_xc2_vyw_yt"><title>Store Command</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The <samp class="ph codeph">store</samp> command provides arguments to view a list of all pipelines         and to import a pipeline. </p>
</shortdesc><topicmeta></topicmeta></topic></topic></topic><topic href="Tutorial/Tutorial-title.html" data-id="concept_nls_w1r_ks"><title>Tutorial</title><topicmeta></topicmeta><topic href="Tutorial/Overview.html" data-id="concept_is5_lrq_ks"><title>Tutorial Overview</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Tutorial/BeforeYouBegin.html#concept_hg5_j2p_ms" data-id="concept_hg5_j2p_ms"><title>Before You Begin</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Tutorial/BasicTutorial.html#concept_phf_cjt_ls" data-id="concept_phf_cjt_ls"><title>Basic Tutorial</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Tutorial/BasicTutorial.html#task_jmz_3dn_ls" data-id="task_jmz_3dn_ls"><title>Create a Pipeline and Define Pipeline Properties</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">When you configure a pipeline, you need to decide what to do with error records. You         can discard them or - more productively - write them to file, another pipeline, or to Kafka. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Tutorial/BasicTutorial.html#task_ftt_2vq_ks" data-id="task_ftt_2vq_ks"><title>Configure the Origin</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The origin represents the incoming data for the pipeline. When you configure the         origin, you define how to connect to the origin system, the type of data to be processed,         and other properties specific to the origin.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Tutorial/BasicTutorial.html#task_xb5_2sf_4s" data-id="task_xb5_2sf_4s"><title>Preview Data </title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">To become more familiar with the data set and gather some important details for         pipeline configuration, let's preview the source data.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Tutorial/BasicTutorial.html#task_br5_rzq_ks" data-id="task_br5_rzq_ks"><title>Route Data with the Stream Selector</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">To route data to different streams for processing, we use the Stream Selector         processor.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Tutorial/BasicTutorial.html#task_cdx_kfm_ls" data-id="task_cdx_kfm_ls"><title>Use Jython for Card Typing</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"> Next, we'll evaluate credit card numbers to determine the credit card type. You can         use an Expression Evaluator to do the same calculations, but with a short script, the Jython         Evaluator is easier.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Tutorial/BasicTutorial.html#task_qbw_d3m_ls" data-id="task_qbw_d3m_ls"><title>Mask Credit Card Numbers</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"> Now let's prevent sensitive information from reaching internal databases by using a         Field Masker to mask the credit card numbers. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Tutorial/BasicTutorial.html#task_wsj_5tm_ls" data-id="task_wsj_5tm_ls"><title>Write to the Destination</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The <span class="ph">Data                   Collector</span> can         write data to many destinations. The Hadoop FS destination writes to HDFS or a local         directory. For the tutorial, we'll use it to write to a local directory.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Tutorial/BasicTutorial.html#task_wgb_t4p_ms" data-id="task_wgb_t4p_ms"><title>Add a Corresponding Field with the Expression Evaluator</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The Jython Evaluator script added a new field to the credit payments branch. To         ensure all records have the same structure, we'll use the Expression Evaluator to add the         same field to the non-credit branch. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Tutorial/BasicTutorial.html#task_ets_dkj_ps" data-id="task_ets_dkj_ps"><title>Create a Data Rule and Alert</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Now before we run the basic pipeline, let's add a data rule and alert. Data rules are         user-defined rules used to inspect data moving between two stages. They are a powerful way         to look for outliers and anomalous data. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Tutorial/BasicTutorial.html#task_m21_dyj_ps" data-id="task_m21_dyj_ps"><title>Run the Basic Pipeline</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Now that the basic pipeline is complete, you can start it by clicking the             <span class="ph uicontrol">Start</span> icon: <img class="image" src="Graphics/icon_ConfigStartPipeline.png" height="NaN" width="NaN" />.</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Tutorial/ExtendedTutorial.html#concept_w4n_gjt_ls" data-id="concept_w4n_gjt_ls"><title>Extended Tutorial</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Tutorial/ExtendedTutorial.html#task_kxl_tvk_ps" data-id="task_kxl_tvk_ps"><title>Convert Types with a Field Type Converter</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Since the sample data is read from a file, the fields are all String. Let's use a         Field Type Converter to convert some data types.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Tutorial/ExtendedTutorial.html#task_rlk_tdq_ps" data-id="task_rlk_tdq_ps"><title>Manipulate Data with the Expression Evaluator</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Now we'll use an Expression Evaluator to create pickup and dropoff location fields         that merge the latitude and longitude details. We'll also calculate the basic trip revenue         by subtracting the tip from the total fare. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Tutorial/ExtendedTutorial.html#concept_u4h_mwf_qs" data-id="concept_u4h_mwf_qs"><title>Preview and Edit the Pipeline</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The extended tutorial is almost done, so let's use data preview to see how different     stages transform data.  We'll make some configuration changes and do some testing by editing     preview data.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Tutorial/ExtendedTutorial.html#task_lh2_yhy_ps" data-id="task_lh2_yhy_ps"><title>Write to Trash</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">To wrap up the extended tutorial, let's use the Trash destination as a temporary         placeholder.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Tutorial/ExtendedTutorial.html#task_fsb_1my_ps" data-id="task_fsb_1my_ps"><title>Run the Extended Pipeline</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Now that the extended pipeline is complete, let's reset the origin and run the         pipeline again. </p>
</shortdesc><topicmeta></topicmeta></topic></topic></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_sh3_frm_tq" data-id="concept_sh3_frm_tq"><title>Troubleshooting</title><topicmeta></topicmeta><topic href="Troubleshooting/Troubleshooting_title.html#concept_ivc_mll_2s" data-id="concept_ivc_mll_2s"><title>Accessing Error Messages</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_vxd_tsm_tq" data-id="concept_vxd_tsm_tq"><title>Pipeline Basics</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Troubleshooting/Troubleshooting_title.html#concept_tz4_fhm_js" data-id="concept_tz4_fhm_js"><title>Data Preview </title><topicmeta></topicmeta></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_ydy_pj5_vt" data-id="concept_ydy_pj5_vt"><title>General Validation Errors</title><topicmeta></topicmeta></topic></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_fwl_5cl_gs" data-id="concept_fwl_5cl_gs"><title>Origins</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Troubleshooting/Troubleshooting_title.html#concept_axb_spb_ys" data-id="concept_axb_spb_ys"><title>Directory</title><topicmeta></topicmeta></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_ocw_b3g_vs" data-id="concept_ocw_b3g_vs"><title>Hadoop FS</title><topicmeta></topicmeta></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_wps_1mc_ww" data-id="concept_wps_1mc_ww"><title>HTTP Client</title><topicmeta></topicmeta></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_ggx_s23_ks" data-id="concept_ggx_s23_ks"><title>JDBC</title><topicmeta></topicmeta></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_err_w23_ks" data-id="concept_err_w23_ks"><title>Kafka Consumer</title><topicmeta></topicmeta></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_lsb_gm3_jx" data-id="concept_lsb_gm3_jx"><title>Oracle CDC Client</title><topicmeta></topicmeta></topic></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_m4g_qyk_2s" data-id="concept_m4g_qyk_2s"><title>Destinations </title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Troubleshooting/Troubleshooting_title.html#concept_a3w_z3m_js" data-id="concept_a3w_z3m_js"><title>Cassandra</title><topicmeta></topicmeta></topic><topic href="Troubleshooting/Troubleshooting_title.html#unique_462688869" data-id="concept_a3w_z3m_js"><title>Hadoop FS</title><topicmeta></topicmeta></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_rp1_ghd_zs" data-id="concept_rp1_ghd_zs"><title>HBase</title><topicmeta></topicmeta></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_mth_cjm_js" data-id="concept_mth_cjm_js"><title>Kafka Producer</title><topicmeta></topicmeta></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_gt1_s41_rt" data-id="concept_gt1_s41_rt"><title>SDC RPC</title><topicmeta></topicmeta></topic></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_vrq_qh1_hy" data-id="concept_vrq_qh1_hy"><title>JDBC Connections</title><topicmeta></topicmeta><topic href="Troubleshooting/Troubleshooting_title.html#concept_oqc_431_hy" data-id="concept_oqc_431_hy"><title>No Suitable Driver</title><topicmeta></topicmeta></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_cx2_p31_hy" data-id="concept_cx2_p31_hy"><title>Cannot Connect to Database</title><topicmeta></topicmeta></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_hnf_wkt_sy" data-id="concept_hnf_wkt_sy"><title>MySQL JDBC Driver and Time Values</title><topicmeta></topicmeta></topic></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_ay2_w1l_2s" data-id="concept_ay2_w1l_2s"><title>Performance</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_dpv_chb_ys" data-id="concept_dpv_chb_ys"><title>Monitoring</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Troubleshooting/Troubleshooting_title.html#concept_zjl_nnl_2s" data-id="concept_zjl_nnl_2s"><title>Cluster Execution Mode </title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Glossary/Glossary_title.html#concept_xbx_rs1_tq" data-id="concept_xbx_rs1_tq"><title>Glossary</title><topicmeta></topicmeta><topic href="Glossary/Glossary_title.html#concept_h2c_pfh_tq" data-id="concept_h2c_pfh_tq"><title>Glossary of Terms</title><topicmeta></topicmeta></topic></topic><topic href="Apx-DataFormats/DataFormat_Title.html#concept_jn1_nzb_kv" data-id="concept_jn1_nzb_kv"><title>Data Formats by Stage</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Apx-DataFormats/DataFormat_Title.html#concept_bcw_qzb_kv" data-id="concept_bcw_qzb_kv"><title>Data Format Support</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Apx-DataFormats/DataFormat_Title.html#concept_kgd_11c_kv" data-id="concept_kgd_11c_kv"><title>Origins</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The following table lists the data formats supported by each origin.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Apx-DataFormats/DataFormat_Title.html#concept_odv_w5c_kv" data-id="concept_odv_w5c_kv"><title>Destinations</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The following table lists the data formats supported by each destination.</p>
</shortdesc><topicmeta></topicmeta></topic></topic></topic><topic href="Expression_Language/ExpressionLanguage_title.html" data-id="concept_pvm_yt3_wq"><title>Expression Language</title><topicmeta></topicmeta><topic href="Expression_Language/ExpressionLanguage_overview.html#concept_p54_4kl_vq" data-id="concept_p54_4kl_vq"><title>Expression Language</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Expression_Language/ExpressionLanguage_overview.html#concept_r1w_tkp_tt" data-id="concept_r1w_tkp_tt"><title>Expression Examples</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Expression_Language/Functions.html#concept_lhz_pyp_1r" data-id="concept_lhz_pyp_1r"><title>Functions</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Expression_Language/Functions.html#concept_p1z_ggv_1r" data-id="concept_p1z_ggv_1r"><title>Record Functions</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Use record functions to determine information about a record, such as the stage that   created it or whether a field exists in the record. </p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Expression_Language/Functions.html#concept_s2c_q14_fs" data-id="concept_s2c_q14_fs"><title>Delimited Data Record Functions</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Use delimited data record functions to process delimited data with the list root field   type. If you configured an origin to process the delimited data with the list-map root field type,   you can use standard record functions.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Expression_Language/Functions.html#concept_ndj_43v_1r" data-id="concept_ndj_43v_1r"><title>Error Record Functions</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Error record functions provide information about error records. Use error functions to   process error records.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Expression_Language/Functions.html#concept_ylk_v44_jw" data-id="concept_ylk_v44_jw"><title>Base64 Functions</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Use Base64 functions to encode or decode data using Base64.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Expression_Language/Functions.html#concept_hpn_xfk_p5" data-id="concept_hpn_xfk_p5"><title>Data Drift Functions</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Use data drift functions to create alerts when data drift occurs. You can use these         functions in data drift rules.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Expression_Language/Functions.html#concept_kxj_nyl_5x" data-id="concept_kxj_nyl_5x"><title>File Functions</title><topicmeta></topicmeta></topic><topic href="Expression_Language/Functions.html#concept_m2m_s1f_lw" data-id="concept_m2m_s1f_lw"><title>Math Functions</title><topicmeta></topicmeta></topic><topic href="Expression_Language/Functions.html#concept_dvg_nqn_wx" data-id="concept_dvg_nqn_wx"><title>Pipeline Functions</title><topicmeta></topicmeta></topic><topic href="Expression_Language/Functions.html#concept_ahp_f4v_1r" data-id="concept_ahp_f4v_1r"><title>String Functions </title><topicmeta></topicmeta></topic><topic href="Expression_Language/Functions.html#concept_qkr_trf_sw" data-id="concept_qkr_trf_sw"><title>Time Functions</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">Use time functions to return the current time or to transform datetime data.</p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Expression_Language/Functions.html#concept_ddw_ld1_1s" data-id="concept_ddw_ld1_1s"><title>Miscellaneous Functions</title><topicmeta></topicmeta></topic></topic><topic href="Expression_Language/Constants.html" data-id="concept_ybc_ly4_yt"><title>Constants</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Expression_Language/DateTimeVariables.html" data-id="concept_gh4_qd2_sv"><title>Datetime Variables</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Expression_Language/Literals.html" data-id="concept_h54_w4m_xq"><title>Literals</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Expression_Language/Operators.html#concept_ltp_5mj_wq" data-id="concept_ltp_5mj_wq"><title>Operators</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta><topic href="Expression_Language/Operators.html#concept_dbm_nxp_1r" data-id="concept_dbm_nxp_1r"><title>Operator Precedence </title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc">The precedence of operators highest to lowest, left to right is as follows:</p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Expression_Language/ReservedWords.html" data-id="concept_wwv_5xp_1r"><title>Reserved Words</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic></topic><topic href="Apx-RegEx/RegEx-Title.html#concept_vcj_1ws_js" data-id="concept_vcj_1ws_js"><title>Regular Expressions</title><topicmeta></topicmeta><topic href="Apx-RegEx/RegEx-Title.html#concept_vd4_nsc_gs" data-id="concept_vd4_nsc_gs"><title>Regular Expressions Overview</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Apx-RegEx/RegEx-Title.html#concept_wnv_25j_ks" data-id="concept_wnv_25j_ks"><title>Regular Expressions in the Pipeline</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Apx-RegEx/RegEx-Title.html#concept_jyt_lb5_js" data-id="concept_jyt_lb5_js"><title>Quick Reference</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Apx-RegEx/RegEx-Title.html#concept_ez2_3jl_ls" data-id="concept_ez2_3jl_ls"><title>Regex Examples</title><topicmeta></topicmeta></topic></topic><topic href="Apx-GrokPatterns/GrokPatterns_title.html#concept_chv_vmj_wr" data-id="concept_chv_vmj_wr"><title>Grok Patterns</title><topicmeta></topicmeta><topic href="Apx-GrokPatterns/GrokPatterns_title.html#concept_vdk_xjb_wr" data-id="concept_vdk_xjb_wr"><title>Defining Grok Patterns</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Apx-GrokPatterns/GrokPatterns_title.html#concept_pzq_5bk_wr" data-id="concept_pzq_5bk_wr"><title>General Grok Patterns</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Apx-GrokPatterns/GrokPatterns_title.html#concept_fvt_tfk_wr" data-id="concept_fvt_tfk_wr"><title>Date and Time Grok Patterns</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Apx-GrokPatterns/GrokPatterns_title.html#concept_xq3_3wq_wr" data-id="concept_xq3_3wq_wr"><title>Java Grok Patterns</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Apx-GrokPatterns/GrokPatterns_title.html#concept_fny_xkk_wr" data-id="concept_fny_xkk_wr"><title>Log Grok Patterns</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Apx-GrokPatterns/GrokPatterns_title.html#concept_rr5_qbk_wr" data-id="concept_rr5_qbk_wr"><title>Networking Grok Patterns</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic><topic href="Apx-GrokPatterns/GrokPatterns_title.html#concept_tpp_12k_wr" data-id="concept_tpp_12k_wr"><title>Path Grok Patterns</title><shortdesc><p xmlns="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
</shortdesc><topicmeta></topicmeta></topic></topic></toc>