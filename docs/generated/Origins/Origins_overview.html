
<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />        
      <meta name="copyright" content="(C) Copyright 2005" /><meta name="DC.rights.owner" content="(C) Copyright 2005" /><meta name="DC.Type" content="concept" /><meta name="DC.Title" content="Origins" /><meta name="abstract" content="An origin stage represents the source for the pipeline. You can use a single origin stage in a pipeline." /><meta name="description" content="An origin stage represents the source for the pipeline. You can use a single origin stage in a pipeline." /><meta name="DC.Relation" scheme="URI" content="../Origins/Origins_title.html" /><meta name="DC.Format" content="XHTML" /><meta name="DC.Identifier" content="concept_hpr_twm_jq" /><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>Origins</title><!--  Generated with Oxygen version 18.1, build number 2016112217.  --><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/skins/skin.css" /><link rel="stylesheet" type="text/css" href="../skin.css" /><script type="text/javascript"><!--
            
            var prefix = "../index.html";
            
            --></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.11.3.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.highlight-3.js"><!----></script><script type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
</head>
<body onload="highlightSearchTerm()" class="frmBody">
<table class="nav"><tbody><tr><td colspan="2"><div id="printlink"><a href="javascript:window.print();" title="Print this page"></a></div><div id="permalink"><a href="#" title="Link to this page"></a></div></td></tr><tr><td style="width:75%;"><span class="topic_breadcrumb_links"><span class="topic_breadcrumb_link"><a class="navheader_parent_path" href="../Origins/Origins_title.html" title="Origins">Origins</a></span></span></td><td><span id="topic_navigation_links" class="navheader">
<span class="navparent"><a class="link" href="../Origins/Origins_title.html" title="Origins"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Origins</span></a></span>  </span></td></tr></tbody></table>
<div class="nested0" id="concept_hpr_twm_jq">
 <h1 class="title topictitle1">Origins</h1>

 
 <div class="body conbody"><p class="shortdesc">An origin stage represents the source for the pipeline. You can use a single origin
    stage in a pipeline.</p>

  <p class="p">You can use different origins
      based on the execution mode of the pipeline. </p>

    <div class="p">In standalone pipelines, you can use the following origins: <ul class="ul" id="concept_hpr_twm_jq__ul_mxz_jxm_jq">
        <li class="li"><a class="xref" href="AmazonS3.html#concept_kvs_3hh_ht" title="The Amazon S3 origin reads objects stored in Amazon S3. The object names must share a prefix pattern and should be fully written.">Amazon S3</a> - Reads objects from
          Amazon S3.</li>

        <li class="li"><a class="xref" href="Directory.html#concept_qcq_54n_jq" title="The Directory origin reads data from files in a directory. The file names must all share a file name pattern and be fully written. To read data from an active file that is still being written to, use the File Tail origin.">Directory</a> - Reads fully-written
          files from a directory. </li>

        <li class="li"><a class="xref" href="FileTail.html#concept_n1y_qyp_5q" title="The File Tail origin reads lines of data as they are written to an active file after reading related archived files in the same directory. File Tail generates a record for each line of data.">File Tail</a> - Reads lines of data
          from an active file after reading related archived files in the directory. </li>

        <li class="li"><a class="xref" href="HTTPClient.html#concept_wk4_bjz_5r" title="You can configure the HTTP Client origin to use the OAuth 2 protocol to connect to an HTTP service that uses basic, digest, or universal authentication, OAuth 2 client credentials, OAuth 2 username and password, or OAuth 2 JSON Web Tokens (JWT).To use OAuth 2 authorization to read from Twitter, configure HTTP Client to use basic authentication and the client credentials grant.To use OAuth 2 authorization to read from Microsoft Azure AD, configure HTTP Client to use no authentication and the client credentials grant.To use OAuth 2 authorization to read from Google service accounts, configure HTTP Client to use no authentication and the JSON Web Tokens grant.The HTTP Client origin processes data differently based on the data format. The origin processes the following types of data:">HTTP Client</a> - Reads data from a
          streaming HTTP resource URL.</li>

        <li class="li"><a class="xref" href="HTTPServer.html#concept_s2p_5hb_4y">HTTP Server</a> - Listens on an HTTP
          endpoint and processes the contents of all authorized HTTP POST requests. Creates multiple
          threads to enable parallel processing in a multithreaded pipeline.</li>

        <li class="li"><a class="xref" href="HTTPtoKafka.html#concept_izh_mqd_dy">HTTP to Kafka</a> - Listens on a
          HTTP endpoint and writes the contents of all authorized HTTP POST requests directly to
          Kafka.</li>

        <li class="li"><a class="xref" href="MultiTableJDBCConsumer.html#concept_zp3_wnw_4y" title="The JDBC Multitable Consumer origin reads database data from multiple tables through a JDBC connection. The origin returns data as a map with column names and field values.">JDBC Multitable
            Consumer</a> - Reads database data from multiple tables through a JDBC
          connection.</li>

        <li class="li"><a class="xref" href="JDBCConsumer.html#concept_qhf_hjr_bs" title="JDBC Query Consumer uses an offset column and initial offset value to determine where to start reading data within a table. Include both the offset column and the offset value in the WHERE clause of the SQL query. JDBC Query Consumer supports recovery after a deliberate or unexpected stop when it performs incremental queries. Recovery is not supported for full queries.When you define the SQL query for incremental mode, JDBC Query Consumer requires a WHERE and ORDER BY clause in the query. You can define any type of SQL query for full mode.">JDBC Query Consumer</a> - Reads
          database data using a user-defined SQL query through a JDBC connection. </li>

        <li class="li"><a class="xref" href="JMS.html#concept_rhh_4nj_dt" title="The JMS Consumer origin reads data from a Java Messaging Service (JMS).">JMS Consumer</a> - Reads messages from JMS. </li>

        <li class="li"><a class="xref" href="KConsumer.html#concept_msz_wnr_5q" title="The Kafka Consumer origin reads data from an Apache Kafka cluster.">Kafka Consumer</a> - Reads messages
          from Kafka.</li>

        <li class="li"><a class="xref" href="KinConsumer.html#concept_anh_4y3_yr" title="The Kinesis Consumer origin reads data from Amazon Kinesis Streams.">Kinesis Consumer</a> - Reads data
          from Kinesis Streams.</li>

        <li class="li"><a class="xref" href="MapRDBJSON.html#concept_ywh_k15_3y" title="The MapR DB JSON origin reads JSON documents from MapR DB JSON tables. The origin converts each document into a record.">MapR DB JSON</a> - Reads JSON documents from MapR DB
          JSON tables.</li>

        <li class="li"><a class="xref" href="MapRFS.html#concept_psz_db4_lx" title="The MapR FS origin reads files from MapR FS. Use this origin only in pipelines configured for cluster execution mode.">MapR FS</a> - Reads files from MapR
          FS.</li>

        <li class="li"><a class="xref" href="MapRStreamsCons.html#concept_cvy_xsf_2v" title="The MapR Streams Consumer origin reads messages from MapR Streams.">MapR Streams Consumer</a> -
          Reads messages from MapR Streams.</li>

        <li class="li"><a class="xref" href="MongoDB.html#concept_bk4_2rs_ns">MongoDB</a> - Reads documents from
          MongoDB.</li>

        <li class="li"><a class="xref" href="MongoDBOplog.html#concept_mjn_yqw_4y">MongoDB Oplog</a> - Reads entries
          from a MongoDB Oplog.</li>

        <li class="li"><a class="xref" href="MySQLBinaryLog.html#concept_kqg_1yh_xx" title="You can configure the origin to start reading the binary log file from the beginning of the file or from an initial offset in the file.The binary log file captures all changes made to the MySQL database. If you want the MySQL Binary Log origin to capture changes from a subset of tables, you can configure the origin to include changes from specific tables or to ignore changes from specific tables.">MySQL Binary Log</a> - Reads
          MySQL binary logs to generate change data capture records. </li>

        <li class="li"><a class="xref" href="Omniture.html#concept_dsr_xmw_1s" title="The Omniture origin processes JSON website usage reports generated by the Omniture reporting APIs. Omniture is also known as the Adobe Marketing Cloud.">Omniture</a> - Reads web usage reports
          from the Omniture reporting API.</li>

        <li class="li"><a class="xref" href="OracleCDC.html#concept_rs5_hjj_tw">Oracle CDC Client</a> - Reads LogMiner
          redo logs to generate change data capture records.</li>

        <li class="li"><a class="xref" href="RabbitMQ.html#concept_dyg_lq1_h5" title="RabbitMQ Consumer reads AMQP messages from a single RabbitMQ queue.">RabbitMQ Consumer</a> - Reads messages
          from RabbitMQ.</li>

        <li class="li"><a class="xref" href="Redis.html#concept_plr_t3v_jw" title="The Redis Consumer origin reads messages from Redis.">Redis Consumer</a> - Reads messages from
          Redis.</li>

        <li class="li"><a class="xref" href="Salesforce.html#concept_odf_vr3_rx" title="The Salesforce origin reads data from Salesforce.">Salesforce</a> - Reads data from
          Salesforce.</li>

        <li class="li"><a class="xref" href="SDC_RPCorigin.html#concept_agb_5c1_ct" title="The SDC RPC origin enables connectivity between two SDC RPC pipelines. The SDC RPC origin reads data passed from an SDC RPC destination. Use the SDC RPC origin as part of an SDC RPC destination pipeline.">SDC RPC</a> - Reads data from an
          SDC RPC destination in an SDC RPC pipeline.</li>

        <li class="li"><a class="xref" href="SDCRPCtoKafka.html#concept_tdk_slk_pw" title="The SDC RPC to Kafka origin reads data from one or more SDC RPC destinations and writes it immediately to Kafka. Use the SDC RPC to Kafka origin in an SDC RPC destination pipeline.">SDC RPC to Kafka</a> - Reads data
          from an SDC RPC destination in an SDC RPC pipeline and writes it to Kafka.</li>

        <li class="li"><a class="xref" href="SDCRPCtoKafka.html#concept_tdk_slk_pw" title="The SDC RPC to Kafka origin reads data from one or more SDC RPC destinations and writes it immediately to Kafka. Use the SDC RPC to Kafka origin in an SDC RPC destination pipeline.">SFTP/FTP Client</a> - Reads files
          from an SFTP or FTP server.</li>

        <li class="li"><a class="xref" href="UDP.html#concept_rst_2y5_1s">UDP Source</a> - Reads messages from one or
          more UDP ports. </li>

        <li class="li"><a class="xref" href="UDPtoKafka.html#concept_jzq_jcz_pw" title="When you use a UDP to Kafka origin in a pipeline, connect the origin to a Trash destination.">UDP to Kafka</a> - Reads messages
          from one or more UDP ports and writes the data to Kafka.</li>

      </ul>
</div>

    <div class="p">In cluster pipelines, you can use the following origins:<ul class="ul" id="concept_hpr_twm_jq__ul_unr_xhb_ws">
        <li class="li"><a class="xref" href="HadoopFS-origin.html#concept_lw2_tnm_vs" title="The Hadoop FS origin reads data from the Hadoop Distributed File System (HDFS). Use this origin only in pipelines configured for cluster execution mode.">Hadoop FS</a> - Reads data from
          the Hadoop Distributed File System (HDFS). </li>

        <li class="li"><a class="xref" href="KConsumer.html#concept_msz_wnr_5q" title="The Kafka Consumer origin reads data from an Apache Kafka cluster.">Kafka Consumer</a> - Reads messages
          from Kafka. Use the cluster version of the origin.</li>

        <li class="li"><a class="xref" href="MapRFS.html#concept_psz_db4_lx" title="The MapR FS origin reads files from MapR FS. Use this origin only in pipelines configured for cluster execution mode.">MapR FS</a> - Reads data from MapR
          FS.</li>

        <li class="li"><a class="xref" href="MapRStreamsCons.html#concept_cvy_xsf_2v" title="The MapR Streams Consumer origin reads messages from MapR Streams.">MapR Streams Consumer</a> -
          Reads messages from MapR Streams.</li>

      </ul>
</div>

    <div class="p">To help create or test pipelines, you can use the following development origins:<ul class="ul" id="concept_hpr_twm_jq__ul_nr2_c1p_qv">
        <li class="li">Dev Data Generator </li>

        <li class="li">Dev Random Source</li>

        <li class="li">Dev Raw Data Source </li>

        <li class="li">Dev SDC RPC with Buffering</li>

      </ul>
</div>

    <p class="p">For more information, see <a class="xref" href="../Pipeline_Design/DevStages.html#concept_czx_ktn_ht">Development Stages</a>.</p>

 </div>

<div class="related-links"></div>
<div class="topic concept nested1" id="concept_rsz_cnw_qy">
 <h2 class="title topictitle2">Comparing HTTP Origins</h2>

 <div class="body conbody">
  <div class="p">We have several HTTP origins, make sure to use the best one for your needs. Here's a quick
            breakdown of some key differences: 
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="concept_rsz_cnw_qy__table_pw5_npv_qy" class="table" frame="border" border="1" rules="all">
                    
                    
                    <thead class="thead" align="left">
                        <tr>
                            <th class="entry" valign="top" width="28.57142857142857%" id="d206053e358">Origin</th>

                            <th class="entry" valign="top" width="71.42857142857143%" id="d206053e361">Description</th>

                        </tr>

                    </thead>

                    <tbody class="tbody">
                        <tr>
                            <td class="entry" valign="top" width="28.57142857142857%" headers="d206053e358 "><a class="xref" href="HTTPClient.html#concept_wk4_bjz_5r" title="You can configure the HTTP Client origin to use the OAuth 2 protocol to connect to an HTTP service that uses basic, digest, or universal authentication, OAuth 2 client credentials, OAuth 2 username and password, or OAuth 2 JSON Web Tokens (JWT).To use OAuth 2 authorization to read from Twitter, configure HTTP Client to use basic authentication and the client credentials grant.To use OAuth 2 authorization to read from Microsoft Azure AD, configure HTTP Client to use no authentication and the client credentials grant.To use OAuth 2 authorization to read from Google service accounts, configure HTTP Client to use no authentication and the JSON Web Tokens grant.The HTTP Client origin processes data differently based on the data format. The origin processes the following types of data:">HTTP
                                    Client</a></td>

                            <td class="entry" valign="top" width="71.42857142857143%" headers="d206053e361 ">
                                <ul class="ul" id="concept_rsz_cnw_qy__ul_ixb_t5v_qy">
                                    <li class="li">Initiates HTTP requests for an external system.</li>

                                    <li class="li">Processes data synchronously.</li>

                                    <li class="li">Processes JSON, text, and XML data. </li>

                                    <li class="li">Can process a range of HTTP requests.</li>

                                    <li class="li">
                                        <p class="p">Can be used in a pipeline with processors. </p>

                                    </li>

                                </ul>

                            </td>

                        </tr>

                        <tr>
                            <td class="entry" valign="top" width="28.57142857142857%" headers="d206053e358 "><a class="xref" href="HTTPServer.html#concept_s2p_5hb_4y">HTTP
                                    Server</a></td>

                            <td class="entry" valign="top" width="71.42857142857143%" headers="d206053e361 ">
                                <ul class="ul" id="concept_rsz_cnw_qy__ul_vsb_x5v_qy">
                                    <li class="li">Listens for incoming HTTP requests and processes them while
                                        the sender waits for confirmation.</li>

                                    <li class="li">Processes data synchronously. </li>

                                    <li class="li">Creates multithreaded pipelines, thus suitable for high
                                        throughput of incoming data.</li>

                                    <li class="li">Processes virtually all data formats. Processes HTTP POST
                                        requests only.</li>

                                    <li class="li">Can be used in a pipeline with processors.</li>

                                </ul>

                            </td>

                        </tr>

                        <tr>
                            <td class="entry" valign="top" width="28.57142857142857%" headers="d206053e358 "><a class="xref" href="HTTPtoKafka.html#concept_izh_mqd_dy">HTTP to
                                    Kafka</a></td>

                            <td class="entry" valign="top" width="71.42857142857143%" headers="d206053e361 ">
                                <ul class="ul" id="concept_rsz_cnw_qy__ul_uj1_v5v_qy">
                                    <li class="li">Listens for incoming HTTP requests and writes them
                                        immediately to Kafka with no additional processing. </li>

                                    <li class="li">Processes data asynchronously. Suitable for very high
                                        throughput of incoming data.</li>

                                    <li class="li">Writes all data to Kafka, regardless of the data format. </li>

                                    <li class="li">
                                        <p class="p">Processes HTTP POST requests only.</p>

                                    </li>

                                    <li class="li">
                                        <p class="p">Cannot be used in a pipeline with processors. For more
                                            flexibility, use the HTTP Server origin.</p>

                                    </li>

                                </ul>

                            </td>

                        </tr>

                    </tbody>

                </table>
</div>
</div>

 </div>

</div>
<div class="topic concept nested1" id="concept_ypd_vgr_5q">
 <h2 class="title topictitle2">Batch Size and Wait Time</h2>

 
 <div class="body conbody"><p class="shortdesc">For origin stages, the batch size determines the maximum number of records sent through
        the pipeline at one time. The batch wait time determines the time that the origin waits for
        data before sending a batch. At the end of the wait time, it sends the batch regardless of
        how many records the batch contains. </p>

  <p class="p">For example, a File Tail origin is configured
            for a batch size of 20 records and a batch wait time of 240 seconds. When data arrives
            quickly, File Tail fills a batch with 20 records and sends it through the pipeline
            immediately, creating a new batch and sending it again as soon as it is full. As
            incoming data slows, a remaining batch contains a few records, gaining an extra record
            periodically. 240 seconds after creating the batch, File Tail sends the partially-full
            batch through the pipeline. It immediately creates a new batch and starts a new
            countdown.</p>

  <p class="p">Configure the batch wait time based on your processing needs. You might reduce the batch wait
   time to ensure all data is processed within a specified time frame or to make regular contact
   with pipeline destinations. Use the default or increase the wait time if you prefer not to
   process partial or empty batches.</p>

 </div>

</div>
<div class="topic concept nested1" id="concept_uxr_g52_qs">
 <h2 class="title topictitle2">File Compression Formats</h2>

 
 <div class="body conbody"><p class="shortdesc">Origins that read files can read uncompressed, compressed files, archives, and
    compressed archives. </p>

  <p class="p">Hadoop
      FS reads compressed files automatically. For all other file-based origins, you indicate the
      compression format in the origin. </p>

    <div class="p">The following table lists the supported file types by extension:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="concept_uxr_g52_qs__table_fwr_k3s_b5" class="table" frame="border" border="1" rules="all">
          
          
          <thead class="thead" align="left">
            <tr>
              <th class="entry" valign="top" width="30%" id="d206053e545">Compression Format</th>

              <th class="entry" valign="top" width="70%" id="d206053e548">Description</th>

            </tr>

          </thead>

          <tbody class="tbody">
            <tr>
              <td class="entry" valign="top" width="30%" headers="d206053e545 ">Uncompressed</td>

              <td class="entry" valign="top" width="70%" headers="d206053e548 ">Processes uncompressed files of the configured data format.</td>

            </tr>

            <tr>
              <td class="entry" valign="top" width="30%" headers="d206053e545 ">Compressed</td>

              <td class="entry" valign="top" width="70%" headers="d206053e548 ">Processes files compressed by the following compression formats: <ul class="ul" id="concept_uxr_g52_qs__ul_ctx_3ss_b5">
                  <li class="li">gzip</li>

                  <li class="li">bgzip2</li>

                  <li class="li">xz</li>

                  <li class="li">lzma</li>

                  <li class="li">Pack200</li>

                  <li class="li">DEFLATE</li>

                  <li class="li">Z</li>

                </ul>
</td>

            </tr>

            <tr>
              <td class="entry" valign="top" width="30%" headers="d206053e545 ">Archive</td>

              <td class="entry" valign="top" width="70%" headers="d206053e548 ">Processes files archived by the following archive formats: <ul class="ul" id="concept_uxr_g52_qs__ul_l1q_gsm_c5">
                  <li class="li">7z</li>

                  <li class="li">ar</li>

                  <li class="li">arj</li>

                  <li class="li">cpio</li>

                  <li class="li">dump</li>

                  <li class="li">tar</li>

                  <li class="li">zip</li>

                </ul>
</td>

            </tr>

            <tr>
              <td class="entry" valign="top" width="30%" headers="d206053e545 ">Compressed Archive</td>

              <td class="entry" valign="top" width="70%" headers="d206053e548 ">Processes files in compressed archives created by supported compression and
                archive formats.</td>

            </tr>

          </tbody>

        </table>
</div>
</div>

 </div>

</div>
<div class="topic task nested1" id="task_jp5_ql1_tq">
    <h2 class="title topictitle2">Previewing Raw Source Data</h2>

    
    <div class="body taskbody"><p class="shortdesc">You can preview raw source data for Directory, File Tail, and Kafka Consumer origins.
        Preview raw source data when reviewing the data might help with origin
        configuration.</p>

        <div class="section context">
            <p class="p">When you preview file data, you can
                use the real directory and actual source file. Or when appropriate, you might use a
                different file that is similar to the source. </p>

            <p class="p">When you preview Kafka data, you enter the connection information for the Kafka
                cluster.</p>

            <p class="p">The data used for the raw source preview in an origin stage is not used when
                previewing data for the pipeline.</p>

        </div>

        <ol class="ol steps" id="task_jp5_ql1_tq__steps_k14_k41_tq"><li class="li step stepexpand">
                <span class="ph cmd">In the Properties panel for the origin stage, click the <span class="keyword wintitle">Raw
                        Preview</span> tab.</span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For a Directory or File Tail origin, enter a directory and file name.</span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For a Kafka Consumer, enter the following information:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_jp5_ql1_tq__table_eh1_q2f_xq" class="table" frame="border" border="1" rules="all">
                            
                            
                            <thead class="thead" align="left">
                                <tr>
                                    <th class="entry" valign="top" width="22.22222222222222%" id="d206053e725">Kafka Raw Preview Property</th>

                                    <th class="entry" valign="top" width="77.77777777777779%" id="d206053e728">Description</th>

                                </tr>

                            </thead>

                            <tbody class="tbody">
                                <tr>
                                    <td class="entry" valign="top" width="22.22222222222222%" headers="d206053e725 ">Topic</td>

                                    <td class="entry" valign="top" width="77.77777777777779%" headers="d206053e728 ">Kafka topic to read.</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="22.22222222222222%" headers="d206053e725 ">Partition</td>

                                    <td class="entry" valign="top" width="77.77777777777779%" headers="d206053e728 ">Partition to read.</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="22.22222222222222%" headers="d206053e725 ">Broker Host</td>

                                    <td class="entry" valign="top" width="77.77777777777779%" headers="d206053e728 ">Broker host name. Use any broker associated with the
                                        partition.</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="22.22222222222222%" headers="d206053e725 ">Broker Port</td>

                                    <td class="entry" valign="top" width="77.77777777777779%" headers="d206053e728 ">Broker port number.</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="22.22222222222222%" headers="d206053e725 ">Max Wait Time (secs)</td>

                                    <td class="entry" valign="top" width="77.77777777777779%" headers="d206053e728 ">Maximum amount of time the preview waits to receive data
                                        from Kafka.</td>

                                </tr>

                            </tbody>

                        </table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">Click <span class="ph uicontrol">Preview</span>.</span>
            </li>
</ol>

        <div class="section result">The Raw Source Preview area displays the preview.</div>

    </div>

</div>
</div>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../Origins/Origins_title.html" title="Origins"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Origins</span></a></span>  </div><div class="footer" id="webhelp_copyright_information"><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script></div>
</body>
</html>