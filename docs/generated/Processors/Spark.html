
<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />        
      <meta name="copyright" content="(C) Copyright 2005" /><meta name="DC.rights.owner" content="(C) Copyright 2005" /><meta name="DC.Type" content="concept" /><meta name="DC.Title" content="Spark Evaluator" /><meta name="abstract" content="The Spark Evaluator performs custom processing within a pipeline based on a Spark application that you develop. Use the Spark Evaluator processor in standalone pipelines only." /><meta name="description" content="The Spark Evaluator performs custom processing within a pipeline based on a Spark application that you develop. Use the Spark Evaluator processor in standalone pipelines only." /><meta name="DC.Relation" scheme="URI" content="../Processors/Processors_title.html" /><meta name="DC.Format" content="XHTML" /><meta name="DC.Identifier" content="concept_cpx_1lm_zx" /><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>Spark Evaluator</title><!--  Generated with Oxygen version 18.1, build number 2016112217.  --><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/skins/skin.css" /><link rel="stylesheet" type="text/css" href="../skin.css" /><script type="text/javascript"><!--
            
            var prefix = "../index.html";
            
            --></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.11.3.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.highlight-3.js"><!----></script><script type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
</head>
<body onload="highlightSearchTerm()" class="frmBody">
<table class="nav"><tbody><tr><td colspan="2"><div id="printlink"><a href="javascript:window.print();" title="Print this page"></a></div><div id="permalink"><a href="#" title="Link to this page"></a></div></td></tr><tr><td style="width:75%;"><span class="topic_breadcrumb_links"><span class="topic_breadcrumb_link"><a class="navheader_parent_path" href="../Processors/Processors_title.html" title="Processors">Processors</a></span></span></td><td><span id="topic_navigation_links" class="navheader">
<span class="navparent"><a class="link" href="../Processors/Processors_title.html" title="Processors"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Processors</span></a></span>  </span></td></tr></tbody></table>
<div class="nested0" id="concept_cpx_1lm_zx">
 <h1 class="title topictitle1">Spark Evaluator</h1>

 
 <div class="body conbody"><p class="shortdesc">The Spark Evaluator performs custom processing within a pipeline based on a Spark
        application that you develop. Use the Spark Evaluator processor in standalone pipelines
        only. </p>

  <p class="p">The Spark Evaluator starts a local Spark
            application. The Spark application - or <samp class="ph codeph">SparkContext</samp> - runs as long as
            the pipeline runs. The Spark application submits a job for each batch of records,
            processing the batch and then returning the results and errors back to the pipeline for
            further processing. </p>

        <p class="p">You can configure a parallelism value for the Spark Evaluator. The Spark application
            creates this number of partitions for each batch of records. Each partition is processed
            in parallel. Set the parallelism value based on the number of available processors on
            the <span class="ph">Data
                  Collector</span> machine. Because the Spark Evaluator can use multiple threads to process a batch, the
            processor is especially useful when you need to perform heavy custom processing within a
            pipeline, such as image classification.</p>

        <div class="note note"><span class="notetitle">Note:</span> The stage libraries that include the Spark Evaluator include all dependencies required
            for the processor. The Spark Evaluator does not require any installation
            prerequisites.</div>

        <div class="p">Complete the following tasks to use the Spark Evaluator:<ol class="ol" id="concept_cpx_1lm_zx__ol_pmh_33p_zx">
                <li class="li">Write the Spark application using Java or Scala. Then, package a JAR file
                    containing the application.</li>

                <li class="li">Install the application and its dependencies.</li>

                <li class="li">Configure the Spark Evaluator processor to submit the Spark application.<p class="p">When
                        you configure the processor, you define the parallelism value to use during
                        processing. You also define the name of the custom Spark class that you
                        developed and define the arguments to pass to the <samp class="ph codeph">init</samp>
                        method in the custom Spark class.</p>
</li>

            </ol>
</div>

 </div>

<div class="related-links"></div>
<div class="topic concept nested1" id="concept_lfl_dvd_1y">
 <h2 class="title topictitle2">Developing the Spark Application</h2>

 <div class="body conbody">
  <p class="p">To develop a custom Spark
            application, you write the Spark application and then package a JAR file containing the
            application.</p>

        <p class="p">Use Java or Scala to write a custom Spark class that implements the StreamSets
            SparkTransformer API: <a class="xref" href="https://github.com/streamsets/datacollector-plugin-api/tree/master/streamsets-datacollector-spark-api" target="_blank">https://github.com/streamsets/datacollector-plugin-api/tree/master/streamsets-datacollector-spark-api</a>.</p>

        <p class="p">You can include the following methods in the custom class:</p>

        <dl class="dl">
            
                <dt class="dt dlterm">init</dt>

                <dd class="dd">Optional. The <samp class="ph codeph">init</samp> method is called once when the pipeline
                    starts to read arguments that you configure in the Spark Evaluator processor.
                    Use the <samp class="ph codeph">init</samp> method to make connections to external systems or
                    to read configuration details or existing data from external systems.</dd>

            
            
                <dt class="dt dlterm">transform</dt>

                <dd class="dd">Required. The <samp class="ph codeph">transform</samp> method is called for each batch of
                    records that the pipeline processes. <span class="ph">Data
                  Collector</span> passes a batch of data to the <samp class="ph codeph">transform</samp> method as a
                    Resilient Distributed Dataset (RDD). The method processes the data according to
                    the custom code.</dd>

            
            
                <dt class="dt dlterm">destroy</dt>

                <dd class="dd">Optional. If you include an <samp class="ph codeph">init</samp> method that makes connections
                    to external systems, you should also include the <samp class="ph codeph">destroy</samp> method
                    to close the connections. The <samp class="ph codeph">destroy</samp> method is called when the
                    pipeline stops.</dd>

            
        </dl>

        <p class="p">When you finish writing the custom Spark class, package a JAR file containing the Spark
            application. Compile against the same stage library version that you use for the Spark
            Evaluator processor. For example, if you are using the Spark Evaluator processor
            included in the stage library for the Cloudera CDH version 5.9 distribution of Hadoop,
            build the application against Spark integrated into Cloudera CDH version 5.9.</p>

        <p class="p">If you used Scala to write the custom Spark class, you must build the application so that
            it is compatible with Scala 2.10.</p>

 </div>

</div>
<div class="topic task nested1" id="task_dr2_gvd_1y">
    <h2 class="title topictitle2">Installing the Application</h2>

    
    <div class="body taskbody"><p class="shortdesc">Install the Spark application JAR file as an external library for <span class="ph">Data
                  Collector</span>. If
        your custom Spark application depends on external libraries other than the
        streamsets-datacollector-api, streamsets-datacollector-spark-api, and spark-core libraries,
        install those libraries in the same location as well. </p>

        <div class="section context">
            <div class="note tip"><span class="tiptitle">Tip:</span> To include all dependent libraries used in your custom Spark
                application, you can use the Apache Maven Dependency Plugin. For more information
                about the Dependency Plugin, see <a class="xref" href="http://maven.apache.org/plugins/maven-dependency-plugin/" target="_blank">http://maven.apache.org/plugins/maven-dependency-plugin/</a>.</div>

            <p class="p">To install an external library for the Spark Evaluator, see <a class="xref" href="../Configuration/ExternalLibs.html#concept_pdv_qlw_ft" title="Install external libraries to make them available to Data Collector stages.">Install External Libraries</a>.</p>

            <div class="p">
                <div class="note note"><span class="notetitle">Note:</span> The Spark Evaluator processor is included in the Cloudera CDH stage libraries.
                    When you install external libraries for the processor, you must make them
                    accessible to the appropriate Cloudera CDH stage library.</div>

            </div>

        </div>

    </div>

    
</div>
<div class="topic task nested1" id="task_g1p_gqn_zx">
    <h2 class="title topictitle2">Configuring a Spark Evaluator</h2>

    <div class="body taskbody">
        <div class="section context">
            <p class="p">Configure a Spark Evaluator
                to process data based on a custom Spark application.</p>

        </div>

        <ol class="ol steps"><li class="li step stepexpand">
                <span class="ph cmd">In the Properties panel, on the <span class="keyword wintitle">General</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_g1p_gqn_zx__d41254e4109" class="table" frame="border" border="1" rules="all">
                            
                            
                            <thead class="thead" align="left">
                                <tr>
                                    <th class="entry" valign="top" width="30%" id="d279713e250">General Property</th>

                                    <th class="entry" valign="top" width="70%" id="d279713e253">Description</th>

                                </tr>

                            </thead>

                            <tbody class="tbody">
                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d279713e250 ">Name</td>

                                    <td class="entry" valign="top" width="70%" headers="d279713e253 ">Stage name.</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d279713e250 ">Description</td>

                                    <td class="entry" valign="top" width="70%" headers="d279713e253 ">Optional description.</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d279713e250 ">Stage Library</td>

                                    <td class="entry" valign="top" width="70%" headers="d279713e253 ">Library version that you want to use. </td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d279713e250 ">Required Fields <a class="xref" href="../Pipeline_Design/DroppingUnwantedRecords.html#concept_dnj_bkm_vq" title="A required field is a field that must exist in a record to allow it into the stage for processing. When a record does not include a required field, the record is diverted to the pipeline for error handling. You can define required fields for any processor and most destination stages.">
                                            <img class="image" id="task_g1p_gqn_zx__d41254e4164" src="../Reusable_Content/../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry" valign="top" width="70%" headers="d279713e253 ">Fields that must include data to be passed into the
                                        stage. <div class="note tip"><span class="tiptitle">Tip:</span> You might include
                                            fields that the stage uses.</div>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d279713e250 ">Preconditions <a class="xref" href="../Pipeline_Design/DroppingUnwantedRecords.html#concept_msl_yd4_fs" title="Preconditions are conditions that a record must satisfy to enter the stage for processing. Like required fields, if a record does not meet a precondition, it is diverted to the pipeline for error handling. You can define preconditions for any processor and most destination stages.">
                                            <img class="image" id="task_g1p_gqn_zx__d41254e4178" src="../Reusable_Content/../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry" valign="top" width="70%" headers="d279713e253 ">Conditions that must evaluate to TRUE to allow a record
                                        to enter the stage for processing. Click
                                            <span class="ph uicontrol">Add</span> to create additional
                                        preconditions. </td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d279713e250 ">On Record Error <a class="xref" href="../Pipeline_Design/ErrorHandling.html#concept_atr_j4y_5r" title="Most stages include error record handling options. When an error occurs when processing a record, Data Collector processes records based on the On Record Error property for the stage.">
                                            <img class="image" id="task_g1p_gqn_zx__d41254e4194" src="../Reusable_Content/../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry" valign="top" width="70%" headers="d279713e253 ">Error record handling for the stage: <ul class="ul" id="task_g1p_gqn_zx__d41254e4198">
                                            <li class="li">Discard - Discards the record.</li>

                                            <li class="li">Send to Error - Sends the record to the pipeline for
                                                error handling.</li>

                                            <li class="li">Stop Pipeline - Stops the pipeline. Not valid for
                                                cluster pipelines.</li>

                                        </ul>
</td>

                                </tr>

                            </tbody>

                        </table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="ph uicontrol">Spark</span> tab, configure the following
                    properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_g1p_gqn_zx__table_ufq_xf4_zx" class="table" frame="border" border="1" rules="all">
                            
                            
                            <thead class="thead" align="left">
                                <tr>
                                    <th class="entry" valign="top" width="30%" id="d279713e382">Spark Property</th>

                                    <th class="entry" valign="top" width="70%" id="d279713e385">Description</th>

                                </tr>

                            </thead>

                            <tbody class="tbody">
                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d279713e382 ">Parallelism</td>

                                    <td class="entry" valign="top" width="70%" headers="d279713e385 ">Number of partitions to create per batch of records. For
                                        example, if set to 4, then the Spark application
                                        simultaneously runs 4 parallel jobs to process the batch.
                                            <p class="p">Set the value based on the number of available
                                            processors on the <span class="ph">Data
                  Collector</span> machine.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d279713e382 ">Application Name</td>

                                    <td class="entry" valign="top" width="70%" headers="d279713e385 ">Name of the Spark application. Spark displays this
                                        application name in the log files. <p class="p">If you run pipelines
                                            that include multiple Spark Evaluator processors, be
                                            sure to use a unique application name for each to make
                                            debugging simpler.</p>
<p class="p">Default is SDC Spark
                                        App.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d279713e382 ">Spark Transformer Class
                                        <a class="xref" href="Spark.html#concept_lfl_dvd_1y">
                                            <img class="image" id="task_g1p_gqn_zx__image_h4p_p5v_yq" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry" valign="top" width="70%" headers="d279713e385 ">Fully qualified name of the custom Spark class that
                                        implements the StreamSets SparkTransformer API. Enter the
                                        class name using the following
                                            format:<pre class="pre codeblock">com.streamsets.spark.&lt;custom class&gt;</pre>
<div class="p">For
                                            example, let's assume that you developed a
                                                <samp class="ph codeph">GetCreditCardType</samp> class that
                                            implemented the SparkTransformer API as
                                            follows:<pre class="pre codeblock">public class GetCreditCardType extends SparkTransformer implements Serializable {
...
}</pre>
</div>
<div class="p">Then
                                            you would enter the class name as
                                            follows:<pre class="pre codeblock">com.streamsets.spark.GetCreditCardType</pre>
</div>
</td>

                                </tr>

                                <tr>
                                    <td class="entry" valign="top" width="30%" headers="d279713e382 ">Init Method Arguments
                                        <a class="xref" href="Spark.html#concept_lfl_dvd_1y">
                                            <img class="image" id="task_g1p_gqn_zx__image_h3p_p6v_yq" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry" valign="top" width="70%" headers="d279713e385 ">Arguments to pass to the <samp class="ph codeph">init</samp> method in
                                        the custom Spark class. Enter an argument as required by
                                        your custom Spark class.<p class="p">Click the
                                                <span class="ph uicontrol">Add</span> icon to add additional
                                            arguments.</p>
</td>

                                </tr>

                            </tbody>

                        </table>
</div>

                </div>
            </li>
</ol>

    </div>

</div>
</div>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../Processors/Processors_title.html" title="Processors"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Processors</span></a></span>  </div><div class="footer" id="webhelp_copyright_information"><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script></div>
</body>
</html>